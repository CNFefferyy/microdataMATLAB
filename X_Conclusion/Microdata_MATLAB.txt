Microdata and Matlab: An Introduction
Abi Adams

Damian Clarke
April 22, 2014

Simon Quinn

Contents
I

Foundations

8

1 Entering the ‘Matrix Laboratory’
1.1 Introduction . . . . . . . . . . . . . .
1.2 Our “Hello World”: OLS in matlab
1.3 The beauty of functions . . . . . . .
1.4 A simple utility function . . . . . . .
1.5 Review and exercises . . . . . . . . .

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

9
10
13
17
23
27

2 Optimisation I: The Agent Optimises
2.1 Proﬁt maximisation and linear programming . .
2.2 Utility maximisation and non-linear optimisation
2.3 Simulating heterogeneity . . . . . . . . . . . . . .
2.4 Review and Exercises . . . . . . . . . . . . . . .

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

30
31
36
44
48

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

3 Optimisation II: The Economist Optimises
50
3.1 Maximising Likelihoods . . . . . . . . . . . . . . . . . . . . . . . 51
3.2 Generalised Method of Moments . . . . . . . . . . . . . . . . . . 57
3.3 Review and Exercises . . . . . . . . . . . . . . . . . . . . . . . . 61

II

Discrete Choice

63

4 Discrete Multinomial Choice
4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.2 The binary logit model . . . . . . . . . . . . . . . . . . . . .
4.2.1 The model . . . . . . . . . . . . . . . . . . . . . . .
4.2.2 Simulating the model . . . . . . . . . . . . . . . . .
4.2.3 Estimating the model . . . . . . . . . . . . . . . . .
4.2.4 Estimating by simulation . . . . . . . . . . . . . . .
4.3 The multinomial logit model . . . . . . . . . . . . . . . . .
4.3.1 The model . . . . . . . . . . . . . . . . . . . . . . .
4.3.2 Simulating, estimating and estimating by simulation
4.4 Multinomial Probit . . . . . . . . . . . . . . . . . . . . . . .
4.4.1 Independence assumptions in the Multinomial Logit

1

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.

64
65
66
66
67
68
69
72
72
78
79
79

4.4.2
4.4.3
4.4.4

Simulating the model . . . . . . . . . . . . . . . . . . . . 81
Estimating by simulation . . . . . . . . . . . . . . . . . . 81
Estimating by simulation: A logit-smoothed AR simulator 82

5 Games
5.1 Introduction: A simple Cournot game . . . . . .
5.1.1 Finding the best-response function . . . .
5.2 Estimating a discrete Bayesian game . . . . . . .
5.2.1 A simple discrete game . . . . . . . . . .
5.2.2 Implementing the best-response functions
5.2.3 Solving the game numerically . . . . . . .
5.2.4 Simulating the game . . . . . . . . . . . .
5.2.5 Estimating . . . . . . . . . . . . . . . . .
5.3 Review . . . . . . . . . . . . . . . . . . . . . . . .

III

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

84
. 84
. 86
. 91
. 91
. 95
. 97
. 97
. 100
. 104

Revealed Preference

105

6 Revealed Preference
106
6.1 Review . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106
7 Linear Programming
107
7.1 Review . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107

IV

Dynamics

108

8 Dynamic Choice on a Finite Horizon
8.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8.2 Dynamic Decisions . . . . . . . . . . . . . . . . . . . . . . . . . .
8.2.1 Household Consumption . . . . . . . . . . . . . . . . . . .
8.2.2 A Small Firm . . . . . . . . . . . . . . . . . . . . . . . . .
8.3 Introducing the Value Function . . . . . . . . . . . . . . . . . . .
8.3.1 Computational Accuracy, Curse of Dimensionality and
Memoization . . . . . . . . . . . . . . . . . . . . . . . . .
8.4 Shocks, Uncertainty, and Microeconometrics . . . . . . . . . . . .
8.5 Review . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

109
109
110
110
117
121

9 Dynamic Choice on an Inﬁnite Horizon
9.1 Value Functions and Inﬁnite Solutions . . . . .
9.1.1 A Rough Outline . . . . . . . . . . . . .
9.1.2 Computation . . . . . . . . . . . . . . .
9.2 Policy Iterations and Faster Solutions . . . . .
9.3 Solving for Structural Parameters Using GMM
9.3.1 Applying GMM to Our Dynamic Model
9.3.2 Final Thoughts on Estimation . . . . .
9.4 Review . . . . . . . . . . . . . . . . . . . . . . .

136
138
138
140
146
151
152
156
158

2

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

127
129
135

9.A Analytically Iterating the Value Function . . . . . . . . . . . . . 158

V

Non-Parametric Methods

163

10 Kernel Regression
10.1 Basic introduction to Kernel regression
10.1.1 In Matlab . . . . . . . . . . .
10.2 Structures . . . . . . . . . . . . . . . .
10.3 Kernel and bandwidth choice . . . . .
10.4 Bandwidth choice . . . . . . . . . . . .
10.5 Multivariate Kernels and the Curse . .
10.5.1 In Matlab . . . . . . . . . . .

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

164
167
168
171
172
177
179
180

11 Semiparametric Methods
11.1 Partially Linear Model . . .
11.1.1 Robinson’s approach
11.2 Single Index Model . . . . .
11.2.1 Ichimura’s estimator

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

183
183
184
186
186

VI

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

Speed

189

12 Speeding Things Up!
12.1 Introduction . . . . . . . . . .
12.2 Clever Coding . . . . . . . . .
12.2.1 Vectorising . . . . . .
12.2.2 Sparse Matrices . . . .
12.2.3 Proﬁling Code . . . .
12.2.4 Waiting. . . . . . . . .
12.3 Parallel Computing . . . . . .
12.4 Parallel Computing Plus: The
12.5 Other Tricks . . . . . . . . .

. . . .
. . . .
. . . .
. . . .
. . . .
. . . .
. . . .
GPU
. . . .

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

190
190
191
191
193
196
198
200
204
208

13 Conclusion
210
13.1 Does This Book Follow Benford’s Law . . . . . . . . . . . . . . . 210

3

Introduction
Brian: Look, you’ve got it all wrong! You don’t need to follow me.
You don’t need to follow anybody! You’ve got to think for yourselves! You’re all individuals!
Crowd: Yes! We’re all individuals!
Brian: You’re all diﬀerent!
Crowd: Yes, we are all diﬀerent!

Monty Python, “The Life of Brian”

Two things are true about the seven billion people on this planet. First, no two
of us are the same. Second, we all respond — in more or less sophisticated ways
— to the incentives that we face. These two characteristics — heterogeneity
and agency — are part of what it means to be human. These characteristics
also present a fundamental challenge for economists. As economists we are
concerned with building and estimating models that treat people as responding
to incentives. Ideally, we need our models and methods to respect the pervasive
heterogeneity in the behaviour we seek to understand; we need to somehow deal
with the fact that the world is full of diﬀerent people, with diﬀerent preferences,
who face diﬀerent circumstances.
This book is designed as a practical guide for theory-based empirical analysis in
economics. In short, it is about how to ﬁt economic models to data in a manner
4

that respects the heterogeneity and the agency of the people whose behaviour
we study. Sometimes, the data that economists make use of are simply casual
observations on the world: we might develop ‘stylised facts’ about the way that
people behave, and try to build new models to explain what we see. Other times,
we use aggregate ﬁgures, on concepts like GDP and inﬂation. In this book, we
are concerned with data that has been collected from individuals: individual
households, individual ﬁrms, individual workers, and so on. This is what we
term ‘microdata’. Speciﬁcally then, this is a book about ﬁtting microeconomic
models to microdata, to improve our understanding of human behaviour.
Matlab is not the central plot of this story — though it is certainly the lead
character. Our goal in this book is not to provide a comprehensive introduction
to Matlab. There are already plenty of good books available to do that.1 Further, our goal in this book is not to teach you microeconometric theory. Rather,
our goal is to discuss a series of standard problems in applied microeconometrics,
and show how you can use Matlab to tackle each of them.
It is quite unlikely that any of the speciﬁc models that we study here will ﬁt
perfectly any particular empirical problem that you face in your own work —
but that, in a sense, is exactly the point. There are many excellent textbooks
that cover standard microeconometric methods, and several excellent software
packages for implementing those methods — often requiring just a single line
of code for any given estimator.2 Of course, all of these methods can be implemented in Matlab, but this is not where Matlab’s comparative advantage lies.

The beauty of Matlab is its extraordinary ﬂexibility. matlab allows us easily
to build and adapt our own estimators. It also opens entire classes of new
models — and, therefore, new ideas — that standard econometrics packages
do not allow. Of course, when it comes to econometric algorithms, there will
always be an important role for pre-bottled varieties oﬀ the shelf. But in this
book, we will brew our own. . .
We start in Section I, with topics that form the very foundation of microeconometrics. After a brief review of basic Matlab syntax in chapter 1, we walk you
1
2

For example, you could see Hahn and Valentine’s Essential Matlab for Engineers and Scientists’.
Without loss of generality, think of (i) Cameron and Trivedi (2005) and (ii) Stata. . .

5

through how Matlab can be used to solve some of the basic optimisation problems that we encounter as economists. First, in chapter 2, we explore how to use
matlab to solve some of the key forward problems that we face in economics.
We use Matlab’s constrained optimisation capabilities to model the behaviour
of optimising agents given the hypotheses of utility and proﬁt maximisation. In
so doing, we encounter the key functions linprog and fmincon for the ﬁrst
time, functions that will make repeated appearences throughout this book.
We move on in chapter 3 to use Matlab’s optimisation techniques for a diﬀerent
purpose. As well as treating agents as optimising, economists must optimise
themselves to ﬁnd the parameters that provide the best possible ﬁt between
their model and the data that we have on the world. This chapter provides the
reader with a foundation in estimation by Maximum Likelihood and Generalised
Method of Moments in matlab, from which they can proceed to engage with
the more exotic models later in the book and adapt to models of their own.
With the important bases covered, it’s time to get started on the fun stuﬀ!
Section II:
Section III brings us to the realm of Revealed Preference theory. Economists
often proceed on the assumption that their model is ‘correct’ and rarely stop to
address whether this is, in fact, the case. In chapter 6, we explore how matlab
can be used to test whether an economic model is capable of explaining the
behaviour that we see in the world. We then continue in chapter 7 to address how
we can place bounds on model parameters without layering additional functional
form assumptions on top of the key hypotheses of interest. In so doing, we
provide the reader with familiarity of more advanced linear programming and
integer programming techniques that are not available in stata.
Section IV:
In many circumstances, applied researchers have little understanding of the
relationship between variables of interest. At other times, this relationship may
be too complicated to easily model with standard parametric functional forms.
To allow you to cope in such circumstances, Section V provides an introduction
to Nonparametric and Semiparametric regression in matlab. We provide a
thorough overview of kernel regression, including bandwidth and kernel choice.
6

In chapter 11, the estimation of key semiparametric models is addressed to
allow us to wriggle around the ‘Curse of Dimensionality’ and obtain easily
interpretable parameters in a multivariate setting.
Section VI:
Finally, we wish you well on your journey through this book. We hope that the
concepts and techniques we cover will open up new possibillities for you as an
applied research.

Abi, Damian & Simon

7

Part I

Foundations

8

Chapter 1

Entering the ‘Matrix
Laboratory’
Let’s start at the very beginning,
A very good place to start.

Hammerstein, “The Sound of Music”

Matlab is a computer language for doing maths. Its name is short for ‘matrix
laboratory’, and its purpose is simple: to provide a very powerful and very
ﬂexible way of solving mathematical problems. In this chapter, we will run
a series of exercises to illustrate the simplicity with which Matlab handles
matrices. This will provide a foundation for more complicated concepts and
structures that we will cover later. We recommend that you read this book with
matlab open in front of you and run the commands yourself as you encounter
them in the text. We have found learning by doing to be the best (and most
enjoyable!) way of getting to grips with new a new programming language and
econometric techniques.
In this book, we assume that you have a working knowledge of the Matlab
9

interface and can navigate your way between the diﬀerent components of the
matlab desktop. If this is your ﬁrst time opening up the programme, there are
a number of excellent books and online resources to bring you up to speed. You
can ﬁnd our personal favourites in the box below.
Introductory texts:our personal favorites.

• Duane Hanselman & Bruse Littleﬁeld, Mastering matlab: 2012 Edition,
Pearson Education Inc, 2013.
• Brian Hahn & Daniel Valentine, Essential Matlab for Engineers and Scientists, Academic Press, 2013.
• Matlab tutorials and learning resources can be found at http:
//www.mathworks.co.uk/academia/student_center/tutorials/
launchpad.html

1.1

Introduction

The simplest way to interact with Matlab is through the ‘command line’, and
this is where we will begin. The command line operates like a calculator. We
can see this by a none-too-complicated calculation:

>> 1 + 1
ans =
2

We can use the command line to create matrix variables to store our results.
Let’s start with a simple variable, y:

>> y = 1 + 1
y =
10

2

As its name suggests, Matlab is designed to deal with matrices very simply and
eﬀectively; in Matlab, we can enter any variable as a matrix, simply by using
commas to separate columns and semi-colons to separate rows. For example,
let’s create a simple 3 × 2 matrix (which we will call ‘x’), and then multiply that
matrix by two:

>> x = [1, 2; 3, 4; 5, 6]
x =
1
2
3
4
5
6
>> 2*x
ans =
2
6
10

4
8
12

We can check which matrices are stored in memory by using the commands who
(for a short summary) and whos (for a longer summary):

>> who
Your variables are:
ans x
y

>> whos
Name
ans
x
y

Size
3x2
3x2
1x1

Bytes
48
48
8

Class
double
double
double

Attributes

Matlab reports that we have three matrices in memory: ans, x and y. We
should not be surprised to see x and y in memory; we just created these matrices,
11

and we can check their contents simply by entering the matrix names at the
command line:

>> x
x =
1
3
5

2
4
6

>> y
y =
2

The matrix ans may be more confusing. This matrix stores Matlab’s most
recent answer that has not been stored in any other matrix. If we enter ans
at the command line, we will ask Matlab to recall its response to our earlier
expression ‘2*x’:

>> ans
ans =
2
6
10

4
8
12

Notice that if we enter another expression that is not assigned to any other
matrix, Matab will use ans to store this new expression:

>> 5 * 5
ans =
25
>> ans
ans =
25

12

Matlab has a very large range of mathematical operators. But our goal here
is not to provide any comprehensive discussion of these. Matlab provides
excellent help ﬁles (to say nothing of a large range of online resources), and we
don’t want to use this book to describe in detail what is available elsewhere.
For example, to learn about Matlab’s arithmetic operators, a researcher could
simply search online to ﬁnd the relevant help page. To learn the syntax of
a particular command, we could use Matlab’s extensive help documentation
from the command line:

>> help ones

Instead of discussing an ungainly list of commands and operations at this point,
we will explore diﬀerent techniques as they become relevant for our analysis of
various microeconometric models. And so we begin — with an illustration of
the most popular microeconometric technique of them all. . .

1.2

Our “Hello World”: OLS in matlab

A simple way to become familiar with the basic workings of an econometric
program is to run an Ordinary Least Squares regression. In some ways, this is
the “Hello World!” of the applied researcher. “Hello World!” is the test program
which many computer programmers run when they ﬁrst learn a language —
to discover its basic syntax, and to ensure that it is running correctly. Such
programs simply print the words “Hello World!” and then terminate.1 While the
OLS regression requires a little more work than just printing a simple statement,
it provides us with a good opportunity to work with the basic building blocks
that we have already introduced.
Almost every applied research is familiar with Stata, and almost everyone who
is familiar with Stata has, at some point or another, come across the auto.dta
dataset. This is a dataset included by default when Stata is installed, and
contains data on a series of models of cars in 1978. We will brieﬂy2 ask that you
1
2

In Matlab, such a program would be quite simple, containing just disp(‘Hello World!’).
And apologetically, for any readers expecting that this book would be based entirely on
Matlab. . .

13

open Stata and, using the auto dataset, run a regression of mileage per gallon
upon the car’s weight and price. We will denote mileage per gallon by the N × 1
vector y, and will use the N × 3 vector X to stack values of (i) price, (ii) weight,
and (iii) the number 1.
Our OLS model is, of course:
y = Xβ + ε,

(1.1)

where β is a 3 × 1 vector of parameters. We denote the OLS estimate of β as
ˆ
ˆ
β; we can ﬁnd β straightforwardly in Stata. . .

. sysuse auto
(1978 Automobile Data)
. reg mpg price weight, noheader

-----------------------------------------------------------------------------mpg |
Coef.
Std. Err.
t
P>|t|
[95% Conf. Interval]
-------------+---------------------------------------------------------------price | -.0000935
.0001627
-0.57
0.567
-.000418
.0002309
weight | -.0058175
.0006175
-9.42
0.000
-.0070489
-.0045862
_cons |
39.43966
1.621563
24.32
0.000
36.20635
42.67296
------------------------------------------------------------------------------

Let’s now write these three variables to the ﬁle auto.csv:

. outsheet mpg price weight using auto.csv, nonames comma

To run the same regression in Matlab, we ﬁrst need to import the data in
auto.csv. Before being able to import this data, we must ensure that our
current working directory contains the auto ﬁle. In order to move to this ﬁle,
we use the commands pwd (print working directory), cd (change directory) and
ls (list the contents of the current directory). After choosing the correct working

14

directory, we can import using dlmread:3

>> DataIn
>> X
>> size(X)

= dlmread('auto.csv');
= DataIn(:, 2:3);

ans =
74
>> X
>> y

2
= [X, ones(74,1)];
= DataIn(:,1);

The above block of code involves various new commands, so ensure that you
are able to run each command without problems in your Matlab window. Try
running each command without the semi-colon at the end of the line; this will
allow you to see the full output each time. The most important command is
dlmread, which allows us to read-in the data from our ﬁle auto.csv. Here we
store the entire dataset as a matrix named DataIn. Remember that if we are
interested in ensuring that auto.dta has imported correctly, we could use the
command whos(’DataIn’) to see the details.
Here we start to see how Matlab is structured around matrices. Rather than
storing data as a series of scalar variables that can be viewed in a browser,
we have stored our data as a 74 × 3 matrix, which must then be manipulated
if we are interested in working with a matrix of independent variables and a
vector for the dependent variable mpg. This is what we do in the remaining
lines of the above block of code: ﬁrst we extract our 74 × 2 matrix X, which
contains the data on price and weight, and add a vector of ones for the constant
in our model. Finally, we create the vector y. It is worth noting here that the
notation DataIn(:, 1) implies that we take data from every single row (‘:’) of
3

We encourage you to type all code displayed above in to your Matlab window manually.
If you copy and paste the above code directly, you may ﬁnd that you have trouble with
the single quote operators around ‘auto.csv’. In reality, what Matlab requires is a straight
apostrophe (which looks like this: ') around the ﬁle name. If you enter the typical single
quote operators (which look like this: ‘’) you may ﬁnd that Matlab will not allow you to
move on to the next line at the command prompt. If this happens, you can exit a given line
by pressing the control and c keys in unison.

15

column 1 in matrix DataIn. This code is also useful in illustrating precisely how
as microeconomists we are likely to deal with matrices in Matlab. Whilst the
previous section of this chapter has suggested that we can enter matrices by hand
at the command line (parsing with commas and semi-colons), it is unlikely that
this will be a frequent exercise. Generally we will either read in data directly as
a matrix (as we have done here), or will use Matlab’s matrix-based operations
to simulate data from economic models.
Now that we have two matrices (X and y) that contain the relevant data from
Stata’s auto dataset, we can run our regression. This requires little more than
introductory econometrics, namely the formula:
ˆ
β = (X X)−1 (X y).

(1.2)

Matlab’s syntax follows equation 1.2 quite closely. The only specialised function that we require is inv, which allows us to invert our X X matrix:

>> XX=X'*X;
>> Xy=X'*y;
>> beta=inv(XX)*Xy
beta =
-0.0001
-0.0058
39.4397

Here we have calculated our coeﬃcient matrix beta. You will notice that our
result is equal to those coeﬃcients which we calculated earlier in Stata.4 We
may also be interested in ensuring that beta is correct to more than four decimal
places. We can do this by changing Matlab’s output format to the long format,
(>> format long) which displays up to 15 digits for ‘double’ variables.5 Try
4

5

Note that there is nothing (except perhaps a desire for clear exposition) that stops us from
calculating β in a single step. This would look like: beta=inv(X’*X)*X’*y, or alternatively
using the functionality of Matlab’s backslash (mldivide): beta = (X’*X)\(X’*y).
We resist the temptation to dive into a tangential discussion about the diﬀerent precision
with which Matlab can store numbers. You can look this up by searching for concepts like
‘double’ and ‘single’.

16

changing the format and then printing out beta. How does this compare to
what we did earlier in Stata? (To change back to the traditional output format,
just enter format once again.)
For those of you interested in jumping ahead at this point, we refer you to
exercise (a) at the end of this chapter. This exercise provides a chance for you
to ‘get your hands dirty’ with some coding of your own. . .

1.3

The beauty of functions
Beautiful is better than ugly.
Explicit is better than implicit.
Simple is better than complex.
Complex is better than complicated.
. . . Readability counts. . .

Tim Peters, The Zen of Python

So far, our analysis has simply involved typing instructions into Matlab’s command line. This is eﬀective, but not very eﬃcient. What we need is a method
of saving commands so that we can run them later — and, if necessary, run
them many times, with diﬀerent data, diﬀerent parameters, and diﬀerent options. In Matlab, we can do this with an ‘M-ﬁle’. We enter M-ﬁles through
Matlab’s Editor window, which we can access by typing edit at the command
line. M-ﬁles are to Matlab what do-ﬁles are to Stata.
The most useful application of an M-ﬁle is to deﬁne a function.6 In Matlab,
a function is a special type of program. There are three main elements to a
funcion:

(i) Functions accept inputs.
6

We can also use an M-ﬁle to deﬁne a script, but we will not spend much time discussing
scripts.

17

(ii) Functions return outputs.
(iii) Each function is self-contained ; this means that each function can access
only those variables that are passed to it as an input, and can store variables only through returning them as outputs.7

To get to grips with functions, let us return to the OLS regression that we ran
earlier.8 A regression is a perfect candidate for a function; each OLS regression
is computationally equivalent, however the inputs and outputs for each regression will vary depending upon the name of the X and y variables that we are
interested in analysing. In this way, we may be interested in permanently having a function available that we can call to calculate regression results. This is
useful to save time when typing in commands at the command line, and to limit
careless mistakes from typing in the calculation of β many times.

Here is an example of a function that we have written, called regress. You
should be able to open this ﬁle in the Matlab editor by opening the ﬁle
regress.m.

function [beta, se] = regress(y,X)
% regress(y, X) runs an OLS regression of the n*k matrix
% of k independent variables, on the dependent variable y
% (an n*1 vector). regress returns a parameter vector of
% coefficients called beta and se.
%*** (1) Calculate the coefficients ***
beta

=

(X’*X)\(X’*y);

%*** (2) Calculate the standard errors ***
7
8

Strictly speaking, a function could save a variable to a ﬁle on the disk — but this is an
unusual exception to the rule, and not one that we will often want to use.
OLS is a useful illustration of Matlab’s basic concepts and basic functionality. But we will
leave these sorts of standard econometric applications after this chapter. In many respects,
it is much easier to implement standard estimators in Stata — and, if you would prefer to use
Matlab, there is an extensive set of functions already available through the Econometrics
Toolbox.

18

yhat
u
N
K
sigma
v_mat
se

=
=
=
=
=
=
=

X*beta;
yhat - y;
length(y);
size(X, 2);
sum(u.*u)/(N-K);
sigma * inv(X’*X);
diag(sqrt(v_mat));

% Covariance matrix
% Standard errors

return

There are a number of things worth highlighting here, either because they are
required for the code to run, or because they are good practice when writing
functions.

(i) The ﬁrst line of the function tells Matlab (a) the name of the function
(regress), the inputs to the function (y and X), and (b) the outputs from
the function (beta and se). The ﬁrst line shows the correct syntax for
this; we always start a function by some version of:
function [output] = name(inputs)
Critically, this does not mean that when we call the function regress we
must use variables named y and X. Instead, it just means that, within the
program, the variables we have introduced will be locally referred to as y
and X. This will become apparent when we run the function shortly.
(ii) There are various lines of text which immediately follow the ﬁrst line, each
of which is prefaced by the % symbol. Matlab reads the % symbol as
saying ‘skip this line’. In this way, the lines of comments can then be
thought of as an explanation (either for other users, or for ourselves in the
future) to help understanding of our code. As an added beneﬁt, those lines
of comments which directly follow the function are included as the help ﬁle
to the function. When we type >> help regress at the command line,
the output will remind us what we need to input, and what we should
expect as output.

19

(iii) The function assigns values to the matrices beta and se. These are the
names of the outputs in the ﬁrst line. This means that when the function
ﬁnishes running, it will return as outputs these assigned values.
(iv) Note that the function generally ‘looks nice’.9 In particular, note that
there are subheadings to show the main parts of the calculation, comments
(after the ‘%’ symbol) to explain the operation of several of the lines of
code, and the ‘=’ signs are tabbed to the same alignment.

Let’s use our function to repeat the regression from section 1.2. Assuming that
the ‘auto’ data from section 1.2 is still in memory (which, remember, can be
easily checked using the command who), we need simply pass this data to the
function using the syntax of regress that we have deﬁned. We can do this
from the command line10 :

>> regress(y, X)
ans =
-0.0001
-0.0058
39.4397

As explained earlier, we do not need to refer to our variable names as y and
X; these are the names that Matlab will use within the function regress, but
this does not constrain the way that we use that function. For example, let’s
create two new variables, taking the values of y and X, and run the regression
again:

>> barack = y;
9
10

Even if we say so ourselves. . .
If you don’t save the function in Matlab’s current working directory (which we can see
using the cd command), you will need to tell Matlab where the M-ﬁle can be found. This
can be done by using the addpath command. For example, if you’ve saved the function in
a folder called ‘C:/MATLABcourse/’, you should enter addpath C:/MATLABcourse. Doing
this, you’ll come across a nice time-saving feature of Matlab: tab completion. If you enter
part of the path and press the tab key, Matlab will complete the path address if only
one unique ending exists, or list all available ways the path could end if multiple endings
are possible.

20

>> hilary = X;
>> regress(barack, hilary)
ans =
-0.0001
-0.0058
39.4397

This is ﬁne if we just want to display our regression results on the screen —
but what if we want to store the results in a variable (say, OLS beta)? This is
straightforward: we simply assign the variable as in section 1.2, but have the
variable refer to a calculation using our function:

>> OLS_beta = regress(barack, hilary)
OLS_beta =
-0.0001
-0.0058
39.4397

As expected, the function regress returns the same regression results as in
section 1.2. However, if you compare the output to the deﬁnition of the function
regress, you might ask a curious question: whatever happened to the variable
se ? When we programmed the ﬁle regress.m, we speciﬁed the output as
‘[beta, se]’ — but, so far, regress has reported only beta. The reason is
that, when we ran regress, we have only asked for beta: if we call a function
from the command line, or assign the result of a function to a single variable,
Matlab will only return the ﬁrst output variable. We can recover beta and
se by assigning both of these variables jointly:

>> [OLS_beta, OLS_se] = regress(barack, hilary)
OLS_beta =
21

-0.0001
-0.0058
39.4397

OLS_se =
0.0002
0.0006
1.6216

We might even want to ask Matlab to report a horizontal concatenation of
OLS beta and OLS se, just to make things look nice:

>> [OLS_beta, OLS_se]
ans =
-0.0001
-0.0058
39.4397

0.0002
0.0006
1.6216

Hopefully, we can now start to appreciate the beauty and simplicity of functions.
Yes, it is true that functions can save us from repeating a lot of unnecessary
typing — and, yes, it is true that functions can help to avoid careless mistakes.
But the true beauty of functional programming is that we can replace a number
with the solution to a mathematical expression — and do so with a syntax that
is both simple and intuitive. For this reason, functions will be fundamental to
everything we do in the rest of this book.

22

1.4

A simple utility function

We are, of course, familiar with many types of functions from our microeconomic
theory. One particularly important building block is the utility function, which
we use to map the quantity of goods an individual consumes to his or her
payoﬀ. Needless to say, this has all the ingredients to be used in a Matlab
function: it accepts inputs (goods consumed), it returns outputs (utility), and it
is self-contained, depending entirely upon the inputs and a number of technology
parameters.
Let’s consider the Cobb-Douglas utility function. In this case our output will
be utility, u, and our inputs good 1, x1 , and good, x2 . For now, we will take a
very simple form of the Cobb-Douglas function:
1/2

u(x1 , x2 ) = x1

1/2

· x2 .

Let’s have a look at how this would be set up in Matlab.

function u = utility(x1, x2)
% Function to calculate utility given a two-good
% Cobb-Douglas specification.
u

=

(x1^0.5) * (x2^0.5);

return

Hopefully, this works well; we can conﬁrm, for example, that the function returns
correct answers for a few diﬀerent bundles. . .

>> utility(1, 4)
ans =
23

2
>> utility(3, 3)
ans =
3.0000

Of course, we rarely want to use Matlab merely to calculate a single number.
We need an elegant way of dealing with multiple possible combinations of x1
and x2 . Suppose that, for some reason, we want to ﬁnd utility for x1 = 5 and
x2 ∈ {1, . . . , 10}. Let’s create a vector x1 and a scalar x2 to represent this:

x1
x2

= [1:10]';
= 5;

We now have ten combinations of (x1 , x2 ) for which we need to ﬁnd u(x1 , x2 ).
We could have utility operate ten separate times — for example, using a
loop.11 But this is very ineﬃcient. Instead, we should have utility run once,
and operate on the entire matrix x1. This is known as vectorising. Having
deﬁned x1 and x2, we should be able simply to enter:

utility(x1, x2)

But we have a problem! Look again at the function utility. As written, the
function works perfectly well for scalars x1 and x2, but doesn’t work for vectors (or, more generally, for matrices). This is because the operators used there
— the power operator and the multiplication operator — are understood by
Matlab to refer to matrices. We managed to get the correct answers when entering two scalars (for example, when we calculated utility(1, 4)), because
the scalar/matrix distinction did not matter in this simple case. But our function doesn’t work for the more general case.
11

We will introduce loops in Chapter 3.

24

Fortunately, Matlab has an elegant solution: we can modify both the power
operator and the multiplication operator so they work ‘element-by-element’.
For both the power operator and the multiplication operator, we can do this by
introducing a leading ‘.’. Let’s go back and ﬁx our function to allow for this. . .

function u = utility(x1, x2)
% Function to calculate utility given a two-good
% Cobb-Douglas specification.
u

=

(x1.^0.5) .* (x2.^0.5);

return

We now have a utility function that is correctly deﬁned for matrices. This is
very powerful — among other advantages, we can now visualise our function
very eﬃciently. Let’s suppose that we want to see how our function behaves for
(x1 , x2 ) ∈ [0, 3] × [0, 3]. We can create a meshgrid to cover this two dimensional
space (discretised on unit intervals):

>> [x1, x2] = meshgrid([0:3], [0:3])
x1 =
0
0
0
0

1
1
1
1

2
2
2
2

3
3
3
3

0
1
2

0
1
2

0
1
2

0
1
2

x2 =

25

3

3

3

3

Hopefully, it is clear what is going on here: we have deﬁned a matrix x1 and a
matrix x2 such that x1 and x2 cover the grid {0, 1, 2, 3} × {0, 1, 2, 3}. With a
single operation, we can now calculate utility for this entire grid:

>> u

= utility(x1, x2)

u =
0
0
0
0

0
1.0000
1.4142
1.7321

0
1.4142
2.0000
2.4495

0
1.7321
2.4495
3.0000

We can then visualise this with the ‘surfc’ command:

>> surfc(x1, x2, u)

Of course, we would really like to visualise this over a ﬁner grid. This is easy
using meshgrid:

[x1, x2]
= meshgrid([0:.1:3], [0:.1:3]);
u
= utility(x1, x2);
surfc(x1, x2, u)

As you will see in ﬁgures 1.1(a) and 1.1(b), the diﬀerence is quite stark, although
the complexity in coding each example is virtually identical once we have set up
our function. We hope that this is something which holds throughout much of
this book: while some things may seem initially quite simple, the basic methods
presented here can be generalised to solve and visualise functions of arbitrary
complexity. We will consider a more complicated function in the exercises that
follow.
26

3

3

2.5

2.5

2

2

1.5

1.5

1

1

0.5

0.5

0
3

0
3
3

2

3

2

2
1

Quantity of Good x1

2
1

1
0

0

Quantity of Good x1

Quantity of Good x2

(a) Rough Mesh Grid

1
0

0

Quantity of Good x2

(b) Fine Mesh Grid

Figure 1.1: Cobb-Douglas Utility

1.5

Review and exercises

command

brief description

whos
help
lookfor
ones
cd
ls
pwd
dlmread
disp
inv
size
format
mldivide
function
addpath

Describes variables currently in memory
Describes a function along with its syntax
Searches all M-ﬁles (including help ﬁles) for a keyword
Creates an array of ones
changes current working directory
Lists content of current working directory
Prints the location of the current working directory
reads in a comma-separated values ﬁle
Prints text to the output window
Inverts a matrix
Displays the size of an array
Sets the format of the output
An eﬃcient way to solve matrix division
Deﬁne a function which can be called from the command line
Adds a directory to the places Matlab searches when a command is called
Replicates vectors to form a rectangular matrix
Draws a three-dimensional surface plot

meshgrid
surfc

Table 1.1: Chapter 1 commands

27

Exercises
(a). We have used Matlab to recreate Stata’s point estimates in a regression
function. Can you now generate the same standard errors? We suggest you
try this exercise before looking at the regress function in section ??, or skip to
exercise (b) if you’ve already worked through this section carefully.
(b). Suppose that we want to generalise our utility function slightly, so that we
have:
(1−α)
.
u(x1 , x2 , α) = xα · x2
1

Create a new function, utility2.m, to accommodate this. Check that
utility2.m matches the behaviour of utility.m for the special case α = 0.5.
Repeat the visualisation exercise. How does variation in α change the shape of
u?
(c). Suppose that a consumer has a utility function of the form:
u(x) = − exp(−r · x).
Suppose that x is drawn from a Normal distribution with mean µ and variance
σ 2 (that is, µ ∼ N µ, σ 2 ). An insurance company oﬀers the consumer a
product with a guaranteed lower limit, g. In eﬀect, the insurance company
says, “If you buy our product and x < g, we will pay the diﬀerence, so you will
get g. If you buy our product and x > g, we will do nothing, so you will just
keep x.”.
(i) Interpret the paramter r.
(ii) What is the certainty equivalent if there is no insurance product?
To answer this question, you may rely on the following result (which applies for this special ‘exponential-normal’ case):
E (u) = − exp

28

1 2 2
·σ ·r −µ·r .
2

(1.3)

(iii) What is the expected utilty with the insurance product? (Assume that
the insurance company provides the product for free.)
To answer this question, you may rely on the following result (which,
again, applies just for this special ‘exponential-normal’ case):
E (u | x > g) = − exp
where a =

1 2 2
1 − Φ(a + σ · r)
·σ ·r −µ·r ·
,
2
1 − Φ(a)

(1.4)

g−µ
, and Φ(·) is the cdf of the Normal.
σ

(iv) (For Matlab. . . ) Assume now that µ = 0 and σ 2 = 1. Deﬁne s(g, r) as
the consumer’s surplus — in utility terms — from having the insurance
product. Show the function s(g, r) for (g, r) ∈ (−3, 3) × (0, 1.5).

29

Chapter 2

Optimisation I: The Agent
Optimises
Mason: Are you sure you’re ready for this?
Goodspeed: I’ll do my best.
Mason: Your best?!

The Rock

Now the fun begins. Constrained optimisation is a fundamental tool of economists.
As Lazear (2000) put it:

Even when evidence suggests that the theories are wrong, we do
not drop the assumption of maximisation. Instead, our approach
is to think more carefully about the nature of the model set up,
but not about the rationality of the individuals making the choices.
Economists are rarely willing to assume that individuals simply do
not know what they are doing.

30

Essentially, there are two ways that optimisation matters for economists:

(i) We treat agents as optimising — for example, we model consumers as
maximising utility, ﬁrms as maximising proﬁts, and so on.
(ii) We need to use optimisation ourselves, in order to ﬁnd the best possible
ﬁt for our model (where ‘best’ is deﬁned by some particular objective
function).

In many respects, these two concepts are fundamentally diﬀerent. On the one
hand, we treat agents as if they optimise, as a way of specifying a model. On
the other hand, we actually optimise, as a way of estimating our model. We
should always keep these two concepts distinct in our minds. Yet each concept
involves an optimisation problem — and the principles and methods that we
use for the two problems are remarkably similar.
In this chapter, we will consider the ﬁrst of these cases—the optimising agent.
We will here use matlab to solve some of the common‘forward problems’ that
we encounter in microeconomics. That is, we will learn how to solve for the
optimal solutions of some core economic models and thereby discover the best
actions for an optimising agent.

2.1

Proﬁt maximisation and linear programming

Cast your mind back to your ﬁrst term studying economics. It is highly likely
that at some point you were asked to solve a question similar to the following:
given output prices, the cost of inputs and any capacity constraints, what levels
of inputs should the ﬁrm select in order to maxmise proﬁt? Let us brieﬂy regress
back to this level to introduce some key Matlab tools that we will use to solve
more complicated models at later stages of this book.
Before starting with our example, a brief word is needed on the structure of
the proﬁt maximisation problem that we will solve. Many of the optimisation
problems that we encounter in economics are formally called ‘linear program31

ming problems’; they involve selecting the values of a set of choice variables to
optimise some linear objective function subject to a set of linear constraints.
The general formulation of a linear programming problem is:

min f (x)
x

such that =





Ax
Aeqx


lb

≤
=
≤x≤

b
beq
ub

(2.1)

where x represents the vector of variables whose value is to be decided upon,
f ,b and beq are vectors of known coeﬃcients and A and Aeq are matrices of
known coeﬃcients. lb and ub denote the lower and upper bounds on the choice
variable.
We will use the in-built matlab function linprog to solve linear programming
problems of this type. The basic linprog syntax is:

[x, fval, exitflag] = linprog(f, A, b, Aeq, beq, lb, ub, x0, options)

linprog is a normal function, just like those we considered in chapter 1. We
supply it with a series of inputs and in return are supplied with the outputs:
[x, fval, exitflag]. The inputs f, A, b, Aeq, beq, lb, ub are deﬁned
as in equation 2.1. x0 is an optional starting guess for the choice variables and
options deﬁnes any changes that you want to make to the default optimisation
options that Matlab uses.
The outputs we recieve are: x, the optimal solution to the linear programming problem; fval, the value of the objective function at the optimal x and
exitflag, an indicator variable that returns information about the optimisation
procedure, i.e. whether a local minimum was reached or whether the problem
is infeasible or was not solved adequately.
To get to grips with linprog, let’s get our hands dirty and solve a simple proﬁt
maxmisation example from Econ 101. Suppose a farmer has 75 acres to plant
up with crops. She must decide how much land to devote to crop a, wheat,
and how much to devote to crop b, corn. Our farmer operates in a perfectly
competitive market, in which wheat commands a higher price than corn. In

32

fact, the farmer’s revenue function takes the form:
R(a, b) = 143a + 60b

(2.2)

If the farmer was unconstrained, she would devote all the space to growing crop
a. However, things are not so simple. Crop a requires more storage space than
crop b and the number of stroage units that the farmer has at her disposal is
constrained at 4, 000.
110a + 30b ≤ 4000
(2.3)
Furthermore, crop a requires greater care, and thus higher maintenance costs
than crop b. Our farmer is credit constrained and only has 15, 000 to spend on
her inital outlay of crops.
120a + 210b ≤ 15000

(2.4)

Let us use Matlab to answer the following:

(i) How many acres should she devote to crop x?
(ii) How many acres should she devote to crop y?
(iii) What will her revenues be?

First, the choice variables are a and b. Therefore, our vector of choice variables,
x, that matlab will manipulate to maximise the objective function is structured
as:
a
x=
(2.5)
b

Now, turing to the objective function: the farmer wants to maximise R(a, b).
However, linprog works to minimise the objective function. Therefore, the f
vector takes the form:

f = [-143; -60];

33

There are three inequality constraints that must be respected: there are only
75 acres of space available, a limited amount of storage space and the farmer
faces a capacity constraint. These are captured by the A matrix and b vector:

% objective function and constraint matrices
>> A = [1 1;110 30;120 210]
A =
1
110
120

1
30
210

>> b = [75; 4000; 15000]
b =
75
4000
15000

The ﬁnal constraints concern the lower and upper bounds on the choice variable.
We cannot plant a negative acerage of crops and, in principle, with no other
contraints could plant an inﬁnite acerage. Thus,

lb = zeros(2,1);
ub = Inf(2,1);

We now have all of the elements of the linear programme expressed in matlab.
We will ignore a starting value, x0, and keep to the default optimisation options
for now. All that there is left to do is solve the problem. We do so as follows....

[crops, obj, exitflag] = linprog(f, A, b, [],[], lb, ub);

34

What we have done here is call linprog with our linear objective function and
inequality constraints, followed ﬁnally by the upper and lower bounds on the
acerage of each crop. You may be wondering why we have included the two
empty matrices [] in our code. In this problem, we do not have any strict
equality constraints to worry about but want to deﬁne lower and upper bounds
on the choice variables. Therefore, we must declare the equality constraint
arrays as empty.
Having passed all of this to Matlab, it returns to us the optimal choice of crop
a and b in the result vector crops, the value of the objective function in obj
and ﬁnally the exitflag indicator. The value for the objective function (obj)
needs relatively little explanation, beyond pointing out that, as expected, it is
the negative of R(a, b). We will, however, want to consider the exit ﬂag quite
carefully (both in this explanation, and more generally whenever we optimise in
Matlab) as this tells us about the status of the optimisation problem when the
solution was found. As is often the case, Matlab’s help ﬁle oﬀers some useful
information here (as always). The ﬁle for linprog lists all possible exitﬂags, and
the reason why the optimisation routine terminates in each case. An exitﬂag of
1 is returned when the function has converged to a solution. Weakly negative
values of the exit ﬂag correspond to infeasible problems or those that have
terminated before the function has converged.

% print solution
optimal = (exitflag == 1);
disp('Optimal solution found?')
if (optimal == 1)
disp('Yes!');
disp(['Optimal planting of crop a is' num2str(crops(1))]);
disp(['Optimal planting of crop b is' num2str(crops(2))]);
disp(['Maximised revenue is' num2str(-obj)]);
else
disp('No');
end

35

This ﬁnal part of code displays the solution output. Using matlab’s logical
functionality, we deﬁne a constant optimal to tell us whether the optimisation
problem solved successfully. Logicals in matlab are represented by 1 for ‘true’
and 0 for ‘false’ and are deﬁned by the comparison operators:

(i) Equal to: ==
(ii) Not equal to: =
(iii) Smaller than/Greater than: </>
(iv) Smaller than or equal to/Greater than or equal to: <=/>=

Thus, optimal equals 1 if the function converged and 0 otherwise.
This section of code also brings us our ﬁrst example of a conditional statement
in matlab. If the statement (optimal == 1) evaluates as true, then the string
Yes! and the solution output is printed, else No is printed. To print the output
we make use of the disp command, which can be used with num2str to convert
numbers into strings for display. Note the negative sign in front of obj, which
is there because we minimise the negative of the revenue function.

2.2

Utility maximisation and non-linear optimisation

Many of the optimisation problems that economists are concerned with are not
linear and thus cannot be solved using linprog. For example, the utility maximising consumer that we met in the last chapter selected her optimal quantities
to maximise her non-linear Cobb Douglas utility function. We return to this
example to introduce a central element of Matlab’s optimisation routines: the
fmincon command. This is a very powerful f unction for minimisation subject
to constraints which we suspect you will encounter frequently in your Matlab
programming. Indeed, in this book we will return to it many times given its
ﬂexibility and power.

36

The fmincon command is used to solve optimisation problems with the structure:

 c(x) ≤ b



 ceq(x) = beq


min f (x) such that =
(2.6)
Ax ≤ b
x



 Aeqx = beq


 lb ≤ x ≤ ub
This has a more general structure to the linear programming problems that we
considered above: the objective function f (x) is not neccessarily linear and, in
addition to the linear constraints, we now allow for the non-linear constraints
c(x) and c(x).
The basic fmincon syntax is then....

[x, fval, exitflag] = linprog(fun, x0, A, b, Aeq, beq, lb, ub, nonlcon, options)

Unlike linprog, fmincon requires us to specify an initial guess x0 from which
it attempts to ﬁnd the vector of choice variables x that minimises the objective function fun subject to the user-speciﬁed constraints. Any non-linear constraints are deﬁned by the function nonlcon.
Let’s put fmincon to work by returning to our utility maximisation example!
As in the previous chapter, we’ll assume that the consumer’s utility function is
1/2 1/2
U = x1 x2 , so that her maximisation problem is:
1/2 1/2

max x1 x2

x1 ,x2

subject to

I = p1 x1 + p2 x2 .

(2.7)

Fortunately, we’ve already deﬁned this function in our utility.m code. Graphically, we are interested in ﬁnding how the consumer can optimally maximise the
utility presented in ﬁgure 1.1(b). This utility comes entirely from the quantities
of each good consumed (displayed on the x- and y-axes), and is calculated on
the z-axis. Of course, were the consumer not subjected to some binding budget
constraint she would consume the maximum amount of both goods and arrive
at the maximum utility of 3 units (which corresponds to the red portion of the
37

ﬁgure).
Before continuing to deﬁne the budget constraint, we must make two slight ammendments to utility.m so that it is easy to use with fmincon. fmincon works
by adjusting a single vector of variables x but utility.m, as it was deﬁned in
chapter 1, takes two arguments, the quantity of each good consumed:
function u = utility(x1,x2).
Therefore, we ammend the function to accept a single vector of quantities that
we then simply ‘unpack’ into its individual elements, as you can see in the ﬁrst
two lines of the new function below. Second, you will also note that on the last
line of our new function we take the negative of utility. This is nothing more
than a computational requirement arising because Matlab’s optimisations are
based on minimisation, and so in cases where we actually want to max imise we
simply reverse the sign of the ﬁnal value.

function u = cobbdouglas(X)
% Function to calculate utility given a Cobb-Douglas specif% ication and varying the quantites of goods consumed (vector
% X requires two goods).
x1
x2
u

=
=
=

X(1);
X(2);
-(x1^0.5)*(x2^0.5);

return

Now that we have written the (non-linear) function that we will ask Matlab
to minimise, we can go about the business of building our constraints and optimising! Let’s imagine that our consumer has a total income of $100, faces goods
prices of $4 and $7, and our initial guess is that she would consume 15 and 5
units respectively.1
1

It is not particularly important that the starting point respects the income constraint, as
Matlab will deal with that once optimisation begins.

38

>>
>>
>>
>>
>>

I
P
G
lb
ub

=
=
=
=
=

100;
[4,7];
[15,5];
[0,0];
[25,100/7];

Here we have introduced the right side of our budget constraint (the prices) as
P, the left side as I, our initial guess as G, and an upper and lower bound for the
consumption of each good (ub and lb respectively).2 Now, let’s see how this all
comes together with the fmincon command:

>> [consumption, u, exitflag] = fmincon(@cobbdouglas,G,P,I,[],...
[],lb,ub)
consumption =
12.5024

7.1415

u =
-9.4491

exitflag =
5

What we have done here is call fmincon with our constraints and inital guess
as parameters; ﬁrst the function name (that is declared to be a function using
the @ symbol), second our initial guess, then the left-hand side of the inequality
2

If we were intersted in checking whether our initial values satisfy the constraint we could
check if P G < I. In Matlab:
>> P’*G<I
ans =
1
implying that it does satisfy the constraint.

39

constraint3 , followed by the right-hand side of the inequality constraint, and
ﬁnally the upper and lower bounds we have deﬁned for consumption of each
good. Having passed all this to Matlab, it returns to us the consumption
values associated with minimisation of the objective function: 12.50 units of x1
and 7.14 units of x2 .
Given that we are now dealing with a non-linear objective function (and in
other applications, possibly constraints), matlab can only guarantee that a
local minimum has been found. For this reason, exitflag can take diﬀerent
values with fmincon when compared to linprog. The ﬁle for fmincon lists all
possible exitﬂags, and the reason why the optimisation routine terminates in
each case. We see that an exitﬂag of 5 is returned when the derivative at the
ﬁnal point was arbitrarily small. However, we can never be entirely sure that
this corresponds to a local minimum. Perhaps if we were to search over a ﬁner
set of points, Matlab would actually be able to ﬁnd a smaller value for the
objective function. Similarly, it may help Matlab if we were to provide an
analytical expression for the Jacobian.4
Fortunately, Matlab allows us great control over how we actually optimise. If
not instructed otherwise Matlab will use its best judgement when determining
how to optimise (as it did above). However, should we decide to, we can specify
many of our own criteria in optimisation. For example, we can ask Matlab
to use a particular algorithm, set the value that the gradient must take at the
‘optimum’, control the step size of the search path, and so forth. All of this is
controlled using the optimset command. Typing optimset at the command
line lists many options, and the default values Matlab assumes when using
fmincon.
To illustrate how we can change the default optimisation options and what
this does to our result, let’s consider make just one change to request that the
state-of-the-art sequential quadratic programming algorithm be used to solve
the problem:
3

4

Note that here we treat the income constraint as non-binding, although generally it always
will. An individual could choose to spend less than all their income, although the form
of the Cobb-Douglas utility function implies that maximisation of utility is achieved by
spending all income on consumption.
This often requires great cost — both in terms of time and emotion — to the programmer.

40

>> opts = optimset('algorithm', 'sqp');
>> [consumption,u,exitflag] = fmincon(@cobbdouglas,G,P,I,...
[],[],lb,ub,[],opts)
consumption =
12.5000

7.1429

u =
-9.4491

exitflag =
1

In order to do this we deﬁne opts that contains our speciﬁc optimisation speciﬁcations. This is passed to fmincon as the tenth argument, leaving another empty
matrix in the ninth position because we do not have any non-linear constraints.
As a result of using this algorithm, we see a small change in our consumption
values, and that now we are returned an exitﬂag of 1. Again referring to the help
ﬁle, this implies that ﬁrst order and constraint conditions are satisﬁed within
the tolerance required, and that there is a “[l]ocal minimum found that satisﬁes
the constraints.” This is a reasonably satisfying result, and subsequent tests
from this starting point suggest that no further improvements are found.5 Usually, ‘exitflag = 2’ is a reasonable sign of success — though, as the previous
discussion indicates, deciding on convergence criteria is often more a matter of
art than science.
Although the fmincon syntax can become somewhat involved (though fortunately never too much more involved than this previous example!), the problem
that we are optimising likely seems quite simple, and perhaps you are left won5

That is to say, if we substitute our optimal values back into fmincon as a new starting point,
no further improvement can be found.

41

dering why we would even bother to do something like this in Matlab. This
is admittedly a very simple function — but simple functions are useful building
blocks for more complicated analysis. Let’s imagine for example that we wanted
to nest utility maximisation inside a more extensive model. This would then
involve deﬁning a (potentially much) more complex function, which calls our
simple Cobb-Douglas maximisation technique. Below we provide an example of
such a function which is built around our previously deﬁned function:

function [u,c] = budget(P,I,X)
%Budget presents the budget constraint faced by an individual,
%and calculates their optimal consumption based upon a Cobb%Douglas utility function defined in the function utility.m
%
%The syntax of the function is budget(P,I,X) and the function
%accepts as arguments a 2*N vector of prices, P, the total inc%ome, I, and the initial guess used in the fmincon command, X.
%
%see also fmincon
%**************************************************************
%*** (1) Unpack relevant parameters from function call
%**************************************************************
p1 =
P(1);
p2 =
P(2);
lb =
[0,0];
ub =
[I/p1,I/p2];
%**************************************************************
%*** (2) Determine utility maximising consumption
%**************************************************************
[c, u] =
fmincon(@cobbdouglas,X,P,I,[],[],lb,ub);
%**************************************************************
%*** (3) Create graphical output
%**************************************************************
x2 =
0:I/p2;
% all possible values of x2
x1 =
(I-p2.*x2)./p1;
% values of x1 corresponding to x2

42

fig =
plot(x1,x2,’LineWidth’,2);
hold on
x1 =
u.^2./x2;
%calculate utility everywhere
axis([0,I/p1,0,I/p2]);
%set axes
plot(x1,x2, ’color’,’r’,’LineWidth’,2)
xlabel(’quantity of good x_1’, ’FontSize’, 14);
ylabel(’quantity of good x_2’, ’FontSize’, 14);
title(’Cobb-Douglas Utility Maximisation’, ’FontSize’,16);
return

Here you will see that we are dealing with a function “budget” which lets
us calculate all possible points on a budget constraint for any set of incomes
and prices {I, x1 , x2 }, and also plots the utility function of the consumer which
corresponds to utility maximisation. Whilst we haven’t introduced a great many
new commands in this example, there are a number of complex elements which
are worth examining (and changing when you run this in your Matlab session).
Finally, let’s try out this command and see what we get.
>>
>>
>>
>>

P=[100,200];
I=10000;
X=[40,20];
budget(P,I,X);

We see that as well as our output from the utility optimisation we get a plot
of the consumer’s budget constraint and the appropriate utility function (ﬁgure
2.1).

43

Cobb−Douglas Utility Maximisation
50

45

40

quantity of good x2

35

30

25

20

15

10

5

0

0

10

20

30

40

50

60

70

80

90

100

quantity of good x1

Figure 2.1: Single utility curve and budget constraint

2.3

Simulating heterogeneity

At its core, microeconometrics is about respecting heterogeneity. If everyone
faced the same set of choices, with the same constraints, and had the same
preferences, then we would all behave in the same way and there would be
little advantage to collecting any dataset greater than N = 1. In many standard econometric models, we allow heterogeneity to enter through an additively
separable ‘error’ term. Of course, there is nothing inherently wrong with this
approach — but we may want to explore the consequences of introducing random variation in other parts of a model. We end this chapter with a simple
illustration of how we might do this in Matlab.
Matlab oﬀers us a wide range of tools to consider drawing random numbers
from the speciﬁc distributions which are likely to underlie our Monte Carlo
Simulations. Table 2.1 lists a number of these distributions, and their associated
Matlab commands:
44

Table 2.1: Random Number Generators

Distribution

Command

uniform
normal
lognormal
multivariate normal distribution
many others...

rand()
randn()
lognrnd()
mvnrnd()
random(distbn,)

It is sometimes argued — particularly in development economics — that diﬀerent economic actors face diﬀerent prices, based on their individual characteristics. (For example, information asymmetries may lead diﬀerent ﬁrms to face
diﬀerent factor costs.) Suppose, then, that we maintain our earlier model of
a consumer with Cobb-Douglas utility. However, suppose that we now assume
that, across the population, consumers face uniform variation in the price of
good 1:
p1 ∼ U (100, 150).

(2.8)

Suppose that we are interested in characterising the resulting distribution of
consumption bundles. Given the tools that we have discussed, this is easy. The
following script shows a simple illustration of how this can be done. We leave it
to you to step through the script to understand how it works; in the exercises
that follow, we suggest two extensions.
%************************************************************
%*** (1) Setup, simulation of random variation
%************************************************************
clear
rng(1)
reps
= 100;
pshock

= [rand(reps, 1) * 50, zeros(reps, 1)];

I
P
x0

= 10000;
= [50, 200];
= [1, 1];

45

lb

= [0, 0];

c
opts

= NaN(reps, 2);
= optimset(’algorithm’, ’sqp’, ’display’, ’off’);

%************************************************************
%*** (2) Determine optimal consumption in each case
%************************************************************
for count = 1:reps
TempP
= P + pshock(count, :);
ub
= I./TempP;
c(count, :) =
fmincon(@cobbdouglas,[1, 1], TempP, ...
I,[],[],lb,ub, [], opts);
end
%************************************************************
%*** (3) Visualise results
%************************************************************
subplot(1,2,1)
scatter(c(:, 1), c(:, 2))
axis([min(c(:,1))-5, max(c(:,1))+5, ...
min(c(:,2))-5, max(c(:,2))+5]);
xlabel(’Good 1 Consumption’)
ylabel(’Good 2 Consumption’)
subplot(1,2,1)
cdfplot(c(:, 1))
xlabel(’Good 1 Consumption’)
ylabel(’F(p_1)’)
return

46

Empirical CDF
1

0.8

27

0.7

26

0.6
F(p1)

0.9

28

Good 2 Consumption

29

25

0.5

24

0.4

23

0.3

22

0.2

21

0.1

20

30

35

40
45
Good 1 Consumption

0
30

50

35
40
45
Good 1 Consumption

Figure 2.2: Incorporating heterogeneity in Cobb-Douglas utility maximisation

47

50

2.4

Review and Exercises

command

brief description

axis
cdfplot
disp
fmincon

Set minimum and maximum for graph axes
Draws the empirical CDF of a vector
Print contents of an array
Routine to minimise an objective function subject to linear or
nonlinear constraints
Repeats a command or series of commands a speciﬁed number
of times
Keep current plot in graph window, and add another plot to
the output
Evalutes an expression and executes a group of statements if
it is true
Create an array of inﬁnite values
Routine to minimise a linear objective function subject to linear constraints
Pre-ﬁlls a matrix with ‘empty’ values
Convert number to string
Create an array of ones
Provides control over the optimisation process in Matlab
Draw a two-dimensional graph
Allows for a (pseudo-)random draw from a uniform(0,1) distribution
Allows for a (pseudo-)random draw from a normal distribution
Sets Matlab’s psuedo random number generator at a replicable point
Allows for multiple graphs on the same plot window
Bivariate scatter plot
Add a title to the plot window
A
Label x-axis in the plot window (allows for L TEX style parsing)

for
hold on
if
Inf
linprog
NaN
num2str
ones
optimset
plot
rand
randn
rng
subplot
scatter
title
xlabel

Table 2.2: Chapter 2 commands

48

Exercises
(i) Using our Cobb-Douglas utility function, simulate variation in income.
Use simulated results to plot Engel curves for x1 and x2 .
(ii) Using our Cobb-Douglas example, suppose that consumers with higher
income also tend to face lower costs for good x1 . Show how a simulation
method could be used to think about consumption bundles in this case.
(Hint: mvnrnd may be useful. . . )
(iii) A ﬁsherwoman must decide how many salmon and how many trout to
catch. She can sell a salmon for £12 but can only sell a trout for £7.
However, salmon requires twice as much storage spaceas trout and she
only has rrom for 1000 trout on her boat. Further, there is a quote
limiting the numbers of ﬁsh she can catch. She may only catch 1600
tokens worth of ﬁsh, where each salmon is worth 3 tokens and a trout
only 2 tokens.

(a) Use linear programming techniques to determine how many salmon
and how many trout the ﬁsherwoman should catch.
(b) How does the solution vary with the price of trout?

49

Chapter 3

Optimisation II: The
Economist Optimises
Inability to perceive one’s own loss function can have disastrous
personal consequences.

Edwin Jaynes

OR...

Announcer: Professor Sargent, can you tell me what CD rates will
be in two years?
Sargent: No.

Predictions

Unfortunately, economists are not omniscient beings. We do not know what
values the parameters of our theoretical models take and cannot directly observe
50

them in the data we have on the world. Instead, we have to estimate them. This
is technically called solving the ‘inverse problem’. However, it is important to
stress that before we can estimate any parameters, we require a model that is
capable of predicting the data we see. Therefore, you should never see estimation
as divorced from the underlying model.
Just as optimisation is the central mechanism in economic models of behaviour,
so it is to the estimation of the parameters of our models. We economists are
looking for the parameters that provide the optimal ‘ﬁt’ between the data and
model. In this chapter, we will explore how you can use Matlab’s constrained
optimisation techniques to estimate model parameters by Maximum Likelihood
and Generalised Method of Moments methods. The examples in this chapter
are admittedly simple but will provide you with a strong base from which you
can proceed to engage with the more exotic models later in this book and also
adapt to models of their own.

3.1

Maximising Likelihoods

When using maximum likelihood estimation, we ﬁnd the set of parameter values,
which given a particular model, were most likely to have generated the data that
we have to hand. In chapter 1, we showed how OLS regression estimates can be
determined by inverting matrices. We can use maximum likelihood estimation
for the same purpose. Therefore, let’s return to the OLS example of chapter 1
to provide an introduction to maximum likelihood in Matlab.
As is likely laid out in your favourite econometrics text, the log-likelihood associated with the classical regression model looks like this:
L(β, σ 2 ; y | x)
=−

N
2

ln 2π −

N
2

ln σ 2 −

1
2σ 2

(y − βx) (y − βx)

The set of maximum likelihood parameters is then the β , σ 2
maximises the log-likelihood function.

51

(3.1)

vector that

This is all well and good but how do we actually maximise something like
equation 3.1 in Matlab? Fortunately, given our work in chapter 2, you’ll
remember that we can combine Matlab’s optimisation routines with our own
functions. We can tell Matlab to ﬁnd the highest value of functions that we
deﬁne by varying the values of the input parameters using routines such as
fmincon, one of the functions introduced in the last chapter. In the above case
this implies ﬁnding the highest value for L, by searching over combinations of
the parameters β and σ 2 .
Thus, as always, the maximisation process begins by converting our objective
function into a Matlab function. As we alluded to earlier, it is convenient to
optimise over a single vector, rather than over two separate objects — so we
deﬁne θ = β , σ 2 , and optimise in terms of θ:

function[ML] = normalML(theta,y,x)
% NormalML(theta,y,x) calculates the likelihood function given
% a matrix of covariates x and a dependent variable y with an
% unobserved stochastic error term which is distributed accor% ding to a normal distribution.
%
% The likelihood function is evaluated at the coefficients
% theta, which must be specified by the user. These should
% include as many coefficients as are to be estimated in the
% model, and finally an estimate of sigma.
%
% See also mle
%**************************************************************
%*** (1) Form stats
%**************************************************************
N
=
length(y);
K
=
size(x,2);
sig =
theta(K+1);
beta =
theta(1:K);
u
=
y - x*beta’;
%**************************************************************

52

%*** (2) Likelihood function
%**************************************************************
ML
= -(N/2)*log(2*pi)-(N/2)*log(sig^2)-(1/(2*sig^2))*(u’*u);
ML
= - ML
return

The penultimate line of this code looks remarkably similar to (3.1). The remainder of the code just consists of determining a number of other parameters
(such as N ) based on the data in question. Once again you’ll notice in the
code that we are reversing the sign of our maximum likelihood value given that
Matlab’s optimisations are based on minimisation.
Once we’ve deﬁned our objective function in this way, we can return to Matlab’s clever range of solvers to determine the optimal value. This can be considered as a constrained optimisation problem (after all, σ 2 > 0), and hence
Matlab’s fmincon command should be used. To do this, we’ll return to our
parameter estimates from section 1.2. There we had deﬁned a matrix X and a
vector y which had come from the trusty auto dataset. We’ll ask you to re-enter
or recall these matrices (perhaps they are still in Matlab’s working memory,
in which case you need do nothing), and we’ll use this data to see whether our
likelihood function allows us to recover the regression estimates we calculated
in the previous chapter.
In the case of this problem, there is no clear upper and lower bound that we
necessarily want to impose on our parameters, but we’ll deﬁne some values
to limit the domain over which Matlab searches.1 Here we are going to be
ˆ
estimating four parameters which correspond to the three β’s, along with σ 2 .
ˆ
We’ll set up the following lower and upper bounds for each of these parameters:

>> lb
1

= [-1000, -1000, -1000, 0];

Matlab also has a function for unconstrained optimisation: fminunc. But as we suggested
above, our problem is constrained, because we have σ 2 > 0. Further, even if our problem
were not constrained by economic or econometric theory, it may still be useful to use
fmincon, and to impose some bound constraints on ‘reasonable’ values of the parameter
space.

53

>> ub

= [1000, 1000, 1000, 100];

We’ll also deﬁne an initial range of values from which Matlab should begin its
search. Although we have quite a good idea of what these parameters should
look like from our regression in chapter 1, we’ll pretend this isn’t the case, and
be reasonably agnostic with our initial choice:

>> theta0

= [0, 0, 0, 1];

Finally, we want to deﬁne a number of optimisation options. So far we have only
just scratched the surface of the optimset options for fmincon. Previously we
had decided to use the sqp algorithm, and let Matlab decide on all the other
values. Below we deﬁne a few of more of these options (as a reminder, the full
list of options can be seen by typing optimset in your Matlab window).

>> opt = optimset(`TolFun',1E-20,`TolX',1E-20,`MaxFunEvals',1000);

Here we have allowed Matlab to keep running until subsequent changes in the
objective function and the optimands are very tiny (10−20 ) and at the same
time allow it to evaluate the objective function a suﬃcient number of times to
ﬁnd an answer. Together these options should allow for a very precise solution
for the values θ.
So, now we have all our ingredients; we’ve deﬁned an objective function, the
constraints, the starting point, and the optimisation options. With all of this,
it’s now just a matter of letting Matlab get to work! We issue the fmincon
command below:

>> fmincon(@(theta)normalML(theta,y,X), theta0, [], ...
[], [], [], lb, ub, [], opt);

We agree that this looks a little bit complicated. It is, however, about as
involved as a typical Matlab command is ever going to get. You’ll note that
54

at its heart it is just a call to fmincon as in chapter 2, and we’ve included all
the parts we’ve just deﬁned above (the starting point theta0, the upper and
lower bounds, and the optimisation options opt).
The only additional tricky part is in deciphering the ﬁrst argument which starts
with the @ symbol. In Matlab parlance this is known as a “function handle”, however this is essentially little more than the name of our function,
and an indicator of which parts of the function we are maximising over. The
normalML(theta,y,X) part of this argument just says that we use the function
normalML and the data y and X which we deﬁned above,2 while the @(theta)
part says that we are maximising over theta. The remainder of the arguments
are simply made up of empty braces. As we discussed earlier, these empty matrices are essentially place holders for elements (like strict equality constraints)
which are not required to solve this problem.
We encourage you to play around with this code until you feel comfortable with
the various moving parts. For example, try varying the optimisation settings,
the lower and upper bound, and the starting point. Depending upon the settings
you use, the output will look something like the following:

Local minimum possible. Constraints satisfied.
fmincon stopped because the predicted change in the objective function
is less than the selected value of the function tolerance and constraints
are satisfied to within the default value of the constraint tolerance.
No active inequalities.
ans =
-0.0001

-0.0058

39.4396

3.3842

Importantly, we see that with these settings our ML estimator does a good job
in recovering the correct estimate for β that we estimated earlier.
2

If you’ve skipped over chapter 1 before reading this, you’ll need to refer to section 1.2 in
order to generate X and y.

55

The optimset options provide a large range of options which are worth being
familiar with when solving for minimums in this way. If, for example, we are interested in producing a graph of convergence of the objective function to its minimum value then we could take advantage of: ‘PlotFcns’,‘optimplotfval’,
while if we are interested in seeing a larger range of output including the procedure and the value of the objective function, we could specify ‘Display’,‘iter’
as part of our options command. In ﬁgure 3.1 we see the output from the
PlotFcns option. As we discussed earlier, we have taken the absolute value of
the likelihood function so it appears to be converging on a positive value from
above, although in reality it will be converging on a negative value from below.
Of course, as we see in our estimates for β, this has no eﬀect on the values
produced.

Current Function Value: 195.217
1600

1400

Function value

1200

1000

800

600

400

200

0
0

5

10

15

20

25

30

Iteration

Figure 3.1: Convergence of (the absolute value of) the likelihood function

56

3.2

Generalised Method of Moments

In this book, and in microeconometrics more generally, we frequentely ﬁnd
ourselves maximising likelihood functions. However, we do not want to suggest
that this is the only, or necessarily the correct, way to estimate parameters in
a given model. Perhaps one of the most ﬂexible ways of estimating parameters
in a wide range of econometric problems is by using method of moments, or
generalised method of moments (GMM). When using GMM, we deﬁne a number
of population moments, which are expressions that are true in our model.3
We then estimate the parameters of our model using the principle of analogy.
This involves setting the identical sample moments to zero in our observed
draw of data.
Once again, GMM is based upon the principle of optimising an objective function, and again (for the last time, we promise!) the most simple example for
us to code comes from estimating parameters in a linear regression model. We
suspect you may remember from an early econometrics class that the basic
Gauss Markov assumptions imply that the following moments will hold in the
population for the linear regression model:
E[ε|X] = 0.

(3.2)

From this, we can also show that:
E[Xε] = E[X(y − Xβ)] = 0.

(3.3)

We can use (3.3) to form our sample moment conditions, which gives one moment for each β parameter in our model. As you may be aware, these sample
moments look like the following:
m=

1
N

N

Xi (yi − Xi β) = 0.

(3.4)

i=1

This vector is what we’ll refer to as our moment vector and will be of dimen3

There are many excellent references to turn to if you are interested in further details on
method of moments based estimation. For example, Hall (2005); Cameron and Trivedi
(2005), or for those particularly interested, the original Hansen (1982) article provide more
extensive details.

57

sion 1 × k, where k is the number of independent (X) variables in our model.
ˆ
The fundamental idea in GMM is that our estimates β should be those values
which drive the weighted quadratic distance mW m to zero, (or as close to
zero as possible if we have more moments than coeﬃcients)4 . For consistent
estimation we simply need to ensure that our weight matrix W is semi-deﬁnite
positive (such as an identity matrix). However, for eﬃciency reasons we may
be interested in using other weight matrices such as those discussed by Hansen
(1982).
This is all well and good in theory, but how does GMM actually work in Matlab? Given that we are attempting to minimise mW m , you may suspect that
our code will involve minimising some function whose output is this value. If so,
you’d be correct! Let’s have a look at the below function which sets up these
sample moments.

function Q = objective(beta,y,X)
% Q = objective(beta,y,X) calculates the moments of a linear
% regression model given input data y (a vector), X (a matrix
% including an intercept of all ones if desired), and the point
% estimates beta. The true method of moments estimate of beta
% occurs when Q=0.
%
% The series of moments that are being fitted here are:
% [E(X_1*u)=0 E(X_2*u)=0 ... E(X_k*u)=0]
%==============================================================
%=== (1) determine sample size N and number of coefficients k
%==============================================================
N = length(y);
k = size(X,2);
%==============================================================
%=== (2) Calculate u and generate the (arbitrary) weight matrix
%==============================================================
u = y - X*beta;
W = eye(k);
4

We refer to this case as ‘over-identiﬁcation’.

58

%==============================================================
%=== (3) Generate moment vector (1*3) in this case
%==============================================================
m = 1/N*u’*[X(:,1) X(:,2) X(:,3)];
Q = m*W*m’;
return

This function accepts as arguments our observed y and X data, and a proposed
ˆ
value for the vector of parameter estimates β. As per normal, step through
each line on the command line in Matlab to ensure that you’re comfortable
with the computations carried out, and to ensure that you’re happy that this
function returns a scalar value for Q.
To calculate our estimates, all we now need to do is minimise the function
objective. As we have seen in a number of earlier examples, Matlab has a
host of minimisation routines which are perfect for such calculations. In this
case, we will use fminsearch rather than fmincon because our optimisation
problem is unconstrained. Let us now return to the auto.csv ﬁle we worked
with in chapter 1. In the code below, we load this into Matlab, and estimate
ˆ
β by GMM:

>>
>>
>>
>>

DataIn
= dlmread('auto.csv');
X
= [ones(74,1) DataIn(:,2:3)];
y
= DataIn(:,1);
[beta,Q] = fminsearch(@(B) objective(B,y,X),[10,0,0]', ...
optimset('TolX',1e-9));

beta =
39.4397
-0.0001
-0.0058

59

Q =
6.3475e-20

We can see above that by minimising this objective function, matlab gets very
close to Q = 0, and recover the identical point estimates that we found in previous trials. You’ll notice that we’ve here speciﬁed some diﬀerent optimisation
settings in our call to fminsearch. In any estimation such as this it’s very important to carefully set our minimisation criteria. For example, try estimating
without this setting. Do you recover the correct point estimates? Fortunately,
we have a very safe way to know when our optimisation settings are ‘sensitive
enough’ in this case. Given that each sample moment should be asymptotically
equal to 0, our weighted result Q should also be approximately 0. In any situation where Q 0, we’ll have reason to think that our GMM estimates have
not been successful in setting the sample moments equal to zero, and that our
optimisation settings likely need ﬁne tuning.

60

3.3

Review and Exercises

command

brief description

length
pi
fminunc
fmincon

Determines the number of rows in a matrix
The mathematical constant π
Routine to minimise an objective function with no constraints
Routine to minimise an objective function subject to linear or
nonlinear constraints
Routine to minimise an objective function with no constraints
Provides control over the optimisation process in Matlab
Draw a two-dimensional graph
Keep current plot in graph window, and add another plot to
the output
Set minimum and maximum for graph axes
A
Label x-axis in the plot window (allows for L TEX style parsing)
Add a title to the plot window
Allows for a (pseudo-)random draw from a uniform(0,1) distribution
Allows for a (pseudo-)random draw from a normal distribution
Sets Matlab’s psuedo random number generator at a replicable point
Pre-ﬁlls a matrix with ‘empty’ values
Repeats a command or series of commands a speciﬁed number
of times
Allows for multiple graphs on the same plot window
Bivariate scatter plot
Draws the empirical CDF of a vector

fminsearch
optimset
plot
hold on
axis
xlabel
title
rand
randn
rng
NaN
for
subplot
scatter
cdfplot

Table 3.1: Chapter 3 commands

61

Exercises
(i) How could you estimate the standard errors of the above estimators in
Matlab? Do these agree with those we calculated in chapter 1
(ii) Write an alternative maximum likelihood estimator. Rather than an
OLS estimator, try generating Matlab code to estimate a probit model.
Remember, that in this case the log likelihood function looks like:
N
L(β; y|x) = i=1 {yi · ln Φ(βxi ) + (1 − yi ) · ln[1 − Φ(βxi )]}. Benchmark
this code using the auto data set as before. Estimate probit foreign
length weight in Stata. Ensure that your code replicates these results
in Matlab.
(iii) Some code in this chapter has estimated β using just-identiﬁed GMM.
However, in this case, we could also consider estimating via tradition
method of moments, which simply involves setting each moment exactly
equal to zero rather than minimising the quadratic distance. How would
you code a method of moments estimator for β in Matlab? Hint: The
fsolve function may be useful in this case.

62

Part II

Discrete Choice

63

Chapter 4

Discrete Multinomial
Choice
Because travel behavior is complex and multifaceted, and involves
‘non-marginal’ choices, the task of bringing economic consumer theory to bear is a challenging one. Particularly diﬃcult is the integration of a satisfactory behavioural theory with practical statistical
procedures for calibration and forecasting.

McFadden (1974)

His policies included procuring double beds for all, world peace, and
a monorail to St Hugh’s and Lady Margaret Hall, which are the two
Oxford colleges most distant from the town centre.

The Independent, 22 November 2013

64

4.1

Introduction

In this chapter, we consider various models of discrete choice. Hopefully, this
will be useful for at least two reasons. First, discrete choice models are fundamentally important for microeconometrics. In some cases, this is because a
decision-maker faces a ﬁnite set of options. In other cases, it is because reserchers
ﬁnd it useful to discretise a continuous variable, to model decision-makers as if
they choose from a ﬁnite set. Second, discrete choice models are a useful way
of introducing the idea of nested optimisation.
To do this, we will consider a simple problem: we will model the demand for
various modes of transport, as a function of individual income. For simplicity,
we will assume throughout that we have data on N = 1000 individuals, and
we will assume that, for each individual, we observe a single covariate: income
(which we will denote xi ). This, of course, is a simple application of a problem
famously studied by Daniel McFadden and others, who developed new methods
in discrete choice theory to estimate consumer demand for the San Francisco
Bay Area Rapid Transit system (‘BART’).
We will proceed in three steps. First, we will consider a very simple binary outcome model, the (binary) logit. Second, we will consider a multinomial outcome
model, making a strong distributional assumption about the error terms (the
multinomial logit). Finally, we will consider a multinomial model with a more
ﬂexible distributional assumption (the multinomial probit). Our discussion will
follow closely the excellent discussion in Train (2009, chapters 3 and 4); if you
are interested in learning more about these methods, we strongly encourage you
to read Train’s discussion.

65

4.2
4.2.1

The binary logit model
The model

Let’s begin with a simple decision problem: should a commuter (i) drive to
work, or (ii) take other modes of transport?1 We will consider this problem
using the binary logit model. Hopefully, this model is very familiar. We have a
binary outcome variable (which we denote yi ), and we assume that yi is chosen
by optimising individuals. Assume that, if individual i chooses yi = 1, (s)he
receives Ui1 ; if individual i chooses yi = 0, (s)he receives Ui0 . We will specify
Uij as the sum of (i) a deterministic function of the data (Vij (xi )) and (ii) a
random noise variable (εij ). Train (2009, p.15) calls Vij (xi ) the ‘representative
utility’.
We can therefore write:
Ui0 = Vi0 (xi ) + εi0 ;

(4.1)

Ui1 = Vi1 (xi ) + εi1 .

(4.2)

We could specify Vi0 (xi ) and Vi1 (xi ) very ﬂexibly — for example, we might have
a sophisticated structural model relating income to the representative utility of
driving to work. However, to keep the exposition simple here, we will assume
that Vij (xi ) is linear in xi : Vij (xi ) = α0j + α1j · xi . The solution to this model
is very simple:
yi =

1 if Vi1 (xi ) + εi1 ≥ Vi0 (xi ) + εi0
0 otherwise.

(4.3)

Having assumed a linear form for Vij (xi ), we can write:
yi =
1

1 if β0 + β1 · xi + µi ≥ 0
0 otherwise,

(4.4)

Of course, we will treat these as mutually exclusive: if the commuter drives for any part of
his or her journey, we will treat this as driving to work.

66

where we deﬁne β0 ≡ α00 − α01 , β1 ≡ α10 − α11 and µi ≡ εi1 − εi0 .

Assumption 1 (distribution of εij ) Assume that εij is independently and
identically distributed according to a type I extreme value distribution:
Pr(εij ≤ z | xi ) = exp(− exp(−z)).

(4.5)

That is — critically — we assume that εij is independent across individuals
(i) and across options faced by a given individual (j). (Note that it is also
independent of the covariate, xi .)

It follows from Assumption 1 that µi has a logistic distribution:
Pr(µi ≤ z | xi ) =

exp(z)
1 + exp(z)

(4.6)

= Λ(z).

(4.7)

We can therefore write the conditional probability of choosing to drive to work:
Pr (yi = 1 | xi ) = Pr (β0 + β1 · xi + µi ≥ 0)

(4.8)

= Pr (−µi ≤ β0 + β1 · xi )
= Λ (β0 + β1 · xi ) ,

(4.9)
(4.10)

where the last line follows from the symmetry of the logistic distribution.
From here, we can easily write the log-likelihood:
i

(β0 , β1 ; yi | xi ) = yi · ln Λ (β0 + β1 · xi ) + (1 − yi ) · ln [1 − Λ (β0 + β1 · xi )] .
(4.11)

4.2.2

Simulating the model

It would be tempting to code equation 4.11, and to start estimating. After all,
what could possibly go wrong? The answer, of course, is simple: everything!
67

When coding your own estimator — whether a simple estimator or intricate —
you should always start by simulating your model. That is, you should write
Matlab code to generate a fake dataset, on the assumption that your model
is correct. It is entirely possible that you will end up completely discarding
the simulated data and the code used to produce it; c’est la vie. If you cannot
estimate successfully using fake data, you will never feel conﬁdent using real
data.
Let’s start, then, by simulating our model for the simple case (β0 , β1 ) = (0.5, 0.5).
First, let’s seed the random number generator, create a vector beta, and generate a normally distributed xi . . .

>>
>>
>>
>>
>>

rng(1)
N
beta
income
x

=
=
=
=

1000;
[0.5, 0.5]';
randn(N, 1);
[ones(N, 1), income];

Let’s deﬁne a function SimulateBinaryLogit, to generate binary outcomes according to the logit speciﬁcation. You should check that you understand how
this function works. (In particular, you should pay special attention to the
line epsilon = -log(-log(rand(N, J))); how does this draw from a Type 1
Extreme Value distribution?)

4.2.3

Estimating the model

The function BinaryLogitLL(beta, y, x) calculates the log-likelihood in equation 4.11. Check that you understand the function, then use fmincon to maximise the log-likelihood. . .

options

= optimset(’Algorithm’, ’sqp’, ’Display’, ’iter’);

beta_init = [0; 0];

68

BinaryLogitLL(beta_init, y, x)
lb
ub

= [-10; -10];
= [10; 10];

[EstBetaML, LL, exitflag]
= ...
fmincon(@(parameters) BinaryLogitLL(parameters, y, x), ...
beta_init, [], [], [], [], lb, ub, [], options)

Hopefully this succeeds in recovering reasonably good estimates of (β0 , β1 ) =
(0.5, 0.5). You should ﬂip back and forth between simulation and estimation,
checking the performance of the estimator. How does the estimator perform for
diﬀerent values of (β0 , β1 )? How does it perform for diﬀerent sample sizes?

4.2.4

Estimating by simulation

So far, so good. One reason that the binary logit is so straightforward is that
we can write an analytical expression for the log-likelihood; from there, we
simply need to code it and optimise. But now suppose — purely for the sake
of exposition — that for some reason we were unable to write equation 4.11.
That is, suppose that we could specify our data-generating process, but could
not ﬁnd an analytical expression for the log-likelihood. It would be a pity if
this were to prevent us from estimating our model; if it did, we would be forced
to change our model purely for the convenience of our code, which is never an
attractive option.
Fortunately, all would not be lost. So far, we have simulated our model, and
we have estimated. But we can do more — we can combine the two methods,
to estimate by simulation. For now, this is purely a pedagogical exercise — but
this idea will become fundamentally important when we need to estimate more
ﬂexible models later in this chapter.

69

The idea is simple. We have a model that predicts how observable behaviour (in
this case, the choice of yi ) depends upon an observable covariate (income, xi )
and a parameter vector (β = (β0 , β1 )). We also have data. For some values of
β, our simulated data will look vastly diﬀerent to our real data — for example,
if we choose β1 = 0, we will simulate data in which yi does not vary with xi ,
which is unlikely to be true in our real data. For other values of β, our simulated
data will look quite similar to our real data. We can estimate by choosing β so
that our simulated data ‘looks like’ our real data.
There are many ways of doing this. Our model relies upon an assumption about
the entire distribution of the unobservable (that is, we have a fully parametric
model ) — so if we are to use a simulation-based estimator, it should be Maximum Simulated Likelihood (‘MSL’). The basic idea of MSL is simple: instead of
calculating probabilities with an analytical expression, we should simulate our
model multiple times, and use the sample probabilities that are generated from
the simulated data.
Formally, suppose that we have R replications of our simulation algorithm.
Then, for each respondent i, we will have a simulated series of binary outcomes,
{˜i1 , . . . , yiR }. (Note that, for each respondent i, all of these simulated outcomes
y
˜
are generated using the same value of xi — this is the sense in which we are
simulating conditional upon the observed values of xi in the data.) Then, for
individual i, the simulated conditional probability of choosing yi = 1 is simply:
R

1
˜
yir .
˜
P (xi ; β0 , β1 ) ≡
·
R r=1

(4.12)

For respondent i, the simulated log-likelihood is therefore:
˜i (β0 , β1 ; yi | xi ) = yi · ln P (xi ; β0 , β1 ) + (1 − yi ) · ln 1 − P (xi ; β0 , β1 ) .
˜
˜
(4.13)
Notice that, for given parameter values β0 , β1 ,
lim ˜i (β0 , β1 ; yi | xi ) =

R→∞

70

i

(β0 , β1 ; yi | xi ) .

(4.14)

This is the basic idea behind Maximum Simulated Likelihood.2
The ﬁle BinaryLogitSimulatedLL(beta, y, x, R) calculates ˜i (β0 , β1 ; yi | xi ).
You should check that you understand how the ﬁle works, then minimise:

R

= 1000;

options2

= optimset(’Algorithm’, ’sqp’, ’Display’, ...
’iter’, ’DiffMinChange’, 1e-2);

BinaryLogitSimulatedLL(beta_init, y, x, R)
[EstBetaMSL, LL, exitflag] = ...
fmincon(@(parameters) BinaryLogitSimulatedLL(parameters,...
y, x, R), ...
beta_init, [], [], [], [], lb, ub, [], options2)

You should play with this code; there are several potential mysteries here worth
exploring. For example, what is the role of R? What does DiffMinChange do,
and why is it necessary in this MSL case? And why does BinaryLogitSimulatedLL
begin by seeding the random number generator (rng(1))? Finally, note that
both BinaryLogitLL and BinaryLogitSimulatedLL return the vector of i as
their second argument. You should use this to produce a scatterplot of i under the analytical expression and under the simulated function; how does this
scatterplot change as R changes?
2

And, in this chapter, we will not go beyond the ‘basic idea’. Of course, if you want to
use MSL in applied research, you should read further on the theory of simulation-based
estimators — but in this chapter, we are focusing on the basic intuition. . .

71

4.3
4.3.1

The multinomial logit model
The model

Hopefully, the previous discussion is a useful illustration of the principles of
discrete binary choice. But, in many contexts, we want to model decisionmakers who face more than two alternatives. Generically, we can describe this
as a model of ‘multinomial choice’. For example, suppose that we now have an
outcome variable with three values:

 1 if the ith respondent drives to work;

(4.15)
yi =
2 if the ith respondent walks to work;


3 if the ith respondent cycles to work.

There are several ways that we could model this problem. For example, we
might be willing to assume that the choices are somehow ordered — that is,
that the outcome varies monotonically in some latent variable. Alternatively,
we may assume that the decision is nested — for example, we might treat commuters as deciding whether or not to drive and, if deciding not to drive, then
deciding whether to walk or cycle.

In this chapter, however, we will eschew both of these assumptions. Instead,
we will treat each outcome as generating utility with its own unobservable component; for simplicity, we will maintain the ‘Additive Random Utility Model’
structure:
(j)

(j)

Uij (xi ) = α0 + α1 xi + εij .

(4.16)

Thus, for example, for choices j ∈ {1, 2, 3}, the individual obtains the following

72

utilities:
(1)

(1)

Ui1 (xi ) = α0 + α1 xi + εi1
Ui2 (xi ) =

(2)
α0

+

(3)

(2)
α1 xi

(4.17)

+ εi2

(4.18)

(3)

Ui3 (xi ) = α0 + α1 xi + εi3 .

(4.19)

Together, these three utilities determine the choice of an optimising agent. Figure 4.1 illustrates preferences between the three options in two-dimensional
space; in each box, the bold outcome represents the agent’s choice.

U3 (x) − U1 (x)
.
.
.
.
..
....
....
.
....
.....
.. .
.
.. .
.
.
.
.
..
.
..
.
..
..
.
.
.
.
.
.
.
.
...
...
.
.
.
.
.
.
..
.
..
.
...
.
.
.
.
.
.
.
.
...
...
.
.
.
.
.
.
.
.
...
.
...
.
.
.
.
.
.
.
.
...
...
.
.
.
.
.
.
.
.
...
...
.
.
.
.
..
.
..
.
..
..
.
.
.
.
.
..
..
.
..
.
..
.
.
.
.
.
.
.
.
...
...
.
.
.
.
.
.
.
.
...
.
...
.
.
.
.
.
.
.
.
...
...
.
.
.
.
.
.
.
. ...
. ...
.
..
. ..
.
..
..
..
............................................................................................................................................................ .
..............................................................................................................................................................
.
...
...
..
..
.
..
....
.. .
.
.
. .
.
.
... .
...
.
.
.
.
.
.
..
..
.
..
.
..
.
.
.
.
..
.
...
.
.
..
.
.
.
.
..
.
..
.
..
.
..
.
.
.
.
..
.
.
..
.
...
.
.
.
.
..
.
.
.
..
...
.
.
.
.
.
.
.
.
...
...
.
.
.
.
.
.
.
.
...
.
...
.
.
.
.
.
.
...
...
.
.
.
.
.
.
.
.
...
.
...
.
.
.
.
.
.
...
.
...
.
.
.
.
.
.
.
..
...
.
.
.
..
.
.
.
.
..
.
..
.
..
..
.
.
.
.
.....
..
....
....
.
..
....
.
.
....
.
.

3
2
3

3
2
3

3
2
3

2
1
1

2
1
1

3
2
3

2
1
1

3
2
3

3
2
3

2
1
1

U3 (x) = U2 (x)

2
1
1

U2 (x) − U1 (x)

2
1
1

Figure 4.1: Multinomial choice among three options

We can, therefore, express the conditional probability of the ith individual

73

choosing, say, option 1:
Pr(yi = 1 | xi ) = Pr U (1) (xi ) > U (2) (xi ) and U (1) (xi ) > U (3) (xi ) xi
(1)

(1)

(2)

(2)

(1)

(1)

(3)

(3)

(4.20)

= Pr α0 + α1 xi + εi1 > α0 + α1 xi + εi2 and
α0 + α1 xi + εi1 > α0 + α1 xi + εi3 xi .

(4.21)

More generally, if the ith individual were to choose yi = j out of J choices, we
could write:
Pr(yi = j | xi ) = Pr U (j) (xi ) > max U (k) (xi )
k=j

xi

j
j
k
k
= Pr α0 + α1 xi + εij > max α0 + α1 xi + εik
k=j

(4.22)
xi .

(4.23)

In order to estimate using equation 4.23, we again need to make a distributional
assumption.

Assumption 2 (distribution of εij ) εij is i.i.d. with a Type I Extreme Value
distribution, independent of xi :
Pr(εij < z | xi ) = Pr(εij < z) = exp (− exp (−z)) .

(4.24)

With this distributional assumption, we can now ﬁnd an expression for the conditional probability that the ith individual chooses outcome j from J choices.3
We think the derivation is useful for understanding the underlying structure
required by multinomial choice models.

First, suppose that the error term for the chosen option, εij , were known. Then
3

This derivation is taken from Train (2009, pages 74-75).

74

we could write:
Pr(yi = j | xi , εij ) = Pr U (j) (xi ) > max U (k) (xi )
k=j

xi , εij

(4.25)

j
j
k
k
= Pr α0 + α1 xi + εik < α0 + α1 xi + εij xi , εij ∀ k = j

(4.26)
= Pr εik < εij +

j
α0

+

j
α1 xi

k
k
− α0 − α1 xi xi , εij ∀ k = j

(4.27)
j
j
k
k
exp − exp − εij + α0 + α1 xi − α0 − α1 xi

=

.

k=j

(4.28)
Of course, εij is not known; we therefore need to integrate across its possible
values:
∞

Pr(yi = j | xi ) =

f (εij ) · Pr(yi = j | xi , εij ) dεij

(4.29)

−∞
∞

exp (−εij ) · exp [− exp (−εij )]

=
−∞

j
j
k
k
exp − exp − εij + α0 + α1 xi − α0 − α1 xi

·

dεij

k=j

(4.30)
∞
j
j
k
k
exp − exp − εij + α0 + α1 xi − α0 − α1 xi

exp (−εij ) ·

=
−∞

dεij

k

(4.31)
∞
j
j
k
k
exp − εij + α0 + α1 xi − α0 − α1 xi

exp (−εij ) · exp −

=
−∞

k

(4.32)
∞

=

exp (−εij )
−∞
j
j
k
k
exp − α0 + α1 xi − α0 − α1 xi

· exp − exp(−εij ) ·

dεij .

k

(4.33)
We can now integrate by substitution. Deﬁne t = exp(−εij ), so that dt =
− exp(−εij ) · dεij . Note that limεij →−∞ t = ∞ and limεij →∞ t = 0. Then we

75

dεij

can rewrite our integral as:
∞

Pr(yi = j | xi ) =

j
j
k
k
exp − α0 + α1 xi − α0 − α1 xi

exp −t ·
0



dt

k

exp −t ·

=

−

k

k

j
j
k
k
exp − α0 + α1 xi − α0 − α1 xi

j
j
k
k
exp − α0 + α1 xi − α0 − α1 xi

(4.34)
∞

0

(4.35)
1

=
k exp −

=

j
α0

j
j
exp α0 + α1 xi
k

(4.36)

j
k
k
+ α1 xi − α0 − α1 xi

k
k
exp α0 + α1 xi

.

(4.37)

Let’s return to our example with three outcomes, y ∈ {1, 2, 3}. The last derivation implies that we can write the conditional probabilities of the outcomes
as:
(1)

Pr(yi = 1 | xi ) =

(1)

(2)

(2)

exp α0 + α1 xi
(1)

(1)

(3)

(3)

;

exp α0 + α1 xi + exp α0 + α1 xi + exp α0 + α1 xi
(4.38)
(2)

Pr(yi = 2 | xi ) =

(2)

(2)

(2)

exp α0 + α1 xi
(1)

(1)

(3)

(3)

;

exp α0 + α1 xi + exp α0 + α1 xi + exp α0 + α1 xi
(4.39)
exp
Pr(yi = 3 | xi ) =

(1)

(3)
α0
(2)

(1)

+

(3)
α1 xi
(2)

(3)

(3)

exp α0 + α1 xi + exp α0 + α1 xi + exp α0 + α1 xi
(4.40)
It would be tempting to take these three conditional probabilities and write
the log-likelihood; for our three outcomes, we could therefore try to maximise
(1)
the log-likelihood across six unknown parameters (that is, the parameters α0 ,
(3)
(3)
(1)
(2)
(2)
α0 , α0 , α1 , α1 and α1 ). However, this would be a mistake, because we
would be unable to ﬁnd a unique set of values that would maximise the function.

76

.

(That is, the model would be underidentiﬁed.) The reason, of course, is that we
can only ever express utility in relative terms. We therefore need to choose a
‘base category’, and estimate relative to the utility from that category. We shall
(2)
(2)
(1)
(2)
(2)
(1)
choose 1 as the base category, and deﬁne β0 ≡ α0 −α0 and β1 ≡ α1 −α1
(3)
(3)
(and symmetrically for β0 and β1 ). Note the emphasis here that the choice
of base category is arbitrary: our predicted probabilities would be identical if we
were to choose a diﬀerent base category. Then we can multiply numerator and
(1)
(1)
denominator of each conditional probability by exp(−α0 − α1 xi ), to obtain:
1

Pr(yi = 1 | xi ) =
1 + exp

(2)
β0

+

(2)
β1 x i

(3)

(3)

(2)

(3)

(2)

(3)

(3)

(3)

(4.41)

;

(4.42)

.

(4.43)

(2)

exp β0 + β1 xi

Pr(yi = 2 | xi ) =

;

+ exp β0 + β1 xi

(2)

1 + exp β0 + β1 xi + exp β0 + β1 xi
(3)

(3)

exp β0 + β1 xi

Pr(yi = 3 | xi ) =

(2)

(2)

1 + exp β0 + β1 xi + exp β0 + β1 xi

These conditional probabilities can then be used to deﬁne the log-likelihood; it
is now straightforward that, for the ith individual, the log-likelihood is:4
(1)

i

(1)

(2)

(2)

β0 , β1 , β0 , β1 ; yi | xi
= 1 (yi = 1) · ln [Pr(yi = 1 | xi )] + 1 (yi = 2) · ln [Pr(yi = 2 | xi )]
+ 1 (yi = 3) · ln [Pr(yi = 3 | xi )] .

(4.44)

This log-likelihood function deﬁnes the famous ‘Multinomial Logit’ model. The
Multinomial Logit is the simplest model for unordered choice. (Note that, if
J = 2, the Multinomial Logit collapses to the logit model that we considered
earlier.)
4

I denote the indicator function by 1(·). Note that, for simplicity, I have not explicitly
written each conditional probability as depending upon the parameters of interest, though
they clearly do.

77

4.3.2

Simulating, estimating and estimating by simulation

The function SimulateMNLogit(x, betavec) simulates the Multinomial Logit.
The function MNLogitLL(betavec, y, x) returns the log-likelihood for the
Multinomial Logit. And the function MNLogitSimulatedLL(betavec, y, x,
R) returns the simulated log-likelihood. These three ﬁles repeat for the Multinomial Logit what we just considered for the binary case.
Figure 4.2 shows a cloud of simulated points, and the resulting simulated choices;
this graph is drawn in (U2 (x) − U1 (x), U3 (x) − U1 (x)) space, and is directly
analogous to Figure 4.1. You should produce this kind of graph when you run
SimulateMNLogit, which calls the function GraphSimulatedData. (Of course,
you should remember to ‘comment out’ the call to GraphSimulatedData when
you maximise the simulated log-likelihood; otherwise, you will ﬁnd yourself
graphing every time you simulate, which will slow the code considerably!)

4

3

2

1

0

−1

−2

−3

−4
−4

−3

−2

−1

0

1

Figure 4.2: Simulating choice

78

2

3

4

4.4

Multinomial Probit

4.4.1

Independence assumptions in the Multinomial Logit

The Multinomial Logit is a very tractable model. As we have discussed, it
provides an analytical expression for the log-likelihood; this function can therefore be evaluated and maximised easily. But this analytical tractability comes
at a cost: the Multinomial Logit requires that the unobservable terms, εij ,
have a Type I Extreme Value distribution, and that these terms are distributed
independently of each other. This has serious implications for a structure of individual choice. Consider, for example, the Multinomial Logit. Using equation
4.37, we can write the ratio of the conditional probability that yi = A and that
yi = B:
(A)

(A)

exp α0 + α1 xi
Pr (yi = A | xi )
=
(B)
(B)
Pr (yi = B | xi )
exp α0 + α1 xi
(A)

= exp α0

(B)

− α0

(4.45)
(A)

+ α1

(B)

− α1

· xi .

(4.46)

Cameron and Trivedi (page 503, emphasis in original) describe why these results
are so concerning:

A limitation of the [Conditional Logit] and [Multinomial Logit] models is that discrimination among the [J] alternatives reduces to a
series of pairwise comparisons that are unaﬀected by the characteristics of alternatives other than the pair under consideration. . .
As an extreme example, the conditional probability of commute by
car given commute by car or red bus is assumed in [a Multinomial
Logit] or [Conditional Logit] model to be independent of whether
commuting by blue bus is an option. However, in practice we would
expect introduction of a blue bus, which is the same as a red bus in
every aspect except colour, to have little impact on car use and to
halve use of the red bus, leading to an increase in the conditional
probability of car use given commute by car or red bus.
79

This weakness of MNL is known in the literature as the red bus –
blue bus problem, or more formally as the assumption of independence of irrelevant alternatives.

This is clearly a serious limitation of the conditional logit and multinomial logit.
Indeed, in his Nobel Prize Lecture in 2000, Daniel McFadden even went so far
as to say (page 339):

The MNL model has proven to have wide empirical applicability,
but as a theoretical model of choice behaviour its IIA property is
unsatisfactorily restrictive.

In this section, we therefore consider a more ﬂexible model: the ‘multinomial
probit’. Let’s start by discarding Assumption 2. Then we can rewrite our threeoutcome model in terms of diﬀerences in utility:
(1)

(1)

Di1 (xi ) ≡ Ui1 (xi ) − Ui3 (xi ) = β0 + β1 xi + µi1 ;
Di2 (xi ) ≡ Ui2 (xi ) − Ui3 (xi ) =

(2)
β0

Di3 (xi ) ≡ Ui3 (xi ) − Ui3 (xi ) = 0,
(1)

(1)

(3)

(2)

(2)

+

(2)
β1 x i

+ µi2 ;

(4.47)
(4.48)
(4.49)

(3)

where β0 ≡ α0 − α0 , β1 ≡ α1 − α1 , µi1 ≡ εi1 − εi3 and µi2 ≡ εi1 − εi3 .
Note that, without loss of generality, we can now treat commuter i as choosing
yi to choose the maximum of Di1 (xi ), Di2 (xi ) and Di3 (xi ). Note that this has
reduced the dimensionality of our unobservable: that is, we now have two error
terms, rather than three.
We need another distributional assumption. In the multinomial logit, it was
convenient to make a distributional assumption over a J-dimensional vector —
in this case, (εi1 , εi2 , εi3 ). In the multinomial probit, it is convenient to make a
distributional assumption over a (J − 1)-dimensional vector — here, (µi1 , µi2 ).5
5

Train (2009, chapter 5) shows how, with a multivariate normal error vector, this is equivalent
to making an assumption in the J-dimensional space and then simplifying. But we will keep
things simple and start with the (J − 1)-dimensional space. . .

80

Assumption 3 (distribution of (µi1 , µi2 )) Assume that (µi1 , µi2 ) has a bivariate Normal distribution such that:
µi1
µi2

4.4.2

0
0

∼N

,

1
ρ

ρ
1

.

(4.50)

Simulating the model

The function SimulateMNProbit(x, betavec, omega) simulates the multinomial probit. Its operation is directly analogous to our simulation functions for
the binary logit and for the Mulitnomial Logit. You should check that you
understand how it works.

4.4.3

Estimating by simulation

But wait! Why have we skipped straight to ‘estimating by simulation’ ? Surely
we’ve missed a step?! Exactly. We have missed a step — when we considered
the binary logit and the Multinomial Logit, we (i) simulated our model, then (ii)
estimated using maximum likelihood, and then (iii) estimated using maximum
simulated likelihood. Step (iii) was redundant in both cases. But now we see
why step (iii) matters — because in the case of Multinomial Probit, we cannot
write the log-likelihood. That is, we can simulate our model, but we cannot use
any closed-form expression to generate the log-likelihood. This is precisely the
kind of problem that requires simulation.
The function MNProbitSimulatedLL(parameters, y, x, R) returns the simulated log-likelihood for the Multinomial Probit. You should check that you
understand how it works, and use it to ﬁnd Maximum Simulated Likelihood
estimates.

81

4.4.4

Estimating by simulation: A logit-smoothed AR simulator

So far, we have considered three functions for simulated log-likelihoods. In each
case, we simulated for each respondent i a series of outcomes series of outcomes,
{˜i1 , . . . , yiR }. In each case, we simulated Pr(yi = j | xi ) as:
y
˜
R

1
˜
Pj (xi ; β0 , β1 ) ≡
·
1 (˜ir = j) ,
y
R r=1

(4.12)

where 1(·) here refers to the indicator function. We can now describe this as
an ‘accept-reject simulator ’ — for each replication, we simply decide whether or
not the simulated outcome matches the outcome of interest.
This approach works — as our previous examples illustrated. However, it is
far from perfect, for several reasons. First, the simulated log-likelihood is everywhere locally ﬂat; that is, it is a step function in the parameter space. The
reason should be obvious: for a tiny change in the parameters, there is probability zero that any simulated outcome switches from ‘accept’ to ‘reject’ (or vice
versa). For this reason, we needed to encourage Matlab to take larger steps
in its optimisation (using DiffMinChange). Second, for any ﬁnite number of
replications R, there is no guarantee that, for a given individual, any simulated
observation will match the observed choice. For example, in the binary logit
case, it is possible that individual i chooses yi = 1, but that all simulated outcomes for individual i are zero. (Of course, this is more likely to occur when we
are trying to evaluate the simulated log-likelihood far from the true parameter
˜
values.) This is a fatal problem: we will then conclude that Pj (xi ; β0 , β1 ) = 0
for some observed outcome j, and will ask Matlab to take the log of zero.
Third — and, perhaps, more philosophically — the accept-reject simulator is
throwing away information. When we simulate, we calculate values for the
utility. However, the accept-reject simulator uses information only on which of
those values is greatest — it discards useful information on whether an option
was ‘nearly chosen’. In this way, the accept-reject simulator is like a sports fan
who wants to know whether his or her team won — but doesn’t care to hear
the score.

82

This is because equation 4.12 is discontinuous in the utility of option j; a small
change in the simulated utilities can cause a discrete change in yir . We can
˜
therefore improve our simulator by smoothing over the simulated utilities. Following Train (2009, p.121), denote the simulated utility for individual i for
r
option j on replication r as Uij . Then, instead of equation 4.12, we can use:
R

1
˜
Pj (xi ; β0 , β1 ) ≡
·
R r=1

r
exp Uij /φ
.
r
k exp (Uik /φ)

(4.51)

Equation 4.51 should look familiar: the term inside the summation is a multinomial logit transformation in the simulated utilities. For this reason, we can
term this a ‘logit-smoothed ’ simulator. Note that, in this equation, φ is used
to ‘tune’ the smoothing. As φ → ∞, each simulated probability is smoothed
to 1/J; as φ → 0, the function approximates the (unsmoothed) AR simulator.
Train (p.121) explains that there is ‘little guidance on the appropriate level’ for
φ; as applied researchers, we need to experiment with this given our particular
model.
The function MNProbitSimulatedLL Smoothed(parameters, y, x, R) implements the logit-smoothed multinomial probit. Check that you understand how
this works; in particular, ﬁnd a sensible value for the smoother, and compare
the number of replications you need in this case compared to in the unsmoothed
case.
Finally, you should note that the logit-smoothed simulator is not the only option
available. Train discusses in detail the Geweke-Hajivassiliou-Keane simulator,
which is a further improvement on the smoothed AR method. This simulator lies
beyond the scope of our discussions here, but we encourage you to read Train’s
discussion of this method if you are interested in estimating multinomial probit
models.

83

Chapter 5

Games
It is not a case of choosing those which, to the best of one’s judgment, are really the prettiest, nor even those which average opinion
genuinely thinks the prettiest. We have reached the third degree
where we devote our intelligences to anticipating what average opinion expects the average opinion to be. And there are some, I believe,
who practise the fourth, ﬁfth and higher degrees.

Keynes (1936)

5.1

Introduction: A simple Cournot game

To this point, we have considered observations on single individuals — whether
individual commuters, individual consumers, and so on. But much microeconomic theory focuses upon strategic interactions between multiple players. It is
useful to think about how we can model such interactions in Matlab — and
how we can estimate such models using data on the outcome of such strategic
interactions.

84

Let’s start with a simple theoretical model. We will use this model to illustrate
the principles of solving games in Matlab. Having established these principles,
we will think about estimating in section 5.2.
We will begin by considering a two-ﬁrm Cournot game. Suppose that each ﬁrm
produces a single good, and that aggregate demand is given as follows (also
illustrated in Figure 5.1):
p(q) =

a−b·q
0

for q < a · b−1 ;
for q ≥ a · b−1 .

(5.1)

Figure 5.1: Inverse demand function
p

a

.
.
.
..
.
...
.....
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
..
.
..
.
.
..
.
..
.
.
..
.
..
.
.
..
..
.
.
..
.
..
.
.
...
...
.
.
...
...
.
.
...
.
...
.
.
....
....
.
.
....
....
.
.
. ...
.....
.
.
.
... ..
.
... ..
.........
........
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
. .............................................................................................................................
.
..............................................................................................................................
.
...
...
..

.....
slope = −b
.....
.....
.....
.....
.....
.....
.....
.....
.....
.....
.....
.....
.....
.....
.....
.....
..............................
a
b

0

q

We assume that each player i chooses a quantity to produce, qi ≥ 0. Actions
are taken simultaneously. For some combination of quantities (qi , qj ), the payoﬀ
(proﬁt) to ﬁrm i is therefore:
πi (qi , qj ) = [a − b · (qi + qj )] · qi − c · qi
2
= (a − c − b · qj ) · qi − b · qi .

85

(5.2)
(5.3)

5.1.1

Finding the best-response function

We want to ﬁnd the Nash Equilibrium. Of course, we need to do this by ﬁnding
the best-response functions. Trivially, the best-response for ﬁrm i is solved as:
∂πi (qi , qj )
∂qi

= a − c − b · qj − 2b · qi = 0

(5.4)

∗
qi =qi

∗
∴ qi (qj ) =

a − c − b · qj
a − c qj
=
− .
2b
2b
2

(5.5)

But let’s assume that we cannot ﬁnd the analytical solution 5.5. How might we
solve this numerically in Matlab? Let’s build the problem from its core parts.
First, we need a function for the inverse demand. . .
function price = Demand(q, a, b)
% This returns the inverse demand for a simple Cournot model.
price

= max(0, a - b * q);

return

From here, it is straightforward to write a simple proﬁt for ﬁrm i :
function y = Profit(qi, qj, ci, a, b)
% This function returns profit for a simple Cournot model.
y

= (Demand(qi + qj, a, b) - ci) * qi;

return

∗
We now need to ﬁnd ﬁrm i’s best response, qi . Remember the key idea to the
‘best response’ concept: we treat ﬁrm i as optimising subject to ﬁrm j’s decision,

86

qj . That is, we solve:
∗
qi (qj ) = arg max πi (qi , qj ).
qi ≥0

(5.6)

It is straightforward to implement this in Matlab, using fmincon:
function qi
= BestResponse(qj, ci, a, b)
% Returns the best response for firm i to output q_j.
options
qi

= optimset(’Algorithm’, ’sqp’, ’Display’, ’off’);
= fmincon(@(q) -Profit(q, qj, ci, a, b), 0, ...
[], [], [], [], 0, [], [], options);

return

∗
The function BestResponse returns a single value for qi , for a single given value
for qj . We can visualise this as a function by looping over a vector of possible
values for qj , as Figure 5.2 illustrates. . .

%============================================================
% (1) Initialise the parameters, generate grid for qj
%============================================================
a
= 20; c = 2; b = 1;
qj = [0:20]’;
%============================================================
% (2) Solve the best response for qi...
%============================================================
qi_star
= NaN(size(qj));
for count = 1:size(qj, 1)
qi_star(count, 1)
= BestResponse(qj(count, 1), c, a, b);
end
line(qj, qi_star, ’LineWidth’, 2, ’Color’, [1, 0, 0])

87

10
9
8
7
6
5
4
3
2
1
0
0

2

4

6

8

10

12

14

16

18

20

Figure 5.2: A numeric solution for player i’s best response function
So far, so good. But, of course, what we would really like is to overlay two best∗
∗
response functions: qi (qj ) and qj (qi ). Having coded the function BestResponse
in such general terms, this is easy: we simply repeat the method we used to
∗
graph qi (qj ), switching i and j. . .
%============================================================
% (3) Generate a grid for qi...
%============================================================
qi = [0:20]’;
%============================================================
% (4) Solve the best response for qj...
%============================================================
qi_star
= NaN(size(qj));
for count = 1:size(qj, 1)
qj_star(count, 1)
= BestResponse(qi(count, 1), c, a, b);
end

88

We can now overlay this function on our earlier graph (ensuring that, as in the
earlier case, we are graphing qj on the x axis and qi on the y axis). Figure 5.3
illustrates.
hold on
line(qj_star, qi, ’LineWidth’, 2, ’Color’, [0, 0, 1])

20
18
16
14
12
10
8
6
4
2
0
0

2

4

6

8

10

12

14

16

18

20

Figure 5.3: Numeric solution for both best response functions
From these two functions, it should be clear that the Nash Equilibrium is (6, 6).
But we’re not done yet — because we need a way for Matlab to identify this
equilibrium automatically. That is, it is not enough that we can look at the
graph at see the equilibrium — if we want to use our model for estimation, we
need a way for Matlab to calculate this equilibrium point automatically.
We can do this by deﬁning a simple loss function. Suppose that our model
∗
∗
generates best-response functions (qi (j), qj (i)). Then for some pair (qi , qj ), we
can deﬁne the loss as:
2

∗
∗
L(qi , qj ) = (qi − qi (qj )) + qj − qj (qi )

89

2

.

(5.7)

Note that L(qi , qj ) is minimised (at zero) when (qi , qj ) is a Nash Equilibrium.
As a Matlab function. . .
function Loss
= CournotLoss(q, a, b, ci, cj)
% This returns the quadratic loss for a simple Cournot model.
% It is minimised at zero at the Nash.
qi_star
qj_star

= BestResponse(q(2), ci, a, b);
= BestResponse(q(1), cj, a, b);

Loss

= (q(1) - qi_star)^2 + (q(2) - qj_star)^2;

return

70
60
50
40
30
20
10
0
20
15
10
5
0
0

10

5

15

20

Figure 5.4: A quadratic loss function for the Cournot game
Figure 5.4 shows this function for the region around the Nash. (You should be
able to reproduce this graph, using the methods that we discussed in Chapter
1, including the ‘meshgrid’ command.)

90

We can ﬁnd the Nash simply by minimising this function:
function Nash = SolveNash(a, b, ci, cj)
% This solves the Nash for a simple Cournot model.
opts
Nash

=
=

optimset(’Algorithm’, ’sqp’, ’Display’, ’off’);
fmincon(@(q) CournotLoss(q, a, b, ci, cj), [0, 0],...
[], [], [], [], [0, 0], [], [], opts);

return

Let’s use this function to ﬁnd the Nash Equilibrium and add it (as a large black
dot) to our earlier graph:

>> Nash = SolveNash(a, b, c, c);
>> hold on
>> scatter(Nash(1), Nash(2), 100, [0, 0, 0], 'filled')

Together, these commands are collated in the script RunCournot. You should
run this ﬁle, and check that you understand how it works. You should vary a
and b. Notice that each of our functions allows for asymmetric cost, ci and cj .
You should experiment: how does cost asymmetry change the Nash?

5.2
5.2.1

Estimating a discrete Bayesian game
A simple discrete game

In the previous section, we showed how we can use standard optimisation methods to ﬁnd a Nash Equilibrium. We did this by minimising over a joint loss
function, where loss is deﬁned as the sum of loss between each player’s action
and that player’s best response.

91

We can now apply these principles for estimation. When we estimates models
of individual decision-making, we have multiple observations, each showing the
result of an individual decision. For example, when we model the decision of a
commuter whether or not to drive to work, we use data on multiple commuters
and their decisions. When we model games, we need to observe a game being
played multiple times. For the rest of this chapter, we will consider a stylised
Bayesian game; we will assume that we have data on diﬀerent outcomes of this
game in diﬀerent contexts.
We assume that we have a series of two-player interactions. Each interaction
will be modelled as a two-player game. We assume that each player can take
one of two actions: for player i, we have ai = 0 or ai = 1. The players act
simultaneously. We assume that utility accrues through two sources: (i) player
i receives a signal, xi , which increases the player’s utility if the player chooses
ai = 1, and (ii) player i receives an additional payoﬀ δi , if player i and player j
make the same choice (i.e. if ai = aj ).
It is convenient to think about this in terms of a a two-player entry game. That
is, let’s assume that we have market m ∈ {1, . . . , M }. In each market, we
have two ﬁrms (which we call ‘Player 1’ and ‘Player 2’), and each ﬁrm needs to
decide whether to adopt one business strategy (ai = 1) or the other (ai = 0). In
this example — and, indeed, in the rest of this chapter — we will assume that
(ceteris paribus) a ﬁrm weakly prefers its competitor not to be using the same
strategy: that is, δi , δj ≤ 0.
In normal form, we can therefore write the game as follows:
Player 1
Player 2

0
1

0
δ2 , δ1
x2 , 0

1
0, x1
x2 + δ2 , x1 + δ1

We can write player i’s utility as:

 xi


 x
i
Ui (ai ; aj , xi ) =





+ δi
0
δi
92

if
if
if
if

ai
ai
ai
ai

= 1, aj
= 1, aj
= 0, aj
= 0, aj

= 1;
= 0;
= 1;
= 0.

(5.8)

In this model, (x1 , x2 ) acts like an error term: it is observed by the players, but
not by the researcher, and therefore generates variation in the outcome that is
not explained by the measured covariates. As in the previous chapter, we need
a distributional assumption on this unobservable. For simplicity, we will use the
Bivariate Normal.

Assumption 4 (bivariate distribution of signals) For players 1 and 2, we
assume that signals (x1 , x2 ) have a Bivariate Normal distribution:
x1
x2

µ1
µ2

∼N

,

1 ρ
ρ 1

.

(5.9)

From this assumption, we can solve the model. For player i, the expected utility
of ai = 1 is:
Ui (1; 1, x∗ ) · Pr (aj = 1 | xi ) + Ui (1; 0, x∗ ) · (1 − Pr (aj = 1 | xi )) .
i
i

(5.10)

The expected utility of ai = 0 is:
Ui (0; 1, x∗ ) · Pr (aj = 1 | xi ) + Ui (0; 0, x∗ ) · (1 − Pr (aj = 1 | xi )) .
i
i

(5.11)

Deﬁne x∗ as the value of xi that makes these two expressions equal (that is,
i
equations 5.10 and 5.11). It is straightforward that utility is increasing in xi ;
therefore, player i should use a simple decision rule:
ai =

0
1

if xi < x∗ ;
i
if xi ≥ x∗ .
i

(5.12)

So how, then, should player i choose this cutoﬀ value x∗ ? We know that, if
i

93

xi = x∗ , player i is indiﬀerent between ai = 0 and ai = 1. We can therefore say:
i
Ui (1; 1, x∗ ) · Pr (aj = 1 | xi = x∗ ) + Ui (1; 0, x∗ ) · (1 − Pr (aj = 1 | xi = x∗ ))
i
i
i
i
= Ui (0; 1, x∗ ) · Pr (aj = 1 | xi = x∗ ) + Ui (0; 0, x∗ ) · (1 − Pr (aj = 1 | xi = x∗ ))
i
i
i
i
(5.13)
(x∗ + δi ) · Pr (aj = 1 | xi = x∗ ) + x∗ · (1 − Pr (aj = 1 | xi = x∗ ))
i
i
i
i
= δi · (1 − Pr (aj = 1 | xi = x∗ ))
i
∴

x∗
i

(5.14)

= δi · (1 − 2 Pr (aj = 1 | xi =

x∗ ))
i

(5.15)

x∗ )
i

− 1)

(5.16)

= δi · (2 Pr (aj = 0 | xi =

Because player i receives utility from coordinating his or her action with player
j, the signal xi plays two roles: (i) it contributes directly to player i’s utility,
and (ii) it provides information to player i on the likely action of player j. From
the assumption of Bivariate Normality, we know:
xj | xi ∼ N µj + ρ · (xi − µi ), 1 − ρ2
∴

xj − µj − ρ · (xi − µi )
1 − ρ2

xi ∼ N (0, 1) .

(5.17)
(5.18)

Now, if it makes sense for player i to use a cutoﬀ strategy, it also makes sense
for player j to do the same. Deﬁne x∗ as the cutoﬀ point for player j. From
j
this, player i can reason as follows:
Pr(aj = 1 | xi ) = Pr(xj ≥ x∗ | xi )
j
= Pr

(5.19)

xj − µj − ρ · (xi − µi )
1 − ρ2

≥

x∗ − µj − ρ · (xi − µi )
j
1 − ρ2

xi
(5.20)

=1−Φ
∴ Pr(aj = 0 | xi ) = Φ

x∗
j

− µj − ρ · (xi − µi )
1 − ρ2

x∗ − µj − ρ · (xi − µi )
j
1 − ρ2

94

.

(5.21)

(5.22)

Therefore, player i’s best-response function looks like this:
x∗ = δ i · 2 · Φ
i

x∗ − µj − ρ · (x∗ − µi )
i
j
1 − ρ2

−1 .

(5.23)

Together with the cutoﬀ strategy, equation 5.23 deﬁnes the equilibrium. (Specifically, it deﬁnes a Bayesian Nash Equilibrium.) It is suﬃcient for the equilibrium
to be unique that:
δi , δj > −

π
·
2

1−ρ
.
1+ρ

(5.24)

You should check that you understand that intuition behind these best-response
functions. For example, what should player i do if (s)he has no preference for
coordination (that is, δi = 0)? What happens if the signals (xi , xj ) are independent, conditional on (µi , µj ) (that is, if ρ = 0)? Given a set of parameters,
what are the maximum and minimum possible values for x∗ ? Play with δ: can
i
you ﬁnd multiple equilibria by violating equation 5.24? (Note: Remember that
equation 5.24 is suﬃcient for a unique equilibrium, but not necessary — you
should be able to ﬁnd cases in which equation 5.24 is violated but where the
equilibrium is still unique.1 )

5.2.2

Implementing the best-response functions

The function SolveBestResponse solves equation 5.23 numerically. It is directly
analogous to the function BestResponse that we considered for the Cournot
game.
As with the Cournot game, we can generate the best-response functions for
player 1 and player 2 over a grid, and graph. . .
1

That said, equation 5.24 provides the weakest suﬃcient condition — you should be able
to ﬁnd some parameter values generating multiple equilibria so long as equation 5.24 is
violated.

95

%============================================================
% (1) Initialise the parameters
%============================================================
mu_i
= 1;
mu_j
= -1;
delta_i
= -0.5;
delta_j = -0.5;
rho
= 0.75
%============================================================
% (2a) % Generate a grid for x_j
%============================================================
x_j = [-5:.1:5]’;
x_i_star
= NaN(size(x_j));
%============================================================
% (2b) Solve the best response for x_i
%============================================================
for count = 1:size(x_i_star, 1)
x_i_star(count, 1) = SolveBestResponse(mu_i, ...
x_j(count, 1), mu_j, rho, delta_i);
end
line(x_j, x_i_star, ’LineWidth’, 2, ’Color’, [1, 0, 0])
%============================================================
% (3a) Generate a grid for x_i
%============================================================
x_i = [-5:.1:5]’;
x_j_star
= NaN(size(x_i));
%============================================================
% (3b) Solve the best response for x_j
%============================================================
for count = 1:size(x_i_star, 1)
x_j_star(count, 1) = SolveBestResponse(mu_j, ...
x_i(count, 1), mu_i, rho, delta_j);
end
hold on
line(x_j_star, x_i, ’LineWidth’, 2, ’Color’, [0, 0, 1])

96

5.2.3

Solving the game numerically

The function SolveBayesianNash solves the Bayesian Nash Equilibrium for this
game. It is directly analogous to the function SolveNash for the Cournot game.
Let’s run it, and plot the solution. Figure 5.5 shows the result.

>> BayesianNash

= SolveBayesianNash(mu_i, mu_j, ...
delta_i, delta_j, rho);

>> hold on
>> scatter(BayesianNash(2), BayesianNash(1), 100, ...
[0, 0, 0], 'filled')

5
4
3
2
1
0
−1
−2
−3
−4
−5
−5

−4

−3

−2

−1

0

1

2

3

4

5

Figure 5.5: A numerical solution to a binary Bayesian game

5.2.4

Simulating the game

We now need to think about how we might take our model to data. We will
use a simple parameterisation. We will assume that we observe a series of
97

independent markets, indexed m ∈ {1, . . . , M }. In each market, we will be able
to identify one ﬁrm as ‘Firm 1’ and the other as ‘Firm 2’. We assume that, for
each ﬁrm, we observe a single binary covariate, xi , and that this covariate is
common knowledge between players. Therefore, our data look something like
this. . .

Firm 1

Firm 2

market (m)

covariate (x1 )

action (a1 )

covariate (x2 )

action (a2 )

1
2
.
.
.
M

0
1
.
.
.
1

0
0
.
.
.
1

0
0
.
.
.
0

1
0
.
.
.
0

For simplicity, we will assume that there is a single value of µ1 across all markets,
and a single value of µ2 (though we do not impose µ1 = µ2 ). Of course, we could
relax this assumption by introducing another covariate — but we will impose
common values across markets for simplicity. Similarly, we will assume that ρ
is common across markets; this, too, could be relaxed.
Critically, we will assume that variation in the binary covariate xi causes variation in the preference for discoordination:
δ 1 = β1 · x 1 ;

(5.25)

δ 2 = β2 · x 2 .

(5.26)

Notice that, under this structure, we observe at least some cases in which
(δ1 , δ2 ) = (0, 0). This is important for identiﬁcation.2 Therefore, we have ﬁve
parameters for this simple model: θ = (β1 , β2 , δ1 , δ2 , ρ).
The function SimulateBayesianNash simulates values for y1 , y2 , x1 and x2 . . .

function [y, x]

= SimulateBayesianNash(N, mu_1, mu_2,...
beta_1, beta_2, rho);
% This function simulates data from the Bayesian Nash model.
2

But we are saying almost nothing about identiﬁcation in this book, and we don’t intend to
start now. . .

98

rng(1)
%============================================================
% (1) Simulate covariate (x), and generate values (mu_i,mu_j)
%============================================================
x
= round(rand(N, 2));
%============================================================
% (2) Second, simulate by solving the game for each value x
%============================================================
cutoffs = NaN(N, 2);
y
= NaN(N, 2);
for count = 1:N
count
cutoffs(count, :) = SolveBayesianNash(mu_1, mu_2, ...
beta_1 * x(count, 1), ...
beta_2 * x(count, 2), rho);
y(count, :)
= mvnrnd([mu_1, mu_2], [1, rho; rho, 1],...
1) > cutoffs(count, :);
end
return

Let’s use this function to simulate a dataset of M = 1000 markets. . .

>>
>>
>>
>>
>>
>>

mu_1
mu_2
beta_1
beta_2
rho
[y, x]

=
=
=
=
=
=

1;
-1;
-0.2;
-0.7;
0.5;
SimulateBayesianNash(1000, mu_1, mu_2, ...
beta_1, beta_2, rho);

99

5.2.5

Estimating

Denote (x∗ , x∗ ) as the solution to the game — that is, the pair of cutoﬀs that
1
2
deﬁnes a Bayesian Nash Equilibrium. Denote Φ2 (a, b, ρ) as the cdf of a Bivariate
Normal with mean (a, b) and variance matrix
1 ρ
ρ 1

.

(5.27)

Then we can say:
Pr(a1 = 0, a2 = 0) = Φ2 (x∗ − µ1 , x∗ − µ2 , ρ) ;
1
2

(5.28)

Pr(a1 = 1, a2 = 0) = Φ2 (µ1 − x∗ , x∗ − µ2 , −ρ) ;
1
2

(5.29)

Pr(a1 = 0, a2 = 1) =

Φ2 (x∗
1

− µ1 , µ2 −

Pr(a1 = 1, a2 = 1) = Φ2 (µ1 −

x∗ , µ2
1

−

x∗ , −ρ) ;
2

(5.30)

x∗ ,
2

(5.31)

ρ) .

Therefore, for a market m, the log-likelihood is:
(θ; a1 , a2 | x1 , x2 )
= ln Φ2 {[(2a1 − 1) · (µ1 − x∗ ) , (2a2 − 1) · (µ2 − x∗ ) , (2a1 − 1) · (2a2 − 1) · ρ]} .
1
2
(5.32)

The function BayesianNashLL implements this. (Notice that the function loops
over the elements of a matrix called ‘UniqueData’. Why? What’s the advantage
of this approach?)

function LL

= BayesianNashLL(parameters, Y, X)

%============================================================
% (1) Unpack arguments
%============================================================
mu_1
= parameters(1);
mu_2
= parameters(2);

100

delta_1
delta_2
rho

= parameters(3);
= parameters(4);
= parameters(5);

N
ll

= size(X, 1);
= NaN(N, 1);

%============================================================
% (2) Ensure simulations are unique, solve for Bayesian Nash
%============================================================
[UniqueData, m, n] = unique(X, ’rows’);
cutoffs_small
= NaN(size(UniqueData, 1), 2);
for count = 1:size(UniqueData, 1)
cutoffs_small(count, :) = SolveBayesianNash(mu_1, mu_2, ...
delta_1 * UniqueData(count, 1),...
delta_2 * UniqueData(count, 2),...
rho);
end
cutoffs_large

= cutoffs_small(n, :);

%============================================================
% (3) Calculate log-likelihood for each repetition
%============================================================
for c = 1:N
q1
= 2 * Y(c, 1) - 1;
q2
= 2 * Y(c, 2) - 1;
ll(c) = log(bvnl( q1 * (mu_1 - cutoffs_large(c, 1)), ...
q2 * (mu_2 - cutoffs_large(c, 2)), ...
q1 * q2 * rho));
end
LL = -sum(ll);
return

101

We can recover estimates of θ by maximising this log-likelihood. But we face
one more problem before we do. Remember that, if δ1 or δ2 are suﬃciently large
negative numbers, our game will have multiple solutions. This poses a problem
for our estimation — because we have not speciﬁed any rule by which players
choose between multiple equilibria. There are certainly ways that we could deal
with this — for example, we could impose an equilibrium selection rule, or we
could even assume that players somehow jointly mix across multiple equilibria
with some predetermined probability. But, to keep things simple for now, we
would like to rule out the possibility of multiple equilibria.
Recall that equation 5.24 provides a suﬃcient condition for equilibrium uniqueness. We should impose this condition as a non-linear constraint on our maximum likelihood algorithm. We can do this in the ﬁle UniqueEquilibrium:
function [c, ceq] = UniqueEquilibriumConstraint(parameters)
delta_1
delta_2
rho
c
ceq

= parameters(3);
= parameters(4);
= parameters(5);

= [-sqrt(pi/2) * sqrt((1 - rho) / (1 + rho)) - delta_1; ...
-sqrt(pi/2) * sqrt((1 - rho) / (1 + rho)) - delta_2];
= [];

return

Note that this returns two outputs: c and ceq. This is necessary for fmincon.
When fmincon evaluates a non-linear constraint, it looks for two types of constraint:
c ≤ 0;

(5.33)

ceq = 0.

(5.34)

In this case, we have a vector of two values that must be negative; this is what
we code in c. We have no non-linear equality constraint, so we set ceq to an

102

empty matrix.
We can now maximise, imposing the unique-equilibrium constraint:
parameters_init

= [mu_1, mu_2, beta_1, beta_2, rho]’;

lb
ub

= [-2, -2, -2, -2, 0];
= [2, 2, 0, 0, 0.99];

options

= optimset(’Algorithm’, ’sqp’, ’Display’,...
’iter’,’DiffMinChange’, 1e-4);

[result.parameters, result.LL, result.exitflag] = ...
fmincon(@(parameters) BayesianNashLL(parameters, y, x),...
parameters_init, [], [], [], [], lb, ub, ...
@(parameters) UniqueEquilibriumConstraint(parameters),...
options);
[parameters_init, result.parameters]

103

5.3

Review

Command/Concept

Brief Description

rng
unique
nonlcon

‘seeds’ the random number generator for reproducible draws
selects only non-repeating values
Non-linear contraints to be used in optimizers. Should be
passed as a function, and list both equality and inequalities.
Table 5.1: Chapter 5 commands

104

Part III

Revealed Preference

105

Chapter 6

Revealed Preference
Quote...

Name...

6.1

Review

command

brief description
Table 6.1: Chapter ?? commands

106

Chapter 7

Linear Programming
Quote...

Name...

7.1

Review

command

brief description
Table 7.1: Chapter ?? commands

107

Part IV

Dynamics

108

Chapter 8

Dynamic Choice on a Finite
Horizon
“The thousand times that he had proved it meant nothing. Now
he was proving it again. Each time was a new time and he never
thought about the past when he was doing it.”

Ernest Hemingway, “The Old Man and the Sea”

8.1

Introduction

The steady march of time casts a pall over many economic decisions. The choice
to do something today may preclude, restrict, encourage or necessitate certain
choices in the future. Among many other areas: searching for work, investing in
human capital, installing or removing physical capital, and choosing a partner
on the marriage market are all decisions which are frequently considered from
a dynamic point of view.

109

While the mathematics behind these dynamic choices are slightly more complex
than traditional single-period optimisation problems we discussed in chapter ??,
the basic idea is—we think—not too much more demanding. When determining
behaviour over a number of periods, a decision maker should aim to equalise
the discounted marginal utility at each point in time. This is analagous to a
consumer’s aim to equalise the cost-adjusted marginal utility of each unit of
consumption in a static environment1 . Eﬀectively, while in a static sense we
expect that a consumer could not increase utility by rearranging consumption
between goods, in a dynamic sense we would expect that such an improvement
could not be made by rearranging consumption over time. Indeed, this ‘noarbitrage’ type condition has a special name in dynamic optimisation: the Euler
equation. This is a point we return to when setting up our problems and code
in the sections which follow.
The aim of this and the following chapter is not to provide a comprehensive
overview of the theory behind dynamic programming. If you are interested
in such a review, we would suggest having a look at a number of text-booklength analyses such as that of Adda and Cooper (2003), or chapters of Dixit
(1990) and Acemoglu (2008). We do however aim to provide a number of selfcontained applied examples of dynamic optimisation in Matlab, along with the
corresponding theory behind these situations. While we hope that this will give
you a good foot-hold into programming and thinking about these types of problems, applications of this type are vast, so further reading (and experimentation
in Matlab!) is likely to be very useful.

8.2
8.2.1

Dynamic Decisions
Household Consumption

To ﬁx the idea in our heads, let’s consider a particular dynamic choice: namely
that of a household deciding how much of a particular endowment to consume.
Given that households exist over various periods of time, and—we assume—aim
1

or likewise, for a ﬁrm to equalise the marginal output per cost of physical capital and labour
in typical (static) optimisation problems.

110

to maximise total lifetime utility, this is eﬀectively a dynamic decision. For the
time being we assume that the household is only interested in their utility from
consumption for the next T periods, perhaps because the good will spoil after
this time. We also assume that utility from consumption is additively separable
over time2 . This then gives us a familiar utility function of the form:
T

β t−1 u(ct ),

U=

(8.1)

t=1

where β represents the household’s discount factor.
At the beginning of the ﬁrst period our household will have some stock of the
good which we will call k1 , and which it apportions over time as it sees ﬁt.
Thus, in each of the T periods the household will consume ct , giving us a ﬂow
equation of the form:
kt+1 = kt − ct .
(8.2)
This transition equation keeps track of capital, our state variable (think
state=stock). From the above we see that the state in any given period depends only upon the state at the beginning of the period, and the decision the
individual makes with respect to the choice variable, c, (also known as the control variable). From (8.2) we start to see the dynamics of the optimisation
problem very clearly. The remaining stock of k in a given period depends upon
consumption in the preceding period and the level of k in the preceding period,
which itself depends upon decisions made earlier in life (that is unless we are in
the initial period in which k1 is given). Equations (8.1) and (8.2), along with the
non-negativity constraints ct ≥ 0 and kt ≥ 0 allow us to completely characterise
the household’s (dynamic) problem as:
T

β t−1 u(ct )

max

{ct }T
1

T
t=1 ct

s.t.

+ kT +1 = k1

t=1

ct ≥ 0

(8.3)

kt ≥ 0.
Here you will notice that we have rearranged the series of ﬂow equations (8.2)
2

This may turn out to be untrue, but we do not entertain this possibility for the time
being. Such an assumption is equivalent to assuming that “the marginal rate of substitution
between lunch and dinner is independent of the amount of breakfast”, an analogy that Dixit
(1990) attributes to Henry Wan.

111

into one equation for ease of presentation (and later ease of computation).
This problem looks remarkably similar to (static) optimisation problems we
have already tackled in earlier chapters of this book. Indeed, if we know the
form of u(ct ), the discount factor β, the initial endowment k1 , and the number
of periods T , we should be able to resolve this problem reasonably easily by
using Matlab’s fmincon function. Let’s deﬁne these and have a look. We’ll
assume for now a log normal utility function u(ct ) = ln(ct ), 10 time periods, a
discount factor of β = 0.9 and an initial endowment of k1 = 100.
As per normal then, we can consider setting up a Matlab function to minimise.
Consider something along the lines of:
function V = flowUtility(T,Beta,C)
% flowUtility(T,Beta,C) takes T periods of consumption of
% size C (a Tx1 vector), and calculates the total
% utility of consumption assuming an additively separable
% utility function and discount rate Beta.
c

=

C(:,1);

t
V
V

=
=
=

[1:1:T];
Beta.^(t-1)*log(c)
-V

return

If we pass this function the appropriate parameters it will return to us a scalar
value V, corresponding to total utility from the T periods of consumption. In
the ﬁnal line of this script you will notice that we convert our (positive) utility
V into a negative value, as although we are interested in maximising utility,
fmincon is a minimisation function.
Having written the function we aim to minimise, and having deﬁned all the
necessary parameters, let’s solve for consumption ct in each period.

112

>>
>>
>>
>>
>>
>>
>>
>>

beta
T
k1
lb
ub
guess
A
opt

>> c

=
=
=
=
=
=
=
=

0.9;
10;
100;
zeros(10,1);
100*ones(10,1);
10*ones(1,10);
ones(1,10);
optimset('TolFun', 1E-20, 'TolX', 1E-20, ...
'algorithm', 'sqp');
= fmincon(@(C) flowUtility(T,Beta,C), guess, ...
A, k1, [], [], lb, ub, [], opt)

c =
15.3534
13.8181
12.4363
11.1926
10.0734
9.0660
8.1594
7.3435
6.6091
5.9842

We see here that along with those parameters we deﬁned above (beta, T, and
k1), we pass additional arguments to fmincon. Our non-negativity constraint
for c is deﬁned as a lower-bound (lb) of zero in each of the ten periods, and
similarly an upper-bound is deﬁned, as consumption can never exceed 100 (the
full amount of the endowment) in any period.3 As usual, we pass an initial
starting point to Matlab as the vector guess (somewhat lazily deﬁning this as
equal consumption in all periods). Finally, we set up the ﬂow constraint that
total consumption must not exceed the full endowment k1. We do this using
the vector A, deﬁning that A · c ≤ k1 . Remember if at any time you are unsure
of what’s going on in this command, you can consult Matlab’s help ﬁles by
3

Strictly speaking, there is nothing which requires us to include ub and lb. These will be
implied by the ﬂow constraint and utility maximisation (respectively). However, it doesn’t
hurt, and is consistent with out so we include it here anyway.

113

typing help fmincon), or working through particular steps at the command
line.
The resulting vector of values shows us expected consumption in each period.
As expected given that β < 1, we see a downward sloping consumption proﬁle,
and we can also conﬁrm that this answer has our household consuming the
entirety of their endowment k1 in line with non-satiation:

>> sum(c)
ans =
100

Sensitivity to Input Parameters In the above example we have made a
number of reasonably particular assumptions upon which our optimal consumption depends. Principally, we have assumed that the (one) household that we are
considering has a particular discount rate, and that their utility from consumption in each period obeys a given functional form. Having written and solved
the above optimisation problem once, there is nothing that stops us from doing
this many times to see how these underlying parameters and primitive functions
aﬀect our results. In the following code we ‘simulate’ consumption over time
for a range of households: those which are remarkably impatient (β = 0.05),
to those which place absolutely no additional weight on their current utility
(β = 1).
%=============================================================
%=== (1) Calculate optimal consumption for 0<Beta<1
%=============================================================
result = NaN(10,20);
for Beta=1:20
beta_use=Beta/20;
result(:,Beta)=fmincon(@(C) flowUtility(T,beta_use,C),...
guess,A,k1,[],[],lb,ub,[],opt);
end

114

%=============================================================
%=== (2) Graphical output
%=============================================================
time = 1:10;
beta = 0.05:0.05:1;
subplot(1,2,1)
plot(time, result, ’LineWidth’, 2)
xlabel(’Time’, ’FontSize’, 12)
ylabel(’Consumption’, ’FontSize’, 12)
subplot(1,2,2)
surf(time, beta, result’)
xlabel(’Time’, ’FontSize’, 12)
ylabel(’Beta’, ’FontSize’, 12)
zlabel(’Consumption’, ’FontSize’, 12)

You’ll notice here that we have eﬀectively solved the problem 20 times, by
generating a for loop. Whilst for loops are not necessarily the fastest way to
write code in Matlab, in some cases this will be the simplest and clearest way
to set-up our code4 . After resolving this problem for each of 20 households with
diﬀering degrees of patience, we will likely be interested in visualising these
results in some way. We suggest a couple in the second block of the above
code. These outputs are available as ﬁgure 8.1. In the left hand ﬁgure we
simply present two-dimensional consumption proﬁles over time for our range
of βs, while the right-hand panel takes advantage of Matlab’s 3-D graphing
capabilities.
Exercise: How do our results depend upon the utility function we specify?

Perhaps this leads you to ask how we can actually determine β (and other
4

This is a point which we will return to extensively in chapter 12, where we discuss the
beneﬁts of vectorisation, how to speed up code via parallelising loops, and a number of
other exciting tricks that Matlab oﬀers.

115

100

90
100

80

90

80

70

Consumption

Consumption

70
60

50

40

30

60

50

40

30

20

20

10

1

10

0.8
0
1

0

1

2

3

4

5

6

7

8

9

10

0.6
0.4
2

3

4

5

6

0.2
7

8

Time

9

10

0

Beta
Time

Figure 8.1: Sensitivity of Consumption to Discount Rate

relevant parameters in problems of this type). This is something we will return to more fully in section 8.4 where we discuss taking these microeconomic
concepts—namely dynamic optimisation—and building them into microeconometric models. While the programs we have written above have been based
upon a single (or representative) household, we can use the power of Matlab to extend these to microeconometric applications which are based on many
households who face the same optimisation problem, but who may have diﬀerent
preferences and diﬀerent discount rates.
So far this entire process hasn’t been too much more diﬃcult than standard
static optimisation. Before getting too excited about this, we should probably
point out that this result is quite artiﬁcial for a number of reasons (or perhaps
you are ahead of us here...). Principally, we have been able to reduce the
‘dynamism’ of the problem by rearranging our ﬂow constraints (8.2) into one
simple constraint, as presented in the ﬁrst line of (8.3). In the subsection which
follows we will relax this, and consider a slightly more realistic example in which
the ﬂow constraints cannot be rearranged into such a nice linear format.

116

8.2.2

A Small Firm

Let’s imagine now that our household from the previous subsection is actually
both a producer and a consumer. We could think of this as being a small
farming household, and so its consumption decisions in one period aﬀect what
it produces in the following periods. Speciﬁcally, the ﬂow equation now takes
the form:
kt+1 = f (kt − ct , θ).
(8.4)
In this case current production depends upon the stock of k remaining from
the previous period, (and some technology parameter θ which represents an
idiosyncratic time-invariant measure of eﬃciency). The dynamic nature of the
problem essentially remains the same, as the household/ﬁrm should decide how
much to consume each period to maximise its total utility ﬂow. We can then
deﬁne the analogous maximisation problem to (8.3):
T

β t−1 u(ct )

max

{ct }T
1

T
t=1

s.t.

[kt+1 = f (kt − ct , θ)]

t=1

ct ≥ 0

(8.5)

kt ≥ 0.
As opposed to the problem in the previous subsection, we can no longer necessarily set up our maximisation problem with one simple linear ﬂow constraint
(as we did with the condition A · c = k1 ). The constraint on the ﬁrst line of
8.5 will likely be both non-linear, and have a highly ‘dynamic’ nature. This
dynamism comes about given that high consumption in early periods not only
runs down the stock of k, but also aﬀects the households’ ability to produce
more k in the future.
By deﬁning the functional form of f (·), we can see how this change aﬀects
the setup—and the result—of the problem. Let’s assume, for example, that
production is adequately captured by a Cobb-Douglas speciﬁcation:
kt+1 = f (kt − ct , θ) = θ(kt − ct )α .

(8.6)

Now, at least without forming a complex and highly recursive equation from
(8.6), setting-up a single constraint is not possible. If we wish to solve this
dynamic maximisation directly using Matlab’s optimisers, we then must form
117

a series of T (non-linear) constraints to account for (8.6) in each period.
Fortunately for problems of this type, fmincon allows us to deﬁne and solve
for non-linear constraints. Much as we can form linear constraints of the form
A · c ≤ k1 and Aeq · c = k1 , we can form non-linear constraints D(c) ≤ k and
Deq(c) = k. We pass fmincon these non-linear constraints as a function, in
precisely the same way that we have been deﬁning and pointing to the objective
function we wish to maximise. Rather than belabour this point in words, let’s
work through an example below in code:

function [d,deq] = flowConstraint(CK,T,K1,theta,alpha)
% flowConstraint(C,k,T,K1,theta,alpha) sets up the system
% of constraints k_{t+1}=\theta (k_t-c_t)^\alpha. It
% requires CK, a Tx2 matrix of consumption and capital
% values in each of the T periods, K1, the stock of k at
% the beginning of the first period, and the production
% function parameters alpha and theta.
cap
c
k

=
=
=

CK(:,2);
CK(:,1);
[K1; cap];

for t = 1:T
deq(t)
end
d
= [];

=

k(t+1) - theta * (k(t) - c(t))^alpha;

return

We suggest you run through the above code carefully to ensure that it makes
sense to you. There are a number of things going on here, some of which may
not be entirely obvious. For example, it is important to note that non-linear
constraints must return two outputs (which we call d and deq in the ﬁrst line of
our function). These correspond to strict non-linear equalities, and non-linear
inequalities. Given that (8.4) is a system of T equality constraints, we just deﬁne
an empty vector for the inequality constraints d.
118

Try experimenting with the flowconstraint function by passing it the entire
set of arguments. Try situations in which deq equals zero (perhaps where α = 1
and θ = 1) and where deq = 0. A useful hint: in order to see both outputs (d
and deq) you must request these explicitly from Matlab.

Thus, having deﬁned our non-linear constraints which make production in one
period depend upon remaining capital from previous periods, and having deﬁned
the utility function we wish to maximise in the previous section, we can make
a call to fmincon. As long as you still have the parameters from the previous
example stored in memory (namely beta, T, and k1), we can enter the remaining
code below:

>>
>>
>>
>>
>>
>>

theta
alpha
lb
ub
guess
opt

=
=
=
=
=
=

1.2;
0.98;
zeros(10,2);
100*ones(10,2);
[10*ones(10,1), [90:-10:0]'];
('TolFun', 1E-20, 'TolX', 1E-20, 'algorithm','sqp',...
'MaxFunEvals', 100000,'MaxIter', 2000);
>> Result = fmincon(@(CK) flowUtility(T,beta,CK), guess,[],[],...
[],[],lb,ub, @(CK) flowConstraint(CK,T,k1,theta,alpha),opt)
Result =
16.5011
15.9856
15.5165
15.0944
14.7213
14.4010
14.1408
13.9543
13.8695
13.9624

91.7125
83.3386
74.8041
66.0245
56.9014
47.3159
37.1173
26.1024
13.9624
0.0000

119

We see that our optimisation returns to us a two column matrix with T = 10
rows. This two column matrix is our result for CK: consumption and remaining
capital in each period. This is of course precisely what we have asked Matlab
to give us by using the ‘function handle’ @(CK) in the fmincon command.
Finally, perhaps we are interested in producing graphical output rather than
simply having tabular output in the form of columns. We track consumption
and remaining capital in the following graph (and accompanying code). Once
again we see that as expected, all capital is consumed, and, given the particular
technology parameters deﬁned, that our household/ﬁrm has an approximately
downward sloping consumption proﬁle.
plot(T, Result(:,1), '--r', T, Result(:,2), 'linewidth', 2)
xlabel('Time', 'FontSize', 14)
ylabel('C_t,k_t', 'FontSize', 14)
legend('Consumption', 'Capital Remaining', 'Location', 'NorthEast')
title({'Firm Consumption and Investment', ...
'\beta=0.9, \theta=1.2, \alpha=0.98'}, 'FontSize', 16)
>> print -depsc DynamicBehaviour

>>
>>
>>
>>
>>

Firm Consumption and Investment
β=0.9, θ=1.2, α=0.98
80
Consumption
Capital Remaining
70

60

C ,k

t t

50

40

30

20

10

0

1

2

3

4

5

6

7

8

9

Time

Figure 8.2: Dynamic behaviour of a household ﬁrm

120

10

8.3

Introducing the Value Function

When we resolve these optimisation problems using Matlab’s solvers (the
fmincon function), we are solving for consumption directly, and eﬀecitvely in
one shot. This is what Adda and Cooper (2003) refer to as Direct Attack,
and corresponds to Stokey and Lucas (1989)’s sequence problem. The basic intuition is that Matlab (or indeed you, the Matlab user,) deﬁne(s) a vector of
possible values for consumption at each period, and then the optimal outcome
is found by shifting consumption between periods until further utility gains are
exhausted. If we were to solve (8.3) algebraically for the ﬁrst-order conditions,
we would ﬁnd that this implies a series of equations:
u (ct )

= βu (ct+1 )

u (ct )

= β 2 u (ct+2 )

and so forth. These are the Euler equations, and when these hold this suggests
that further gains from rearranging consumption over time may be unable to
be made.
This method of (numerical) direct attack is not the only way to consider resolving dynamic optimisation in Matlab. We could also consider using Dynamic
Programming. The idea behind dynamic programming is that rather than
solving a complex optimisation which considers consumption in T periods all
at once, we can break this down into a number of much simpler optimisation
problems. Intuitively, from the point of view of the household ﬁrm in the ﬁnal
period, the problem is quite simple: maximise utility given the total amount
of remaining k. Of course, given that k has no value to the household beyond
the T th period (we assume that the good spoils), their optimal behaviour is to
consume all remaining k. Then, having ‘resolved’ for the optimal ﬁnal period
behaviour, we can consider the consumer’s behaviour in period T − 1. In this
case their goal is maximise the value of current consumption and the discounted
value of future consumption. Given that we know the value of future consumption (we resolved this in the ﬁrst stage), this is just a matter of how much to
consume in T − 1, and how much to save for T which will then be consumed
optimally. We can then continue this process, moving to period T − 2, where
the decision becomes how much to consume in this period, and how much to
consume in the future (T − 1 and T ). Thus, we solve a series of T optimisation

121

problems which are eﬀectively two period in nature: now and the future.
The important element of dynamic programming is that at each step we can
form a single summary statistic for ‘the future’, which is simply the value of
all remaining capital when consumed optimally. Thus, to solve for any given
period, we must have already solved for ‘the future’. For this reason in dynamic
programming we follow a process of backwards induction: we ﬁrst solve for the
ﬁnal period, then for the penultimate which depends upon the ﬁnal, then for
the second last which depends upon the penultimate and the ﬁnal, and continue
this until we arrive at the ﬁrst period. Once solving for optimal behaviour in
each subproblem of two periods, we combine all these optimal subproblems to
ﬁnd the ﬁnal solution.
This may all seem slightly abstract, so we will introduce some mathematical
notation, and then see how it works in practice in Matlab. We ﬁrst introduce
the idea of the value function. This summarises the value to the household of
a given amount of capital, assuming that this capital is used optimally. Whilst
we can’t say much about the value function yet, one thing we do know, is that
the value of any capital which remains beyond the ﬁnal period is zero, given
that it spoils. This allows us to deﬁne the following:
VT +1 (kT +1 ) = 0

∀ k.

(8.7)

Eﬀectively, for for any amount of remaining k after the ﬁnal period, the future
value ﬂow to the household is zero. This then gives us a place to start for our
backwards inductions. When making their optimal decision in period T , the
household resolves:
VT (kT ) = max {u(cT ) + βVT +1 (kT +1 )}
cT

(8.8)

where kT +1 = kT − cT . Given that we already have our terminal condition from
(8.7), the equation 8.8 can be solved for any kt .5 This solution is precisely our
value function for period T : that is, it tells us the total value to the household
of entering period T with some amount KT , and then behaving optimally. This
in turn allows us to consider the decision in kT −1 :
VT −1 (kT −1 ) = max {u(cT −1 ) + βVT (kT )} .
cT −1

5

The solution for any value of k will be kT = cT . Why?

122

(8.9)

Here we start to see the process of backwards induction emerging. Once we
solve (8.9), we can then move on and solve for VT −2 (k), and continue (or in
reality instruct Matlab to continue) until it ﬁnally reaches V1 (k).
Let’s have a look at how a problem like this would be resolved in practice:
%============================================================
%=== (1) Prompt user to input parameters
%============================================================
Beta
T
K1
grid

=
=
=
=

input(’Input
input(’Input
input(’Input
input(’Input

Beta:’);
time:’);
initial capital:’);
fineness of grid:’);

K
V

=
=

0:grid:K1;
[NaN(length(K),T), zeros(length(K),1)];

%============================================================
%=== (2) Loop over possible values of k_{t} and k_{t+1}
%============================================================
aux
=
NaN(length(K),length(K),T);
for t =
T:-1:1
for inK
= 1:length(K)
for outK = 1:(inK)
c
= K(inK)-K(outK);
aux(inK,outK,t) = log(c)+Beta*V(outK,t+1);
end
end
V(:,t)=max(aux(:,:,t),[],2);
end
%============================================================
%=== (3) Calculate optimal results going forward
%============================================================
vf
= NaN(T,1);
kap = [K1; NaN(T,1)];

123

con

= NaN(T,1);

for t=1:T
vf(t)
kap(t+1)
con(t)
end

=
=
=

V(find(K==kap(t)),t);
K(find(aux(find(K==kap(t)),:,t)==vf(t)));
kap(t)-kap(t+1);

%============================================================
%=== (4) Display results
%============================================================
[kap([1:T],:),con]
subplot(2,1,1)
plot([1:1:T],[con, kap([2:T+1],:)], ’LineWidth’, 2)
ylabel(’Consumption, Capital’, ’FontSize’, 12)
xlabel(’Time’, ’FontSize’, 12)
legend(’Consumption’, ’Capital’)
subplot(2,1,2)
plot([1:1:T], vf, ’Color’, ’red’, ’LineWidth’, 2)
ylabel(’Value Function’, ’FontSize’, 12)
xlabel(’Time’, ’FontSize’, 12)

In order to get a handle on what this code is doing, it’s probably best to start
in section (2). Ignore for the time being the outer loop (which starts with for
t = T:-1:1), and focus on the inner two loops. Here we deﬁne a matrix called
aux (in reality a 3-dimensional matrix, but we’ll get to that...), which looks
very similar to the formula to the value function we’ve written down in (8.8)
and (8.9). This is essentially what aux is. It shows us—for each possible entry
value of k—the value to the household of a choosing a particular exit value of
capital (and corrsponding level of consumption). For example, if we enter a
given period with 20 units of kt , the household could choose to consume 20 now
and 0 in the future, 19 now and 1 in the future, 18 now and 2 in the future,
and so forth. So, aux tells us the value for all possible entry values of kt and all
possible exit values of kt+1 .

124

Once we’ve calculated this matrix for all possible input and output capital values, we can calculate the optimal decision for each possible input capital. This
is what we do 3 lines below the aux matrix. The matrix V() tells us the best
possible behaviour for any given kT —for example, were we to arrive to a given
period with kT = 20, we may ﬁnd that the optimal choice is to consume 5 now,
and save 15 for the future (and so can discard the other 20 possible combinations). You may wonder why we bother doing this for each possible input capital
value. For example, why is it important to know what the household would do if
it were to arrive with 20 units, if in reality it arrives and has 19 units of capital?
The reason why we have to program such a computationally intensive process
is that we won’t know what decisions are made for consumption (and hence
capital) in each period until we completely solve the model, and to be able to
solve the model we must know the what the value function looks like in future
periods.6 We call the vector V the value function because it is a solution for all
possible values of k. While it may not necessarily oﬀer a closed form solution
in the form of an algebraic function, numerically at least Matlab allows us to
calculate the output value for V over some domain of k—precisely the deﬁnition
of a function with which we are familiar.
This brings us to the heart of dynamic programming (at least when considering
problems with a ﬁnite horizon). When resolving, we must iterate backwards to
solve the model, and only then can we iterate forward to obtain the objective
function. This is why you see two loops involving time (those starting with for
t =...) in the above code. The ﬁrst of these loops calculates the value function
starting in period T and counting backwards to the ﬁrst period. Once having
calculated the value function, the second loop determines how much capital to
consume in each period, starting from period 1 and ending in period T. The
reason we must start in period 1 in this case is because this is the only period
where we know with certainty what the beginning capital will be. For example,
in the code in sections 8.2.1 and we know that the initial endowment or stock
of capital was 100. Eﬀectively we need something like this initial condition to
pin down the solution.
Now that we’ve discussed a few of the more cental parts of the above code, let’s
run it and see what happens. In order to test how this compares to a direct
attack using Matlab’s native optimisers, we will use the same values as earlier
6

In the next section we will also discuss another reason why such a process can be useful.

125

when prompted by our code to input the parameters:

>> backwards_induc
Input Beta:0.9
Input time:10
Input initial capital:100
Input fineness of grid:0.25
ans =
100.0000
84.5000
70.7500
58.2500
47.0000
37.0000
28.0000
19.7500
12.5000
6.0000

15.5000
13.7500
12.5000
11.2500
10.0000
9.0000
8.2500
7.2500
6.5000
6.0000

When we compare the consumption values—which are returned as the second
column of the above output—with those calculated from the direct attack in
section 8.2.1, we will note that we have lost some precision. This occurs due to
the fact that here we had to discretise the possible values of kt and kt+1 . You
will note that in section (1) of the code we deﬁne the possible values of capital
as K = 0:grid:K1;. This allows the household to choose any possible values
between 0 and full amount K1, in steps of size grid. Given that in the above
example we have speciﬁed a grid of 0.25, we are losing some precision in our
solution. Depending upon the computational resources you have available, you
may wish to see how this solution changes as we deﬁne ﬁner and ﬁner grids over
which to search.7
7

For general interest, with a grid size of 0.05 we ﬁnd that Result(:,2)’ = 15.3500 13.8000
12.4500 11.2000 10.1000 9.0500 8.1500 7.3500 6.6000 5.9500.

126

Consumption, Capital

100
Consumption
Capital

80
60
40
20
0

1

2

3

4

5

6

7

8

9

10

6

7

8

9

10

Time

Value Function

20
15
10
5
0

1

2

3

4

5

Time

Figure 8.3: Resolving dynamic behaviour using a value function

Exercise: In the above code we have solved for a ﬂow equation of the form
kt+1 = kt − ct . Modify the code to solve for kt+1 = θ(kt − ct )α (and conﬁrm
that this is correct by referring to the results from section 8.2.1). A useful hint:
this can be incorporated into the above code with two fairly minor changes.
Concentrate only on the formulas which deﬁne consumption (c and con).

8.3.1

Computational Accuracy, Curse of Dimensionality
and Memoization

In the above example we have seen that the accuracy of the solution of these
types of problems depends upon the grid size we ask Matlab to search over.
Of course, if we want a highly accurate solution, we could just specify a very
ﬁne grid, such as an increment of 0.001. The problem with such an approach
127

however, is that this will very quickly become quite demanding on the processing
capacity of many personal computers unless we are quite careful about the way
we write our code (and not long after, even if we are quite careful).
The main bottleneck in this code comes about as we need to calculate an intermediate step for each possible capital pair combination (as we see in the aux
matrix in the last code example). For example, if we specify a grid search of
0.1 (which allows us to calculate optimal consumption to one decimal place),
we see that:

>> size(aux)
ans =
1001 1001 10

Similarly, when we try with a grid size 0.01, we have that size(aux)=10001
10001 10, and were we patient (or brave?) enough to try with a grid size of
0.001, we would be dealing with a matrix with 100 billion individual elements.
Whilst perhaps we would be willing to accept waiting a reasonable amount of
time to solve this one problem very accurately, it is unlikely that we could aﬀord
such a luxury if we were resolving this for many households (rather than one),
or if rather than dealing with one state variable we were dealing with multiple.
Such a situation is well known in Dynamic Programming, and was labelled the
curse of dimensionality by Bellman (1957) when introducing the principles
we’ve laid out above. Whilst we will not delve too deeply into solutions to
this problem here, we will provide some discussion of alternative optimisation
techniques in chapter 9, and refer the interested reader to the large body of
work on dynamic optimisation and interpolation, perhaps starting with Keane
and Wolpin (1994) or the text-book exposition of Adda and Cooper (2003).
Given the somewhat demanding form in which we have resolved the above dynamic programming problem, we likely want to avoid solving it repeatedly were
we to use this in microeconometric applications with various individuals. Matlab, and computational-based numerical solutions in general, oﬀer a way to do
precisely this. Memoization (Michie, 1968) refers to the process of ‘remem-

128

bering’, rather than re-computing, results for use in subsequent analysis. As
Michie suggests, “It would be useful if computers could learn from experience
and thus automatically improve the eﬃciency of their own programs during execution. A simple but eﬀective rote-learning facility can be provided within the
framework of a suitable programming language”. Above in step 2 of our code we
entirely solve the problem for any possible starting value and ﬁnishing value of
capital in each period. Only once we have completely solved this problem (and
stored all possible solutions in aux and V!) do we actually determine what the
household does when starting with a capital value of k1 = 100. However, if we
suddenly become interested in a household whose k1 = 50, we have memoised
our solution from step 2, so need to do no further backwards induction. Similarly, if our household unexpectedly receives an additional amount of capital in
between periods 3 and 4, we simply follow our memoised solution, avoiding the
main cost of calculation. We will see the importance and ﬂexibility of such a
situation below, where we consider stochastic dynamic programming.

8.4

Shocks, Uncertainty, and Microeconometrics

Having gone through the above code and discussion, this more or less gives us
the tools required to set up any ﬁnite horizon dynamic programming problem.
Perhaps the most obvious remaining question is how to build stochastic elements
into these types of problems. Almost all economic processes are stochastic in
some sense, whether it be due to uncertainty about what will happen to state
variables like capital in future periods, uncertainty about what the decision
maker will want to do in future periods, uncertainty in external parameters
and events, measurement error in observational data, and so forth. Indeed,
microeconometrics is entirely based upon the existence of unobservable elements.
Once we try to ﬁt these dynamic models to data, such an extension will be
fundamental, as in real data, there will be shocks to a dynamic process.
The problems we have looked at so far have all been deterministic in the sense
that we knew with certainty what the decision maker would face in future periods. For example, in the household consumption example we knew that future
capital would just be current capital minus current consumption, while in the
129

ﬁrm example we knew that capital—our state variable—follows a Cobb-Douglas
process: kt+1 = θ(kt −ct )α . A much more relasistic situation might be one where
future capital follows something like the aforementioned process, but which is
subject to positive or negative shocks.
Let’s imagine for the moment that evolution of capital is subject to a stochastic
shock, so our transition equation (8.6) is now revised as:
kt+1 = f (kt − ct , θ, εt+1 ) = θ(kt − ct )α + εt+1 .

(8.10)

Here ε could be thought of as an unknown return on investment, which is only
resolved in the subsequent period. However, at moment t, the decision maker
will be entirely aware of current kt , all technology parameters, and we assume,
the distribution of possible εt+1 (and hence kt+1 ).
Now, rather than deciding between consumption now and consumption in the
future, the decision must be framed in terms of consumption now and expected
consumption in the future. This suggests a re-writing of the dynamic programming problem as:
Vt (kt ) = max{u(ct ) + βE[Vt+1 (kt+1 )]}
ct

(8.11)

where kt+1 is represented in (8.10), and the expectation is taken over the distribution of εt+1 .
In previous sections, we have illustrated these concepts by assuming certain
vaules and functional forms for our key parameters and functions. Similarly,
here we will assume a reasonably simple structure for the ε term. Speciﬁcally,
we assume that ε takes two possible states: low and high. We will assume that
1
each state occurs with a probability of 2 , and that returns in each case are
ε ∈ {−2, 2}.8 Hence, we can eﬀectively fully characterise the stochastic portion
of this problem with two vectors: a vector of returns: [-2, 2], and a vector of
probabilities [0.5, 0.5]. Of course, were we to enter these vectors into Matlab,
ﬁnding the expectation of ε should be a relatively straightforward process.
8

For those interested in a more extensive discussion of modelling stochastic processes with
dependence in dynamic systems, we point you to any of a multitude of resources which
discuss the Markov property and Markov chain for shocks. Stachurski (2009) for example
provides a very nice overview.

130

Now, with the incorporation of stochastic elements into the optimisation problem, we should rewrite the backwards induction to allow us to compute the
value function V for each possible future value of k at each time period. Fundamentally, this involves an additional step, as rather than just having that
J
kt+1 = θ(kt − ct )α , we have that E[kt+1 ] = θ(kt − ct )α + j πj × εt+1,j , a
formula we translate to Matlab in the line which calculates EnextK.
clear; clc
%==============================================================
%=== (1) Setup parameters
%==============================================================
epsilon = [2 -2]; PI
= [0.5 0.5];
Beta
= 0.9;
alpha
= 0.98;
K1
= 100;
grid
= 0.2;
T
= 10;
theta
= 1.2;
K
V
aux

=
=
=

0:grid:K1+max(epsilon);
[NaN(length(K),T), zeros(length(K),1)];
NaN(length(K),length(K),T);

%==============================================================
%=== (2) Loop over possible values of c, k and epsilon
%==============================================================
for t = T:-1:1
fprintf(’Currently in period %d\n’, t)
for inK = 1:length(K)
for outK = 1:inK
c
= K(inK)-(K(outK)/theta)^(1/alpha);
EnextK
= theta*(K(inK)-c)^alpha+epsilon*PI’;
position
= round(EnextK/grid + 1);
aux(inK,outK,t) = log(c)+Beta*V(position,t+1);
end
end
V(:,t)=max(aux(:,:,t),[],2);
end

131

Following on from the earlier code that we have gone through, much of the
above looks similar, but there are two additional lines in the second block of
code. Firstly, the line EnextK ... which we alluded to above. You’ll note that
the diﬀerence here is that we take the expectation ε by multiplying the matrix of
possible shocks (ε) by the transpose of the probability of a given shock occurring
(π). Secondly, we add a line to ensure that this predicted kt+1 value will lie in
the future value function. Given that we do not necessarily want to restrict the
values of ε and π in any way, but we do need to limit the state space for ease of
computation, position just rounds E[kt+1 ] to the closest value in our capital
grid. In dynamic problems with continuous state variables, discretisation steps
such as this are necessary for computation.
If we run the above code in Matlab, this calculates the value function at each
of the (ten) time periods, and for each possible (optimal) capital–consumption
pair. Having run this once, we can save these results (that is to say memoise
the above function), and then consider particular realisations of the shocks, and
the resulting consumption paths. As a decision maker’s particular consumption
path depends upon the values of ε at each point in time, there is not one
optimal result. In the below code we consider 100 diﬀerent individuals, and
speciﬁc draws from the distribution of ε.
%=============================================================
%=== (1) Setup parameters, simulate shocks
%=============================================================
people
=
100;
epsilon
epsilon(epsilon==1)

=
=

randi(2,people,T+1);
-2;

vf
kap
con

=
=
=

NaN(people,T);
[K1*ones(people,1) NaN(people,T)];
NaN(people,T);

%=============================================================
%=== (2) Determine consumption based on simulated shocks
%=============================================================
for p=1:people

132

for t=1:T
position
vf(p,t)
kap(p,t+1)
con(p,t)
kap(p,t+1)
end

=
=
=
=
=

round(kap(p,t)/grid+1);
V(position,t);
K(find(aux(position,:,t)==vf(p,t)));
theta*kap(p,t)^alpha-kap(p,t+1);
kap(p,t+1)+epsilon(p,t+1);

end
%=============================================================
%=== (3) Output
%=============================================================
plot([1:1:T], con)
ylabel(’Consumption’, ’FontSize’, 12)
xlabel(’Time’, ’FontSize’, 12)
title(’Simulated Consumption Paths’, ’FontSize’, 16)
figure(2)
hist(sum(con,2))
title(’Lifetime Consumption’, ’FontSize’, 16)

Here we calculate each person’s actual outcome for consumption (con), capital
(kap) and the resulting value function (vf) at each point in time. The loop in
the second block of code outlines the optimal decision for each ﬁrm. Starting
at period 1 (and k1 = 100), the optimal future value function is calculated
(from our memoised V), which implies the optimal consumption and optimal
capital with which to exit the period. Then, prior to making the decision in the
following period, the shock ε is realised, giving the actual capital the decision
maker has to work with.
Figure 8.4 describes these optimal consumption paths for our 100 simulated
decision makers. As you would perhaps expect, in period 1 (where each ﬁrm
has the same capital endowment) all ﬁrms decide to act in precisely the same
way. In following periods however, depending on the actual realisations of ε
(and hence k), optimal behaviour diverges.

133

Simulated Consumption Paths
20

18

Consumption

16

14

12

10

8

1

2

3

4

5

6

7

8

9

10

Time

Figure 8.4: Simulated Consumption in a Stochastic Model

Lifetime Consumption
20
18
16
14
12
10
8
6
4
2
0
130

135

140

145

150

155

160

165

170

Figure 8.5: Total Simulated Consumption in a Stochastic Model

134

8.5

Review

Command

Brief Description

subplot
input
ﬁnd
print
clc
ﬁgure

Display multiple graphs on one output
Prompt user input from the keyboard
ﬁnd location(s) of exact coincidence in a matrix
print to disk the item currently in graphical memory
clear results screen
output various ﬁgures in a Matlab script
Table 8.1: Chapter 8 commands

135

Chapter 9

Dynamic Choice on an
Inﬁnite Horizon
“Bigger than the biggest thing ever and then some. Much bigger
than that in fact, really amazingly immense, a totally stunning size,
real ‘wow, that’s big’, time. Inﬁnity is just so big that by comparison, bigness itself looks really titchy. Gigantic multiplied by colossal
multiplied by staggeringly huge is the sort of concept we’re trying
to get across here.”

Douglas Adams, “The Hitchkiker’s Guide to the Galaxy”

If you’re following this book linearly, in the previous chapter you’ll have gone
through a number of issues involved in determining optimal choice across time
periods, including an outline of the ideas behind Bellman’s functional equation.
In setting up all of these solutions, we’ve relied on having some known point
from which to anchor things: typically the fact that no value remains if goods
are left unconsumed after the ﬁnal period of time. Once we have this ﬁnal period
to act as an anchor, we are able to iterate backwards, and in this way calculate
the value function—and as a result optimal decisions—in all time periods.
136

But, you might ask, how would we move ahead were we not to have such a point
to work from? What if we are solving a problem that doesn’t have a terminal
point at all? There are many times in microeconometric problems where this
may be a relevant concern. For example, it seems unlikely that many ﬁrms
would plan to close up shop at a deﬁned point in the future. Indeed, even in
the case of individuals deciding over their lifetime, the terminal point may be
so many periods away1 (hopefully!), so uncertain, and discounted in such a way
that acting as if the horizon is inﬁnite may be the most reasonable approach
when searching for a solution.
Problems of this type—those that never end and hence have no terminal point
as an anchor—will require another class of solution. Fortunately, such a situation can be well-served using the ideas motivated by Bellman (1957) which
we discussed in chapter 8. In the sections ahead we will have a look at this
class of solutions, and set up some implementations in Matlab. Once again
though, there are many applications, and we will only scratch the surface. We
hope that this outline should provide you with a strong foothold in how to set
up a wider range of these problems, but direct the interested reader to further
resources such as Acemoglu (2008); Adda and Cooper (2003); Ljungqvist and
Sargent (2000); Judd (1998); Dixit (1990) and the many papers cited therein.2
In this chapter we return to the problem outlined in Chapter 8 which represents a ﬁrm’s decision over how much to invest now, and how much to save
for the future. This problem has a long history in economics, being described
by Ramsey as early as 1928 (although applied to countries rather than ﬁrms;
some examples for ﬁrms include Bond and S¨derbom (2005); Fafchamps et al.
o
(2011)). The objective is to maximise total discounted utility, subject to the
1

2

Of course, the idea of a ‘period’ is quite nebulous. For example, when deﬁning these
problems, should we consider a period to be a year? Or a month? Or a day? Generally we
will allow the context of a problem to dictate the length of a period. For example in optimal
child-bearing decisions a woman can only become pregnant at most once every 9 months, in
job search a searcher can receive job oﬀers which much greater frequency (depending upon
search intensity), and so forth.
Much work on dynamic programming with an inﬁnite horizon has been done in macroeconomics, for example considering country growth rates and investment decisions. There
is a large literature in this area, including resources on the application of these problems
in computer languages (see for example the excellent references of Stachurski (2009) and
Sargent and Stachurski (2013) in Python, or Collard’s online lecture notes on value function
iteration in Matlab with a macroeconomic focus.)

137

ﬂow equation for capital:
∞

β t−1 ln(ct )

max
∞

{ct }t=1 ,{kt }∞
t=2

subject to

kt+1

α
= θkt − ct

t=1

ct

≥ 0

kt

≥ 0.

(9.1)

You will note here that we are assuming quite a particular functional form:
that of log utility and Cobb-Douglas production. There is a reason that we
make these assumptions. Such a functional form allows for us to ﬁnd both an
analytical and a numerical solution. Typically ﬁnding an analytical solution to
dynamic problems of this type is not possible or very diﬃcult—meaning that
we have to revert to numerical tools like Matlab. However, in this case having
both solutions is quite handy. We can see how we would resolve this in Matlab,
while also having the exact solution against which we can compare our results.

9.1
9.1.1

Value Functions and Inﬁnite Solutions
A Rough Outline

In the previous chapter we introduced the notion of Bellman’s functional equation to solve dynamic optimisation problems (see for example equation 8.8).
The basic idea is that we break down an optimisation problem which runs over
many periods into two periods: now (ie the current period), and the future,
where the value of the future is represented by a ‘functional equation’ which we
have been labelling V . This looks something like:
˜
V (k) = max u(c) + βV (k)
˜
c,k

(9.2)

where here rather than rely on time subscripts we are using a tilde over a
˜
variable (such as k) to signify future values, and no tilde (ie k) to denote current
3
values. Substituting the functional forms we assumed in (9.1), into our Bellman
3

This notation is not without reason. We use it given that time does not actually enter into
the Bellman equation at all. In other words, the Bellman equation is stationary.

138

equation implies that (9.2) will end up looking like:
˜
˜
V (k) = max ln(θk α − k) + βV (k) .

(9.3)

˜
c,k

So far this looks much like what we have done so far in ﬁnite horizon problems.
However as we suggested in the introduction to this chapter, in inﬁnite horizon
problems, we have (by deﬁnition) no ﬁnal period, so backwards recursion from
VT is no longer a viable option. Fortunately we have a way forward using the
tools we’ve already been looking at. Much work exists to show that if we choose
an arbitrary value function—say for example V (k) = 0 × k = 0, and iterate on
this value function, we will eventually converge on the true value function.
If you will permit us to be somewhat verbose on this point, this implies that we
choose some arbitrary initial function, in this case a vector of zeros, and plug
˜
this into the right hand side of (9.3) as V (k). Resolving (9.3) will give us a new
value function (ie the left-hand side of (9.3)). If we then plug this new value
function back into the right-hand side of the equation, we will once again get
a new value function, which we yet again substitute into (9.3) ad inﬁnitum –
or rather, until the value function on the left-hand side is equal to the value
function on the right-hand side. At this point our convergence is complete, and
we know that we have the true value function. Essentially then, we are searching
for a ﬁxed point which implies that we have determined a function V (·) which
summarises the value of behaving optimally forever more. You may note that
in this case the same V (·) enters both sides of the functional equation (9.3)
implying stationarity, or that optimal consumption just depends upon capital,
and not upon the time period in which the ﬁrm ﬁnds itself.
In more compact form, we are interested in calculating:
˜
˜
Γ V (k) = max ln(θk α − k) + βV (k)
˜
k

∀ k,

(9.4)

where Γ is an operator representing this process of iteration on the value function until the point that Γ V (k) = V (k). We do not think that this book is
the place to provide a great deal of detail on the maths (and certainly not the
mathematical proofs!) behind this idea. However, we do provide an appendix to
this chapter where we show analytically how value function iteration works. If

139

you are after more precise mathematical details about the process of value function we would refer you to one of the previously cited texts such as Ljungqvist
and Sargent (2000), or alternatively, to Bertsekas (1976, 2005), as from here
on we choose to focus entirely on the computational aspects of the problem.
In order to do so, we would ask that you convince yourselves (or perhaps you
are already familiar with the maths behind dynamic optimisation) that this
particular Bellman equation (9.3) can be satisﬁed by a value function of the
form:
α
V (k) =
ln k + F
(9.5)
1 − βα
where F just represents a constant, and that this value function implies the
following policy function:
c(k) = θk α (1 − βα).

(9.6)

If you are not entirely convinced, or if you simply wish to brush up on your
math here, we direct you to the aforementioned appendix to this chapter where
we show that this is the case.

9.1.2

Computation

The Value Function

In moving to computation then, the question becomes how we can actually
instrumentalise the iteration process Γ V (k). From (9.4) a number of things
˜
perhaps stand out. We will likely have to calculate θk α − k, we will likely have
˜ we will want to choose
to try this over a range (or grid) of diﬀerent values of k,
˜
the ‘best’ outcome for k in the sense that it maximises Γ V (k), and ﬁnally, we
will want to do this for ‘all’ values of k. Let’s have a look at some code. . .
function [TV optK] = iterateVF(V,maxK)
% iterateVF(V,maxK) takes a potential value function V and
% performs an iteration, returning the updated proposed value
% function TV. When TV==V, we have found the true value
% function. The scalar maxK represents the maximum possible
% amount of capital that can be consumed in one period

140

%============================================================
%=== (1) Basic Parameters
%============================================================
alpha
= 0.65; beta = 0.9; theta = 1.2;
grid
K
TV

=
=
=

length(V);
linspace(1e-6,maxK,grid)’;
zeros(length(V),1);

%============================================================
%=== (2) Loop through and create new value function for each
%===
possible capital value
%============================================================
for k = 1:grid
c
= theta*K(k)^alpha-K(1:k);
c(c<=0)
= 0;
u
= log(c);
[TV(k) optK(k)] = max(u + beta*V(1:k));
end
return

This code provides one iteration of the value function, after being passed a
proposed value function V, and given an upper bound for capital (maxK). The
ﬁrst section simply inputs our necessary parameters so we won’t discuss this.
The second section is the important part of this function. Firstly we loop over
all possible values of k. This ensures that when we ﬁnd our ﬁnal solution, it
will hold for all k. In this loop we calculate utility based on all possible values
˜
for k – in the ﬁrst line of the loop we deﬁne a vector of possible values for
˜
k: from lowest possible K value, right up to the entire amount k. From there
we maximise the current iteration of the value function: here deﬁne a vector
which gives us two outputs: TV(k) which is the maximised value function, and
optK(k) which is the capital value associated with this maximum (note that if
this is unclear to you, it may be worth reading the help ﬁle for max).
Now that we have deﬁned a function iterateVF which allows us to make one
141

iteration of a value function, we will want to implement this by passing this
a proposed value function, and receiving an updated value function. As per
the appendix of this chapter, we will subscript proposed value functions with
j ∈ [0, ∞) to signal the iteration number. In this case V0 will be our starting
point (which we will arbitrarily deﬁne as V0 (k) = 0), and the result for the ﬁrst
iteration will be labelled as V1 (k). In the following code we run through 10
value function iterations, in which case the ﬁnal result will be V10 (k).
%==============================================================
%=== (1) Set parameters, plot analytical solution
%==============================================================
Beta = 0.9; alpha = 0.65; theta = 1.2; aB = alpha*Beta;
K = linspace(1e-6,100,1000);
E = alpha/(1-aB);
F = 1/(1-Beta)*(log(theta*(1-aB)) + aB*log(aB*theta)/(1-aB));
soln = E*log(K)+F;
plot(K,soln, ’-k’, ’LineWidth’, 3)
axis([0 100 -15 10])
hold on
%==============================================================
%=== (2) Plot 10 value function iterations
%==============================================================
TV = [zeros(1000,1) NaN(1000,9)];
for iter = 1:10
fprintf(’Iteration number %d\n’, iter)
TV(:,iter+1)=iterateVF(TV(:,iter),100);
end
plot(K,TV)
xlabel(’Amount of Capital’, ’FontSize’, 12)
ylabel(’Value Function’, ’FontSize’, 12)
title(’Value Function Iteration’, ’FontSize’, 14)

The above script stores our 10 value function iterations in the matrix TV, along
142

with the initial value function which is just a vector of zeros. Along with these
value function iterations which we calculate in Matlab, we also deﬁne the
analytical solution which we can use as a comparison to our numerical solutions.
The resulting output is presented in ﬁgure 9.1. You’ll probably notice a few
things in this ﬁgure. Firstly, the initial value functions (the thin coloured lines)
seem to converge reasonably rapidly towards the true value function (the thick
black line). However, there’s clearly more work to do. Our 10th iteration, V10 (k),
(the light blue line), is not that close to the target result.

Value Function Iteration
10

Value Function

5

0

−5

−10

−15

0

10

20

30

40

50

60

70

80

90

100

Amount of Capital

Figure 9.1: Convergence after 10 Iterations

In this case we can write another script in which we explicitly require the value
function to converge before stopping. This time we won’t use a loop which
deﬁnes a certain number of iterations (as we did above in the code with for
iter=1:10), but rather we will ask Matlab to itearate on our code until a
certain condition is met. The idea here is that our value function iteration will

143

have ‘converged’4 when Vj+1 (k) ≈ Vj (k) ∀ k. In order to operationalise this in
Matlab we use a while loop. As long as the following convergence criterion is
not met, we ask Matlab to keep iterating on the value function.
||Vj+1 (k) − Vj (k)|| ≤ ε ∀ k

(9.7)

In the code which follows our ε is labelled crit (which we deﬁne as 0.01), and
at the end of each iteration we calculate ||Vj+1 (k) − Vj (k)||, which we call conv.

%==============================================================
%=== Convergence to the Value Function
%==============================================================
conv = 100;
crit = 1e-2;
K
= linspace(1e-6,100,1000);
V
= zeros(1000,1);
axis([0 100 -15 10])
hold on
cc
=
Iter =

hot(70);
0;

while conv>crit
Iter
= Iter+1
[TV opt] = iterateVF(V,100);
conv
= max(abs(TV-V))
plot(K,TV, ’color’, cc(Iter,:))
V
= TV;
end

The output from this code is presented in ﬁgure 9.2, and here we see that our
value function does indeed converge. In this graph we’ve used Matlab’s inbuilt
4

We write converged in inverted commas here to imply that it is a slight abuse of nomenclature. In numerical iterations we will never have true convergence of the value function.
Rather, contiguous value functions will move closer and closer to one another as we iterate
towards inﬁnity until the distance between them is extremely small.

144

“colormap” hot, which results in higher iterations on the value function being
‘hotter’ colours. As with all the code outputs in this book, we suggest you look
up any functions that you aren’t familiar with in Matlab’s help ﬁles or on
the web, and encourage you to play around and see how the results react to
diﬀerent input parameters. What happens to the following code if you start
with an alternative V0 (k) for example? How about if you make a more ﬁnely
spaced capital grid?

Value Function Iteration
10

Value Function

5

0

−5

−10

−15

0

10

20

30

40

50

60

70

80

90

100

Amount of Capital

Figure 9.2: Convergence to the True Value Function

The Policy Function

After all of this work to ﬁnd the value function in problems with an inﬁnite
horizon, you may be wondering how we actually determine what our ﬁrm’s
optimal behaviour is. More speciﬁcally, how much should the ﬁrm consume at
a given point in time, and how much should it save? Fortunately, ﬁnding this
145

policy function—that is c(k), or the mapping from capital to consumption—is
reasonably straightforward.
You may remember that in the function iterateVF, we solved for both the
value function at each point on our capital grid, along with the corresponding
optimal amount of capital consumption at this point. If you want to refresh
your memory, have a look at the ﬁnal line of the loop in section 2 of this code.
You’ll also notice that we return this optimal capital vector when we deﬁne the
Iterate VF (to review functions and returning vectors, see chapter 1). And
ﬁnally, when we run our optimal convergence code, for each iteration we save
two vectors: TV, the value function, and opt, the optimal amount of capital
consumption.
In this case, generating the policy function is just a question of applying these
optimal capital values to our capital grid K. In the ﬁve lines of code which
follow we show how we generate ﬁgure 9.3b. This shows both our numerically
calculated policy function (the solid blue plot), along with the exact analytical
result we derived in appendix 9.A.

>>
>>
>>
>>
>>

aB = 0.65*0.9; theta = 1.2; alpha = 0.65;
plot(K,K(opt),K,aB*theta*K.^alpha, '--r', 'LineWidth', 3)
xlabel('Amount of Capital', 'FontSize', 12)
ylabel('Optimal k_{t+1}', 'FontSize', 12)
title('Policy Function for Capital Consumption', 'FontSize', 14)

Exercise: Create similar graphs to these optimal kt+1 graphs displayed as 9.3a
and 9.3b (with both analytical and numerical predictions) for optimal consumption at t based upon the amount of capital in hand at t.

9.2

Policy Iterations and Faster Solutions

In the previous section we saw that iterating on the value function in Matlab
is quite an eﬀective way to ﬁnd the numerical solution to these inﬁnite horizon
146

Policy Function for Capital Consumption

Policy Function for Capital Consumption

10

10

Optimal k

Optimal kt+1

15

t+1

15

5

0

5

0

10

20

30

40

50

60

70

80

90

0

100

Amount of Capital

0

10

20

30

40

50

60

70

80

Amount of Capital

Figure 9.3a: Calculated Best Path

Figure 9.3b: True Best Path

problems. However, this value function iteration is not necessarily computationally cheap. In some cases this may not concern you. If the ‘traditional’ value
function iteration works for your particular problem you may be happy to learn
and apply this, rather than focusing on more eﬃcient reﬁnements. However, in
other cases you may ﬁnd that it is worth your while to spend some time learning
how to further optimise your code. If, for example, you expect to work with a
very large state space, you may ﬁnd that each additional iteration on the value
function takes a long time to complete. If this is the case, the remainder of this
section is for you. . .
As we saw with the code ConvergeGraph.m, we required 66 iterations before
Vj+1 was close enough to Vj for us to consider that the function had ‘converged’.
What’s more, in this code, we deﬁne ‘convergence’ as a situation where ||Vj+1 −
Vj || < 0.01. Were we to set a more rigorous convergence criterion (which we
control in the second line of ConvergeGraph.m), we will require (perhaps many)
more iterations to solve the problem.5
One particularly useful alternative manner to solve this problem is the socalled Howard Improvement Algorithm or policy function iteration (Sargent, 1987). Rather than iterate to calculate the value function, and then from
5

For example, setting a convergence criterion of 1e-6 means that our problem now takes 153
iterations to converge.

147

90

100

this the policy function (ﬁgure 9.3b), the Howard Improvement Algorithm alows
us to directly solve for the policy function. Fortunately, as we will see, this algorithm typically converges to the true policy function in much fewer steps than
the value function iteration in section 9.1.2.
In broad terms, the policy function iteration looks like the following, where the
process is initialized by setting some initial arbitrary value function Vj = V0 ,
and deﬁning some stopping criterion ε:

(i) Based upon Vj , determine optimal consumption for each k, giving a proposed ‘policy function’, cj (k)
(ii) Calculate the payoﬀ associated with this policy function, u(cj (k))
(iii) Calculate the value of following this policy function forever, Vj+1
(iv) If ||Vj+1 − Vj || < ε stop, or else return to step (i) for another iteration

The increase in the eﬃciency of this routine comes from calculating a value
function associated with following the policy function forever in step (iii). In the
traditional value function iterations we’ve been calculating so far, the calculated
policy function is only followed for one period before again iterating to calculate
Vj+1 . While policy function iteration generally takes many fewer steps than
value function iteration, there is one computationally heavy step involved in
calculating the value function from the policy function. To see this, consider
solving for the unknown Vj in the following computation6 :
Vj
⇒ Vj

= u(cj (k)) + βQj Vj
=

(I − βQj )−1 u(cj (k)),

(9.8)

where I is the identity matrix, and Q a matrix which keeps track of the capital
stock associated with a given Vj .7 At each step of (9.8), which corresponds to
item (iii) on the above list, Vj is calculated by matrix left division; this can be
a computationally demanding process.
6
7

Here we borrow the notation of Judd (1998), and direct you to his discussion on pp. 411–417
should you be interested in further details
In the case of a stochastic inﬁnite horizon model, Q acts as a transition matrix describing
the probability of each realisation in the stochastic portion of the model. We do not go into
that here, and refer you once again to resources such as Judd (1998) if you’re interested in
these sort of details.

148

Below we lay out how the above enumerated list would look in Matlab code.
We suspect that by now you will be familiar with many of these commands, so
will spare you a step-by-step discussion, and will leave it to you to examine this
at the command line. We will however point out the use of Matlab’s sparse
routines, given that the matrix Q in (9.8) is made up largely of zeros.

function [V,opt] = Iterate_Policy(V, maxK)
% Iterate_Policy(V, maxK) takes an aribitrary value function
% V and iterates over the policy function c(k). At each step
% it calculates an updated policy function c_j(k), and a
% corresponding value function V_j(k), which is the value of.
% following c_j(k) forever.
%
% see also iterateVF
%============================================================
%=== (1) Parameters
%============================================================
alpha = 0.65; beta = 0.9; theta = 1.2;
grid
= length(V);
K
= linspace(1e-6,maxK,grid)’;
opt
= NaN(grid,1);
%============================================================
%=== (2) Calculate optimal k for V
%============================================================
for k = 1:grid
c
= theta*K(k)^alpha-K(1:k);
c(c<=0)
= 0;
u
= log(c);
[V1,opt(k)]
= max(u+beta*V(1:k));
end
kopt =
c
=
u
=

K(opt);
theta*K.^alpha-kopt;
log(c);

149

%============================================================
%=== (3) Invert k, u to find V_{j+1}
%============================================================
Q
= sparse(grid,grid);
for k = 1:grid
Q(z,opt(z)) = 1;
end
TV = (speye(grid)-beta*Q)\u;
V
= TV;
return

Having now written an iteration for this policy function improvement step, we
can ask Matlab to loop over this a number of times until our numerical policy
function has converged. Were we to do this at the command line, we would
proceed as below. The ﬁrst four lines set graphing parameters and graph the
analytical solution, while the for loop iterates over the policy function 7 times,
starting with the deﬁned V0 = 0. Figure 9.4 presents output, and it appears as
if after only 7 iterations we are already very close to the true policy function!

>> cmap = cool(7);
>> V
= zeros(1000,1);
>> K
= linspace(1e-6,100,1000);
>> aB
= 0.65*0.9; theta = 1.2; alpha = 0.65;
>> plot(K, aB*theta*K.^alpha, '-k','LineWidth',3)
>> hold all
>> for l = 1:7
[V,k]
= Iterate_Policy(V,100);
plot(K,K(k), 'color', cmap(l,:))
end
>> legend('Analytical', 'Iter 1', 'Iter 2', 'Iter 3', 'Iter 4', ...
'Iter 5', 'Iter 6', 'Iter 7', 'Location', 'NorthWest')
>> xlabel('Amount of Capital')
>> ylabel('Optimal c_t')
>> title('Policy Function Iteration and Optimal Consumption')
150

Policy Function Iteration and Optimal Consumption

Optimal consumption

15
Analytical
Iteration 1
Iteration 2
Iteration 3
Iteration 4
Iteration 5
Iteration 6
Iteration 7

10

5

0

0

10

20

30

40

50

60

70

80

90

100

Amount of Capital

Figure 9.4: Faster Convergence to the Policy Function

9.3

Solving for Structural Parameters Using GMM

So far in this and the preceding chapter we have essentially been simulating
models and assuming that we know the relevant underlying structural parameters. We have assumed that we know an individual’s discount rate β, and the
nature of the production technology of the good that the individual or ﬁrm is
producing (that is to say we know the parameters γ and θ). For now we will
refer to this group of parameters as Ω:
Ω = (β, θ, γ)

(9.9)

While these simulations are interesting and useful to predict behaviour under
a certain parametric representation of the world, often our interest will be in
151

inverting this problem. Rather than assume that we know the true underlying
parameter set Ω and then use this to generate data, frequently we will have
data on household behaviour, and from this will be interested in estimating
these underlying parameters. This is typically the type of problem that we
are used to working with in microeconometrics: that of observing data and
recovering estimates to summarise the underlying data generating process.
So, the question now becomes whether the methods we have been looking at here
lend themselves to microeconometric modelling. Given the title of this book, you
will not be surprised to learn that the answer is a robust ‘yes’. Indeed, Keane
et al. (2011) point out that “[i]t is a truism that any dynamic optimization
model that can be (numerically) solved can be estimated.”

9.3.1

Applying GMM to Our Dynamic Model

Perhaps the most ﬂexible ways of estimating such models, and indeed a large
range of econometric problems, is by using method of moments, or generalised
method of moments (GMM). Way back in chapter 3 we talked about using
Matlab to estimate GMM, and motivated this in a linear regression framework.
The dynamic models which we have been generating and simulating in this and
the previous chapter are entirely amenable to estimation in a similar way via
GMM. While parameter estimates in a linear regression model can be generated
by forming moments based on the Gauss-Markov assumptions, our dynamic
models can be estimated if we believe that we can make reasonable assumptions
about expectations of the stochastic elements of these models.
Perhaps the trickiest part of this process is in motivating and justifying speciﬁc
moment conditions. To ﬁx ideas in our heads, we will return to the example we
have been using all along of a producer/consumer with log utility. Speciﬁcally,
we will return to the example we have discussed in section 8.4 of the previous
chapter. If you are yet to go through this section, however, there is no need to
despair. We will simply ask you to convince youself that this example results
in observations of the “true behaviour” of 100 individuals based upon their
realisations of stochastic shocks εt at each point in time. Note that although
we did simulate this data, from here onwards we will just be acting as if this

152

were real data which we received as researchers considering a particular type
of microeconometric issue. Importantly, this implies that we do not know the
true data generating process, the values of all parameters in this process, or the
nature of the stochastic elements in this ‘world’.
Method of moments estimation starts with an assumption that something in
the population is equal to zero. Let’s assume that we have reason to believe
that the expected value of the stochastic error term is zero in each period:
E[εt ] = 0 ∀ t.

(9.10)

You will note that this is simply an assumption about one moment (the mean of
a parameter) in the real world. Here we simply assume that we know something
about the mean of this unobserved term, and do not assume that we know
anything else about its distribution.8
Let’s also assume that we know the general form of the problem. We’ll imagine
that we know that our agent is a utility maximizer, subject to a stochastic ﬂow
equation for capital:
T

β t−1 u(ct )

max

{ct }T
t=1

subject to

kt+1 = f (kt , ct ) + εt+1 .

(9.11)

t=1

Now, by combining (9.10) with (9.11), we have immediate candidates for moment conditions. The ﬁrst comes from simply rearranging the capital ﬂow equation, expressing in terms of ε, and taking expectations of both sides. The second
comes from the Euler equations. These state that the marginal rate of substitution of consumption between periods should be equal to the marginal return
8

This is, perhaps, one of the nicest things about method of moments based estimation.
Rather than making a full distributional assumption regarding the nature of the error term,
we just make an assumption about one meaningful point in the distribution. This is less
demanding than what we have been assuming in earlier estimation techniques where maximum likelihood was used based upon a distributional assumption. We return to this point
in section 9.3.2.

153

of saved capital. These moment conditions look like the following9 :
E[kt+1 − f (kt , ct )] = 0
u (ct )
− f (kt )
= 0.
E
βu (ct+1 )

(9.12)
(9.13)

With population moment conditions in hand, we can now ﬁt the sample analogue
of these moments using our ‘data’ on the 100 individuals we simulated earlier.
Our goal is to estimate the parameters of the production technology f (kt , ct ).
We start by assuming (correctly) that the functional form for utility is ln(ct ),
and the for production is θ(ct − kt )α .10 Ideally then, we’d like to form these
ˆ
moments, and estimate Ω from equation (9.9). Unfortunately however, we will
ﬁnd we still have a problem were to try to do this. Typically in dynamic models
like the one we are working with here, the discount factor β is not identiﬁed
without placing strong restrictions on other primitives in the model.11 Normally
then, we will assume some plausible value for β, plug this into our estimation,
and based upon this assumption be able to identify the remaining parameters.
Let’s try setting up these moment conditions in Matlab:

function [Q] = dynamicMoments(ct,ctp,kt,ktp,params)
% dynamicMoments(ct,ct+1,kt,kt+1,params) returns the quadra% tic distance (scalar) based on dynamic model moments and
% specified values of alpha and theta
alpha = params(1);
theta = params(2);
beta
= 0.9;
k
= size(params,2);
%============================================================
9

Or, with our assumed functional form that f (kt , ct ) = θ(kt − ct )α + ε, they look like:
E[kt+1 − θ(kt − ct )α ]
ct+1
E
− αθ(kt − ct )α−1
βct

10
11

=

0

=

0.

This functional form also allows for the ﬂow equation we used in the earlier case that
kt+1 = kt − ct .
We will not go into this here, however an exposition can be found in Rust (1994a,b).

154

% Form moments
%============================================================
m1 = mean([ktp - theta*(kt - ct).^alpha]);
m2 = mean([(ctp./(beta*ct))-alpha*theta*(kt-ct).^(alpha-1)]);
%============================================================
% Create weight matrix and quadratic distance
%============================================================
W
= eye(k);
Q
= [m1 m2]*W*[m1 m2]’;
return

You’ll probably notice a few things that we’re doing here. Firstly, the moments
m1 and m2 are based on the functional form outlined above, and we’ve assumed
a value for β. Secondly, we’re forming only two moments here. You will note,
however, from (9.10) that we have assumed that ε = 0 in each of our T time
periods, meaning that we could create an overidentiﬁed system of moments. We
leave this case as an exercise below.
So, to estimate we’ll consider just arbitrarily choosing data from one time period and using method of moments. We’ll start by re-simulating our ‘sample’
data, and then use fminunc—Matlab’s unconstrained minimisation routine—
to minimize our objective function Q(Ω):

>>
>>
>>
>>

finiteStochastic;
simulateStochastic;
opt
= optimset('TolFun', 1E-20, 'TolX', 1E-20);
[Omega, Q] = fminunc(@(p) dynamicMoments(con(:,4),con(:,5),...
kap(:,4),kap(:,5),...
p),[1, 1], opt);

Omega =
0.9832

1.1895

155

Q =
2.7558e-08

Perhaps as expected given our somewhat ‘serendipitous’ set of assumptions, we
see that this estimation technique works well to recover estimates for α and θ.
Our estimates of 0.9832 and 1.1895 are close to the true population values of
0.98 and 1.20, and we’ll let you check whether you can improve these by using
a larger set of moment conditions to estimate.
ˆ
Exercise: In the above example we estimated α and θ by using two moment
ˆ
conditions based upon ε5 . Generalise this GMM estimation so that rather than
using two conditions you use all the (T-1)*2 moments available from εt .

9.3.2

Final Thoughts on Estimation

Before closing this chapter we think it’s worthwhile to brieﬂy discuss a few
additional points on estimating these dynamic models. Firstly, although we
motivate estimation via GMM in this chapter, there is nothing in this framework which suggests that this must be the only (or indeed even the best) way
to estimate these models. Alternative ways to estimate these models include
method of simulated moments (MSM) techniques, and even techniques which
do not involve deﬁning moments at all, such as maximum likelihood. While
techniques based around full distributional assumptions such as ML are liable
to be less accurate if these assumptions turn out not to hold in reality, in many
cases these assumptions will already be built into the structure of our model,
meaning that ML is an entirely reasonable and eﬃcient estimation technique.
This brings us to a more general point about these ‘structural’ estimation techniques. While a more structural approach allows us to pursue highly ambitious
questions which may be outside the scope of reduced form estimation techniques, the assumptions which we require to estimate these models are generally much stronger (hence the emphasis on structure!). We won’t belabour this
point too much, as it is partially outside the scope of a book on computational
156

and microeconometric methods, and especially one of this length. However,
we do encourage you to experiment with the code in this chapter to see how it
performs under alternative (and less serendipitous) assumptions regarding functional form, discount rate, and so forth, and certainly to turn to more expert
opinion if you are interested, such as Keane et al.’s (2011) handbook chapter,
and their excellent closing remarks on “how credible are DCDP models?”.

157

9.4

Review

command

brief description

linspace
hot
fsolve
sparse
speye

A linearly spaced vector based of (user-deﬁned) values
A colourmap of black, red and yellow for use in visual outputs
Solves a system of equations
Store sparse matrix in a computationally more eﬃcient way
A sparse identity matrix, with only the diagonal stored in
memory
Add a legend to a plot

legend

Table 9.1: Chapter 9 commands

9.A

Analytically Iterating the Value Function

In what follows, we use Vj to signify the value function, where the subscript
j ∈ [0, ∞) represents the iteration on the value function. Importantly, this
number does not have any link to time periods, simply telling us how many
times we have iterated over V , and hence how close we are to our solution.
From Stokey and Lucas (1989) we know that under a relatively innocuous set of
assumptions, the contraction mapping theorem implies that as j → ∞, Γ V → V
(or that our value function will converge). To start the iterations we deﬁne an
initial value function12 :
V0 (k) = 0 ∀ k.
We treat V0 as a proposed solution, where a proposed solution is only veriﬁed
as the true solution if it is determined that Vj+1 = Vj , otherwise Vj+1 becomes
the new proposed solution, and iteration continues. So, starting from V0 the
ﬁrst iteration is deﬁned by maximising the functional equation:
˜
V1 (k) = max{ln(c) + βV0 (k)}
˜
k

s.t.

˜
c = θk α − k.

(9.14)

˜
Here we use k and k to denote capital in the current and subsequent periods
respectively. In this case given that for all k the value of V0 will be 0, it is optimal
to consume all capital, giving a utility maximising consumption of c∗ = θk α .
12

This is arbitrary in the sense that starting the iteration from any resolvable value function
will still lead us to the true solution.

158

Substituting this optimal solution into our value function (9.14) gives:
=

˜
ln(c∗ ) + βV (k ∗ )

=

ln(θk α ) + β0

=

V1 (k)

ln θ + α ln k,

(9.15)

and given that V1 (k) = V0 (k) we know that our proposed V0 is not the solution
to the Bellman equation.
Now, having the result from the ﬁrst iteration, we are able to iterate again, and
continue the process of iteration until Vj = Vj+1 , in which case we have arrived
at our solution. For our second iteration we continue as above:
˜
V2 (k) = max{ln(c) + βV1 (k)}

˜
c = θk α − k.

s.t.

˜
k

(9.16)

Maximising (9.16) gives us a ﬁrst order condition of the following form:
βα
1
=
,
˜
˜
−k
k

θk α

˜
which, by rearranging implies that k ∗ =
˜
equation that c = θk α − k gives c∗ =

βα
α
1+βα θk , and substituting into
1
α
1+βα θk . Substituting these

the ﬂow
optimal

values back into our value function gives that
V2 (k)

˜
ln c∗ + βV1 (k ∗ )
1
βα
= ln
θk α
θk α + β ln θ + α ln
1 + βα
1 + βα
θ
βα
= α(1 + βα) ln k + ln
+ β ln θ + βα
θ
1 + βα
1 + βα
= E1 ln k + F1
=

where in the second line the functional form for V1 comes from (9.15), E1 and
F1 just denote constants, and once again we can verify that V1 (k) = V2 (k).
Now, similarly we can iterate again to calculate V3 (k):
V3 (k)

=

˜
max{ln(c) + βV2 (k)}

=

˜
˜
max{ln(θk α − k) + β[α(1 + βα) ln k + F1 ]}

˜
k

˜
k

159

s.t.

˜
c = θk α − k,

and here the relevant ﬁrst order condition for the above equations is:
1
βα(1 + βα)
=
.
˜
˜
−k
k

θk α

βα+β 2 2
1
˜
˜
Rearranging this FOC gives k = 1+βα+βαα2 θk α and c = θk α −k = 1+βα+β 2 α2 θk α .
2
We can then substitute these into our value function, giving that V3 (k) is:

V3 (k)

=
=

˜
ln c∗ + βV2 (k ∗ )
1
ln
1 + βα + β 2 α2

θk α + β α(1 + βα) ln

βα + β 2 α2
θk α + F2
1 + βα + β 2 α2

= α(1 + βα + β 2 α2 ) ln k + F2
= E2 ln k + F2
where once again E2 , F2 just denote constants.13
Here, yet again, we see that V3 (k) = V2 (k), however we do start to see a pattern
emerging. Indeed, were we to keep iterating ad inﬁnitum, we would ﬁnd that for
each iteration j the solution would look like Vj (k) = Ej ln k +Fj . In order to actually resolve this fully, we could keep iterating, forming V4 (k), V5 (k), . . . , V∞ (k)
as above, or we can take advantage of the algebra of geometric series. For the
ﬁrst constant Ej , the limit is as follows:
lim Ej = α[1 + βα(1 + βα + β 2 α2 + . . . + β j−1 αj−1 ] =

j→∞

α
,
1 − αβ

(9.17)

while for F we can break this down into a number of steps. From F1 and F2 we
begin to see that the general form of Fj is:
Fj = ln

13

θ
1 + βα + . . . + β j−1 αj−1

θ
+ . . . + β j−1 ln θ
1 + βα + . . . + β j−2 αj−2
βα + . . . β j−2 αj−2
+βα(1 + βα + . . . + β j−2 αj−2 ) ln
αβθ
1 + βα + . . . β j−2 αj−2
βα + . . . β j−3 αj−3
αβθ
+β(βα)(1 + βα + . . . + β j−3 αj−3 ) ln
1 + βα + . . . β j−2 αj−2
1
αβθ .
+ . . . + β j−2 (βα) ln
1 + βα
+ β ln

If you wish to do the algebra for F2 , feel free! If your algebra is correct (and we haven’t
made any mistakes) you will ﬁnd something like: F2 = ln
β2

ln θ +

β2α

βα
θ
1+βα

+ βα ln

2

2

βα+β α
θ
1+βα+β 2 α2

160

.

θ
1+βα+β 2 α2

+ β ln

θ
1+βα

+

This can be simpliﬁed into what is essentially two geometric series. The ﬁrst
line of the above equation as:
j−1

β t ln

lim

j→∞

t=0

j−1

1
θ
1 + βα + . . . + β j−1 αj−1

=
=

β t ln [θ(1 − βα)]

lim

j→∞

t=0

1
ln [θ(1 − βα)]
1−β

while the ﬁnal three lines are:
j−2

β t βα(1 + βα + . . . + β j−2 αj−2 ) ln

lim

j→∞

t=0

βα + . . . β j−2 αj−2
αβθ
1 + βα + . . . β j−2 αj−2
j−2

βt

= lim

j→∞

t=0

βα
ln(βαθ)
1 − βα

1
βα
=
ln(βαθ) ,
1 − β 1 − βα
in which case we have that
lim Fj =

j→∞

ln[θ(1 − αβ)]
βα ln(βαθ)
+
.
1−β
(1 − βα)(1 − β)

Of course, this has been an awful lot of algebra, and we might be concerned
that we haven’t actually found the closed form solution to this value function.
Thankfully we’ve already come across a way we can check this solution: all we
need to do is show that iterating once again on the above value function gives
us an identical value function (a ﬁxed point). Let’s give it a try14 ...
˜
V∞+1 (k) = max{ln(c) + βV∞ (k)}
˜
k

s.t.

˜
c = θk α − k.

(9.18)

As we have done above, we can form the ﬁrst order condition for (9.18), which
gives:
βα
1
=
.
α−k
˜
˜
θk
(1 − βα)k
˜
From here we can rearrange for k ∗ = βαθk α , and c∗ = θk α (1 − βα). If we
14

And please excuse our abuse of notation in (9.18).

161

substitute these optimal values into our value function we have:
=

˜
ln c∗ + βV∞ (k ∗ )

=

V∞+1 (k)

ln [θk α (1 − βα)] + β

=

ln[θ(1 − αβ)] βα ln(βαθ)
α
ln(βαθk α ) +
+
1 − αβ
1−β
1−β
α
ln[θ(1 − αβ)]
βα ln(βαθ)
ln k +
+
1 − αβ
1−β
(1 − βα)(1 − β)

and indeed, we ﬁnd that V∞+1 (k) = V∞ (k), indicating that we have actually
iterated onto the true solution.

162

Part V

Non-Parametric Methods

163

Chapter 10

Kernel Regression
The goal of a regression analysis is to produce a reasonable approximation to
an unknown response function, m(X), given some data {(Xi , yi )}i=1,...,N . The
relationship between yi and Xi is often modelled as:
yi = m(Xi ) + ei

(10.1)

with the common assumptions e ∼ N (0, 1) and E(e|X) = 0.
There are diﬀerent ways of modeling the conditional expectation function, E(y|X) =
m(X):

• Parametric approach: the researcher assumes that m(x) is known,
smooth and fully described by a ﬁnite set of parameters, which are to
be estimated. For example, the linear model that we all know and love:
yi = Xi β + ei

(10.2)

• Nonparametric approach: the researcher assumes that m(X) is unknown but smooth, and lets the data determine the form of m(X).
yi = m(Xi ) + ei
164

(10.3)

• Semiparametric approach: the researcher assumes a mixed model, imposing some known structure upon m(X) and letting other parts be determined by the data. For example,
yi = Xi β + mz (Zi ) + ei

(10.4)

There are many circumstamces in which a fully parametric model will work well.
However, to model certain relationships or when little is know a priori about
the underlying shape of the regression curve, a more ﬂexible approach might be
needed.
To illustrate this point, imagine that we observe the data set {yi , Xi }i=1,..,N ,
where the data generating process producing yi takes the form:
yi = sin(Xi ) + ei

(10.5)

with e ∼ N (0, 1). Although OLS provides the best linear approximation to
m(X) in a mean-squared sense, it is way oﬀ in this instance. To observe this in
matlab, try the following in the command line:

>> X = [1:100]';
>> y = sin(0.1*X) + randn(length(X),1);
>> betaOLS = (X'*X)\(X'*y)
betaOLS =
0.0012
>> plot(X, betaOLS*X);
>> hold on
>> scatter(X,y)

In the ﬁrst part of this chapter, we will explore how Nadaraya-Watson kernel
regression methods can be used to recover m(X) without strong assumptions on
the form of the data generating process. However, before we begin it is worth
noting that there are some trade oﬀs to be aware of when opting for nonparametric estimation methods. One can view parametric estimation problems as

165

5
True
OLS

4
3
2

y

1
0
−1
−2
−3
−4

0

10

20

30

40

50

60

70

80

90

100

X

Figure 10.1: OLS Misspeciﬁcation
ﬁnite-dimensional, on the other hand, nonparameric estimation problems are
inﬁnite-dimensional. This causes issues both for the interpretation of regression
output and for the convergence of estimates to the truth. Parametric estimates
typically converge at a N −1/2 rate. Nonparametric estimates typically are much
slower this, especially when the dimension of X is large.
In fact, the famous statisticians Fisher and Pearson had many a disagreement
over which was the best approach to take.1 Fisher objected to nonparametric
methods because of their relative lack of eﬃciency, whilst Pearson was much
more concenred about questions of speciﬁcation. For Pearson, the price of
parametric model ﬁtting was the possibility of gross functional misspeciﬁcation,
which would then result in large model bias. However, for Fisher, too pure a
focus upon parameter free estimation was a worry given the greater variation
in estimates in small samples and the generally poor eﬃcienct of the approach.
1

And not just in this context, throughout their professional careers, Fisher and Pearson were
bitter adversaries.

166

10.1

Basic introduction to Kernel regression

If m is believed to be smooth, then the observations at X near x
should contain information about the value of m at x. Thus it should
be possible to use something like a local average of the data near x
to construct and estimator of m(x). – R. Eubank (1988, p.7)

The basic idea lying behind nonparametric regression is to approximate the
regression curve at m(X) using the local average of response variables in the
close neighbourhood of X. More formally the procedure an be deﬁned as:
m(x) =
ˆ

1
N

N

Wi (x)yi

(10.6)

i=1

where {Wi (x)}i=1,...,N is a sequence of weights, which may depend on the whole
vector {Xi }i=1,...,N .
Most speciﬁcations for determining the precise value of these weights embody
the idea that one wants to give less weight to observations further from x.
For example, a conceptually simple approach to specifying the weight sequence
{Wi (X)}n is to describe the shape of the weight function by a density function
i=1
with a scale parameter that then adjusts the size and form of the weights near
x. This shape function is what people commonly call a kernel. The kernel is a
continuous, bounded and symmetric real function K that interates to 1.
To build intuition and the necessary methods, we’ll focus on the case where x is
one-dimensional. Additional techniques for the mutlivariate case are developed
later in this chapter. The form of the kernel in the univariate setting is:
Kh (u) =

1
K(u)
h

(10.7)

where h is the scale factor, commonly referred to as the bandwidth.
Given a particular kernel function and bandwidth, the weight on an observation

167

i, when evaluating the regression function at point x, is deﬁned as:
Wi (x) =

Kh (x − Xi )
N
i=1

N −1

Kh (x − Xi )

(10.8)

This leads to the Nadaraya-Watson estimator proposed by (suprise, suprise!)
Nadaraya (1964) and Watson (1964):
mh (x)
ˆ

=
=

N −1
N −1

N
i=1 Kh (x − Xi )yi
N
i=1 Kh (x − Xi )

N
i=1 Kh (x − Xi )yi
N
i=1 Kh (x − Xi )

(10.9)
(10.10)

Therefore, it is clear to see that there are two main choices to make when using
this technique: the shape of the kernel weights, which is determined by K, and
the size of the weights, which is parameterised by h the bandwidth. We will
discuss these points in due course.....

10.1.1

In Matlab

To ﬁx the basic ideas, let’s ﬁrst consider how to implement the basic NadarayaWatson kernel estimator in Matlab with a Gaussian kernel function and the
”plug-in” bandwidth suggested by Bowman and Azzalini (1997) using the data
set we conjured up above, i.e.:

>> X = [1:100]';
>> y = sin(0.1*X) + randn(length(X),1);

The Gaussian kernel function takes the form:
1
u2
K(u) = √ exp −
2
2π
In matlab, this is deﬁned as follows:

168

(10.11)

>> GaussKrnl = @(u) exp(-(u.*u)/2)/sqrt(2*pi);

The plug-in choice for the bandwidth as given by Bowman and Azzalini (1997),
is implemented as:

>>
>>
>>
>>

N = length(X);
hx=median(abs(X-median(X)))/0.6745*(4/3/N)^0.2;
hy=median(abs(y-median(y)))/0.6745*(4/3/N)^0.2;
h=sqrt(hy*hx);

Kernel regression proceeds pointwise- i.e., you pick the values of x that you
want to evaluate the regression function at, and then you evaluate mh (x) at
ˆ
these points only. Here we will evaluate mh (x) at the values of the independent
ˆ
variable that we have already observed in our data set.

yhat = NaN(N,1);
for i = 1:N
u = (X - X(i))/h;
Ku = GaussKrnl(u);
yhat(i) = sum(Ku.*y)/sum(Ku);
end

Compared to the OLS estimate above, the Nadarya-Watson estimator gets us
much closer to the true underlying regression function.

169

5
True
OLS
Kernel

4
3
2

y

1
0
−1
−2
−3
−4

0

10

20

30

40

50

60

70

X

Figure 10.2: Basic Kernel Regression

170

80

90

100

10.2

Structures

Above, we simply assumed particular forms for the bandwidth and the kernel
function. However, it is important to consider the impact that these choices
have on the regression output. Before getting started, we will brieﬂy review
matlab’s structure arrays, which provide a handy way of storing output.
Structure arrays allow for storing multiple data types in the same variable. If
you like, a structure represents a single idea or ”object”. Inside a structure is a
list of ﬁelds that represent a variable name for a subpiece of data. For example,
below we will try out diﬀerent speciﬁcations of our kernel regression function
and will use a structure to collect our various results. To illustrate, we could
store the results of our regression above in the structure Kresults as follows:

Kresults.name = 'Gaussian';
Kresults.h = h;
Kresults.yhat = yhat;

To see the contents of a structure, just type it’s name at the command line:

>> Kresults
Kresults =
name: 'Gaussian'
h: 1
yhat: [100x1 double]

The individual components of the structure are the ﬁelds. It’s worth noting that
you can operate on the elements of the structure just like any other matlab
variable. For example,

>> Kresults.h*10
171

ans =
10

We will use an array of structures to hold the results associated with diﬀerent
bandwidths and kernel functions. Imagine that we were also interested in storing
the results associated with a bandwidth of 6:

>> Kresults(2).h = 6;
>> Kresults
Kresults =
1x2 struct array with fields:
name
h
yhat
>> Kresults(2).yhat
ans =
[]

The ﬁelds ’name’ and ’yhat’ are left empty for this second record, until they are
speciﬁed.

10.3

Kernel and bandwidth choice

We will now use matlab’s structure arrays to record regression output as we
vary the bandwidth and our choice of kernel. We will consider three popular
choices for the Kernel function....

172

• Gaussian

1
u2
K(u) = √ exp −
2
2π

(10.12)

krnl = @(u) exp(-(u.*u)/2)/sqrt(2*pi);
• Epanechnikov
K(u) =

3
(1 − u2 )1(|u| ≤ 1)
4

(10.13)

krnl = @(u) 0.75*(1 - (u.*u)).*(abs(u) <= 1);
• Uniform
K(u) =

1
1(|u| ≤ 1)
2

(10.14)

krnl = @(u) 0.5.*(abs(u) <= 1);

... and 4 choices for the bandwidth.....

>> h = [1e-3; 3; 6; 40];
>> h_ = length(h);

The script below creates a structure, Kresults, that records the kernel function,
bandwidth and regression output associated with the 12 combinations of the
kernels and bandwidths above. It calls on the function ”kreg” that uses a more
general form of the code we introduced above to perform these regressions with
the kernel function and bandwidth speciﬁed.

% Example Class Script: Kernel Regression with Structures
clear; clc;
%% Faking some data
%..... for example
X = [1:100]’;
y = sin(0.1*X) + randn(length(X),1);
%% Prepare structure
K = [’Gaussian
’; ’Epanechnikov’; ’Uniform

173

’];

K = cellstr(K);
K_ = length(K);
h = [1e-3; 3; 6; 40];
h_ = length(h);
Kresults = struct(’name’, [], ’h’, [], ’yhat’, []);
%% Kernel regression
for k =1 : K_
for hh = 1 : h_
Kresults((k-1)*h_ + hh).name = K(k)
Kresults((k-1)*h_ + hh).h = h(hh);
Kresults((k-1)*h_ + hh).yhat = kreg(X, y, X, h(hh), K(k));
end
end
%% Plot output
% Bandwidth
figure;
for hh = 1 : h_
subplot(2, 2, hh);
scatter(X,y);++
hold on
plot(X, Kresults(hh).yhat,’Color’,’r’, ’LineWidth’, 1.5);
hold off
end
figure;
for k = 1 : K_
subplot(3, 1, k);
scatter(X,y);
hold on
plot(X, Kresults((k-1)*h_ + 3).yhat,’Color’,’r’);
hold off
end

174

function [yhat,h] = kreg(X,y,x,h0,func)
%--------------------------------------------------------------% PURPOSE: performs the Gaussian regression of y on (univar) X
%--------------------------------------------------------------% USAGE: yhat = kreg(X,y,x,h0)
% where: y = n-by-1 dependent variable
%
X = n-by-1 independent variable
%
x = N-by-1 points of evaluation
%
h0 = scalar bandwidth
%--------------------------------------------------------------% OUTPUT: h = bandwidth used
%
yhat = regression evaluated at each elemnt of x
%--------------------------------------------------------------n = length(y);
N = length(x);
%% Determine bandwidth if not supplied
if nargin < 4
% suggested by Bowman and Azzalini (1997)
hx=median(abs(x-median(x)))/0.6745*(4/3/n)^0.2;
hy=median(abs(y-median(y)))/0.6745*(4/3/n)^0.2;
h=sqrt(hy*hx);
else
h = h0;
end
%% Determine Kernel function if so desired
if nargin < 5
% Gaussian as default
krnl = @(u) exp(-(u.*u)/2)/sqrt(2*pi);
else
K = [’Gaussian
’; ’Epanechnikov’; ’Uniform
’];
K = cellstr(K);
if (func == K(1))
krnl = @(u) exp(-(u.*u)/2)/sqrt(2*pi);
elseif (func == K(2))
krnl = @(u) 0.75*(1 - (u.*u)).*(abs(u) <= 1);

175

elseif (func == K(3))
krnl = @(u) 0.5.*(abs(u) <= 1);
else
krnl = @(u) exp(-(u.*u)/2)/sqrt(2*pi);
end
end
%% Perform kernel regression!
yhat = NaN(N,1);
for i = 1:N
u = (X - x(i))/h;
Ku = krnl(u);
yhat(i) = sum(Ku.*y)/sum(Ku);
end
return

Bandwidth =0.001

Bandwidth =3

2

0

0

y

4

2

y

4

−2
−4

−2

0

50

−4

100

0

X

100

X

Bandwidth =6

Bandwidth =40
4

2

2

0

0

y

4

y

50

−2
−4

−2

0

50

100

X

−4

0

50

X

Figure 10.3: Inﬂuence of Bandwidth Choice

176

100

From inspection of the ﬁgures, it is clear that the choice of bandwidth has a
huge inﬂuence over the regression output, whilst the choice of kernel function
does not inﬂuence the general shape of the curve too signiﬁcantly. In fact, in
large samples, the choice of K is of negligible impact.

Gaussian
y

5
0
−5

0

10

20

30

40

50

60

70

80

90

100

60

70

80

90

100

60

70

80

90

100

X
Epanechnikov
y

5
0
−5

0

10

20

30

40

50

X
Uniform
y

5
0
−5

0

10

20

30

40

50

X
Figure 10.4: Inﬂuence of Kernel Choice

10.4

Bandwidth choice

The choice of bandwidth has caused much head scratching within the literature
on nonparametric regression. Bandwidth is clearly really important but it is
hard to work out exactly how to choose its value.
One popular and practical approach to bandwidth selection is cross-validation.
The approach is motivated by considering the sum-of-squared errors:
(yi −
2
ˆ i )2 =
h
ei . A natural procedure would involve picking h to minimise this
ˆ
177

quantity. However, it turns out that this is not a sensible thing to do. Think
about it. As h shrinks, the within-sample ﬁt of the model improves and thus
e2 decreases. In fact, as h approaches zero, mh (Xi ) collapses on yi to obtain
ˆi
ˆ
2
perfect ﬁt. Thus, picking h to minimise
ei , would result in h = 0 and an
ˆ
interpolation of observed data points.
Thus, rather than pick h to minimise the sum of squared residuals, one selects
h to minimise the sum of squared ”leave one out” residuals:
N

(yi − m¬i (Xi ))2
ˆ

CV =

(10.15)

i=1

where m¬i (Xi ) is the estimator obtained by omitting the ith observation, {Xi , yi }.
ˆ
This is easily done in Matlab using, you guessed it, our favorite friend fmincon! First, we have to create a function that returns the sum of squared errors
associated with the leave one out estimator given a paritcular value for the
bandwidth h.

function value = MSE(X,y,h)
%--------------------------------------------------------------% PURPOSE: calculate the MSE for the leave one out kernel reg
%--------------------------------------------------------------N= length(X);
yhat = NaN(N,1);
%% Calculate the cross validation criterion function
for i = 1:N
% remove ith observation
x0 = X(setdiff(1:N,i),:);
y0 = y(setdiff(1:N,i),:);
% caluclate yhat using kernel reg
yhat(i) = kreg(x0,y0,X(i),h);
end
value = sum((y-yhat).^2);

178

return

Then, given some starting value h0 , we can pick the bandwidth to minimise this
objective function subject to the constraint that h must be weakly positive.

options = optimset('Display', 'off', 'Algorithm', 'sqp');
opth = fmincon(@(h)MSE(x,y,h), h0, [],[], [],[], 0, Inf,[], options);

Voila! We have the cross-validation global bandwidth!

10.5

Multivariate Kernels and the Curse

There is no fundamental methodological diﬀerence between kernel regression in
the univariate and multivariate settings. However, high-dimensional nonparametric regression does face some rather serious practical problems. In fact, it
is aﬄicted by the so-called ”Curse of Dimensionality”, which severely limits its
applications to high dimensional settings.
To begin, let us ﬁrst consider the mulitvariate generalisation of the NadarayaWatson estimator that takes the form:
mH (x) =
ˆ

N
i=1 KH (x − Xi )yi
N
i=1 Kh (x − Xi )

(10.16)

Thus, the regression estimator has the same interpretation as previously: it si
the weighted sum of observed responses, yi , that are associated with values of
Xi that lie in a ball around x. weighted average of observation in a ball around
x.
The multivariate kernel function KH is typically chosen as the as the product

179

of univariate kernels:
d

K(u) =

K(uj )

(10.17)

j=1

10.5.1

In Matlab

Implementing multivariate kernel regression in Matlab simply requires us to
adapt the techniques introduced earlier in this chapter to evaluate the regression
function at a grid of points. As a simple example, let’s attempt to estimate the
following regression model :
yi

= sin(10Xi Zi ) + ei

(10.18)

Xi

∼ U (0, 1)

(10.19)

Zi

∼ U (0, 2)

(10.20)

ei

∼ N (0, 1)

(10.21)

% Class Script- multivariate kernel code
X
Z
y
n

=
=
=
=

rand(1000,1);
2*rand(1000,1);
sin(10*X.*Z) + 0.1*rand(length(X),1);
length(y);

% create meshgrid for points of evaluation
[x,z] = meshgrid(0:0.1:1, 0:0.2:2);
N = size(x,1);
% kernel and h
krnl = @(u) exp(-(u.*u)/2)/sqrt(2*pi);
hx=median(abs(X-median(X)))/0.6745*(4/3/n)^0.2;
hz=median(abs(Z-median(Z)))/0.6745*(4/3/n)^0.2;
hy=median(abs(y-median(y)))/0.6745*(4/3/n)^0.2;
hx=sqrt(hy*hx);

180

hz=sqrt(hy*hz);
% create multivariate kernel
KX = NaN(length(y),size(x,1));
KZ = NaN(length(y),size(z,1));
for x_ = 1 : N
xi = x(1,x_);
ux = (X - xi)/hx;
Kux = krnl(ux);
KX(:,x_) = Kux;
end
for z_ = 1 : N
zi = z(z_, 1);
uz = (Z - zi)/hz;
Kuz = krnl(uz);
KZ(:,z_) = Kuz;
end
% putting together
yhat = NaN(size(x,1), size(x,2));
for i = 1 : N
for j = 1 : N
Ku = KX(:,i).*KZ(:,j);
yhat(j,i) = sum(Ku.*y)/sum(Ku);
end
end
surf(x,z,yhat)
xlabel(’X’, ’FontSize’, 14);
ylabel(’Z’, ’FontSize’, 14);
zlabel(’y’, ’FontSize’, 14);
hold on
scatter3(X,Z,y)

181

1.5
1

y

0.5
0
−0.5
0

−1
1

0.5

0.8
0.6

1
0.4

1.5

0.2
0

2

X
Figure 10.5: Multivariate Kernel

182

Z

Chapter 11

Semiparametric Methods
In the last chapter, we saw that the curse of dimensionality curtails the application of nonparametric multivariate techniques. Much eﬀort has been devoted
to developing models that reduce the complexity of high dimensional regression
problems. This often involves an allowance for partly parametric modelling.
We will here focus on two popular semiparametric models: the partially linear
model and the linear index model.

11.1

Partially Linear Model

The partially linear model has two parts: a parametric component Xβ and a
nonparametric component mz (Z).
yi = Xi β + mz (Zi ) + ei

(11.1)

Our goal is to estimate β and mz (Z). For the reasons discussed previously
concerning the curse of dimensionality, we will restrict attention to the case
where Zi is unidimensional. The extension to the multidimensional case is

183

straightforward once you are familiar with the section on multivaraite kernels
in the last chapter.
It is worth noting that simply regressing y on X alone will return inconsistent
estimates for β except in the unlikely case when cov(X, mz (Z)) = 0. Further,
since mz is unconstrained, the elements of Xi cannot be collinear with any
function of Zi . Thus, an intercept and any deterministic function of Zi must be
excluded from Xi as the function mz will embody these components.

11.1.1

Robinson’s approach

We will focus on the seminal approach suggested by Robinson (1988) as a way to
estimate the partially linear model. Robinson’s method involves ”concentrating
out” the unknown function mz using a double residual regression. This estimator for β is consistent, asympotically normal and converges at the parametric
rate.
To convey the essential theory behind the Robinson estimator, take expectations
of the partially linear model with respect to Zi to yield:
E(yi |Zi )

= E(Xi β|Zi ) + E(mz (Zi )|Zi ) + E(ei |Zi )

(11.2)

= E(Xi |Zi )β + mz (Zi )

(11.3)

Subtracting this from the full model removes the unknown function mz to leave:
yi − E(yi |Zi )
eyi

=

(Xi − E(Xi |Zi ))β + ei

= exi β + ei

(11.4)
(11.5)

Thus, β can be recovered as the coeﬃcient of the regression of conditional errors.
Robinson (1988) suggested ﬁrst estimating E(yi |Zi ) and E(Xi |Zi ) by Nadarayaˆ
Watson regressions and then using the associated residuals eyi and exi to estiˆ

184

ˆ
mate β. More formally, let
yi

= my (Zi ) + eyi

(11.6)

Xi

= mx (Zi ) + exi

(11.7)

with the estimators
my (z)
ˆ

=

md (z)
ˆx

=

N
i=1 Kh (z − Zi )yi
N
i=1 Kh (z − Zi )
N
d
i=1 Kh (z − Zi )Xi
N
i=1 Kh (z − Zi )

(11.8)
(11.9)

where md (z) gives the estimator of the mean of the dth dimension of the matrix
ˆx
of X given Z.
Implementation of the Robinson estimator requires one to regress each variable
(yi and each of the separate dimensions of Xi ) on Zi . These should each be
viewed as separate kernel regressions, with diﬀerent bandwidths if required. This
is easily implemented in matlab using the techniques, speciﬁcally the function
kreg, introduced in the previous chapter.

%% Faking some data
%..... for example
Z = [1:100]’;
X = 100*rand(length(X1),2);
beta = [2;3]; % make up a beta
y = sin(0.1*Z) + X*beta + randn(length(X),1);
%% Concentrate out X1
% 1. NP regression of y on Z
ghat_y = kreg(Z,y,Z);
ehat_y = y - ghat_y;
% 2. NP regression of X’s on Z
ehat_X = NaN(size(X,1),size(X,2));
for i = 1:size(X,2)
ghat_X = kreg(Z,X(:,i),Z);

185

ehat_X(:,i) = X(:,i) - ghat_X;
end
%% Estimate for beta
bhat = (ehat_X’*ehat_X)\(ehat_X’*ehat_y);

11.2

Single Index Model

Another commonly encountered semiparametric model is the Single Index Model.
Under this framework, yi depends upon X through the function m(Xβ), where
m is often referred to as the link function. These models are useful because they
are only nonparametric in one dimension and thus are useful for alleviating the
curse of dimensionality.
yi = m(Xi β) + ei
(11.10)

Note that X cannot include an intercept as the function m will include any
location and level shift. Further, the level of β is not identiﬁed and thus some
normalisation criterion is required for beta. This is typically achieved by setting
one element of β equal to 1. In this case, one must be careful that this variable
correctly has a non-zero coeﬃcient. Identiﬁcation also requires that X includes
one continuously distributed variable and that is informative for y. Otherwise it
is impossible to identify the continuous function m on what is a discrete support.

11.2.1

Ichimura’s estimator

If m were known then we could estimate β by nonlinear least squares techniques.
In this circumstance, one would pick β to minimise the criterion function:
N

(yi − m(Xi β))2

S(β, m) =
i=1

186

(11.11)

Ichimura proposed replacing the unknown function m with the ”leave one out
estimator”:
N

S(β)

(yi − m¬i (Xi β))2
ˆ

=

(11.12)

i=1

=

(Xi −Xj )β
h

yi

i=j K

m¬i (Xi β)
ˆ

K

(Xi −Xj )β
h

yi

i=j

(11.13)

The leave one out estimator is used because one is estimating the regression at
the ith observation and is analogous to that used when using cross validation
methods to calculate the bandwidth. In fact, Hardle, Hall and Ichimura (1993)
suggest picking β and h to jointly minimise S(β).

function [beta,opth] = ichimura(X,y)
%--------------------------------------------------------------% PURPOSE: implements Ichimura’s estimator
% imposing beta(1) = 1 as the normalisation condition
%--------------------------------------------------------------% USAGE: [beta,yhat] = ichimura(X,y)
% where: y = n-by-1 dependent variable
%
X = n-by-K independent variable
%--------------------------------------------------------------% OUTPUT: beta = coefficients on index
%
opth = bandwidth
%--------------------------------------------------------------n = length(y);
% starting value for beta (OLS)
y_ = y - X(:,1);
X_ = X(:,2:end);
beta0 = (X_’*X_)\X_’*y_;
beta0 = [1; beta0];
% starting values for the h’s (Bowman and Azzalini (1997))
x_ = X*beta0;
hx=median(abs(x_-median(x_)))/0.6745*(4/3/n)^0.2;

187

hy=median(abs(y-median(y)))/0.6745*(4/3/n)^0.2;
h=sqrt(hy*hx);
% gubbins
param0 = [h;beta0];
options = optimset(’Display’, ’off’, ’Algorithm’, ’sqp’,...
’MaxFunEvals’, 1e5, ’MaxIter’, 1e5,’TolX’,1e-10,...
’TolFun’,1e-10);
Aeq = zeros(1, length(param0));
Aeq(2) = 1;
beq = 1;
lb = [0;-Inf(length(beta0),1)];
% determine optimal h and beta by minimising squared error
Param = fmincon(@(p) ghat_ni(X, y, p), param0, [],[],...
Aeq,beq,lb, [], [] ,options);
opth = Param(1);
beta = Param(2:end);
return

188

Part VI

Speed

189

Chapter 12

Speeding Things Up!
If I’m not back in ﬁve minutes, just wait longer.

Ace Ventura, “Ace ventura, Pet Detective”

12.1

Introduction

In general in our work so far, we have concentrated on getting things right, rather
than doing things in the fastest way possible. However, one of the beauties of
the Matlab language is that there are many ‘low hanging fruits’ waiting to be
picked in terms of writing code which runs quickly on our machines. In this
ﬁnal chapter we will discuss a number of tricks to keep in mind when writing
code, or when optimising code which you have already written and which you
plan to run many times.
Some of these time-saving tricks are as simple as preferring column- rather than
row-vectors, while some are slightly more complex, such as taking advantage of
the power of parallel processing. We think it worth pointing out here, however,

190

that there is—as common in many economic problems—a trade-oﬀ involed in
these sort of coding decisions. We could spend a long time trying to make our
code run faster to save computation time, or we may be happy to write somewhat less optimal code, save our own time, and accept that our compuational
resources will be tied up for longer.1 For this reason we will focus mostly on the
quick and easy ways to speed up code in Matlab, however we’ll also point you
in the direction of further resources in case you’re interested in spending more
time making very quick code...

12.2

Clever Coding

12.2.1

Vectorising

The simplest way to speed up our code is to follow a number of basic rules when
writing any Matlab functions or scripts. The ﬁrst among these: to always work
with the most vectorised code possible. From working with other languages, you
may be inclined to write operations one-by-one on elements of a list by looping
through each element of the list. In Matlab, we’d encourage you as much as
possible to avoid the loop. Matlab has been written to operate very eﬃciently
on matrices, with the incorporation of a number of clever linear algebra rotuines
to speed up computation. Perhaps the easiest way to see this is by working with
some code. . . Below we provide a simple example where we do one very simple
thing (build a vector of ones), in a number of ways. We’ll time these operations
using Matlab’s tic and toc commands (try these out at the command line if
you’re interested in seeing how they behave).

function[ratio1, ratio2, ratio3] = TimeTests(n)
% [r1,r2,r3] = timetests(n) runs tests for vectors of length n.
% This tests how a naive loop compares to vectorised code, and
% how this compares to using a loop over a preallocated array.
1

Of course, the amount we decide to optimise our code should depend on how frequently we
will run a particular program. If we are writing a program to run once or a small number
of times it seems unlikely that we’d want to spend a long time thinking about speeding up
code, whereas if it is a program we will use many times, or repeat many times in a given
project, we may be interested in thinking about speeding things up!

191

%==============================================================
%=== (1) Generate n x 1 vector of ones in 4 different ways
%==============================================================
tic; vectones = ones(n,1); vect=toc;
tic; for i=1:n
rowloopones(1,i) = 1;
end; rowloop=toc;
tic; for i=1:n
loopones(i) = 1;
end; loop=toc;
preloop = NaN(n,1);
tic; for i=1:n
preloop(i) = 1;
end; prealloc = toc;
%==============================================================
%=== (2) Calculate ratio of slow methods to fast method
%==============================================================
ratio1 = rowloop/vect;
ratio2 = loop/vect;
ratio3 = prealloc/vect;
return

When you read through the code above carefully, you’ll see that we build a vector
containing n 1’s in four diﬀerent ways: ﬁrstly by directly creating an n×1 vector
(the vectorised way), then by looping through in two diﬀerent ways, and ﬁnally
by looping through a vector where we have ﬁrstly ‘preallocated’, by making an
empty vector of the correct size to ﬁll in. If we now run this function for a given
n (say n = 1, 000, 000), we can compare the time ‘clever’ vectorisation takes
compared to less clever looping:

>> [r1,r2,r3]=TimeTests(1000000);
192

>> [r1,r2,r3]
ans =
90.9239

80.0123

22.9465

While this is of course a relatively contrived example, you’ll see that we can
speed up our code by a remarkable 80-90 times if we use vectorisation rather
than naive loops2 , or a still very impressive ∼20 times when compared to looping
over pre-allocated vectors.

12.2.2

Sparse Matrices

A number of times throughout this book we’ve taken advantage of Matlab’s
sparse commands, however we’ve delayed explicit discussion until now. The
group of ‘sparse’ commands allows us to work with matrices containing mostly
zeros in a more eﬃcient way by squeezing out all zeros from the matrices. Then,
Matlab stores only all the non-zero (information containing) elements of our
data, and avoids storing and operating on a large number of zeros.
Sparsity can come in handy in many microeconometric calculations. Among
others: when working with matrices containing observations on individual choice
along a range of goods (which are mostly not chosen), transition matrices in
dynamic choice (where individuals only transition between a relatively small
number of the total states), and when working with identity matrices and their
many oﬀ-diagonal zeros.
Fortunately, incorporating these matrices into your code is relatively simple,
and can oﬀer important speed-ups and memory savings. Below we write a quick
script to demonstrate the beneﬁts of these matrices in terms of memory space
and time.
2

While we won’t go into it in too much detail, you may wonder why dealing with column
vectors is more eﬃcient than dealing with row vectors. This has to do with the way Matlab
stores arrays in memory, and is a useful general principle that you should prefer columns to
rows when working in this language. . .

193

%============================================================
% (1) Set up test size, prefill results vector
%============================================================
N
= 1000;
factor = NaN(N,2);
%============================================================
% (2) Test memory improvement of sparse v non-sparse
%============================================================
for i = 1:N
naive
= eye(i);
cool
= speye(i);
mem_n
mem_n
mem_c
mem_c

=
=
=
=

whos(’naive’);
mem_n.bytes;
whos(’cool’);
mem_c.bytes;

factor(i,1) = mem_n/mem_c;
clear naive cool
end
%============================================================
% (3) Test speed improvement of sparse v non-sparse
%============================================================
for i = 1:N
naive
= eye(i)
cool
= speye(i)
tic; inv(naive); n=toc;
tic; inv(cool); c=toc;
factor(i,2) = n/c;
clear naive cool
end
%============================================================

194

% (4) Graphical output
%============================================================
subplot(2,1,1)
plot(1:N,factor(:,1), ’LineWidth’, 2)
xlabel(’Size of Matrix (N\times N)’, ’FontSize’, 10)
ylabel(’Proportional Saving in Memory’, ’FontSize’, 10)
title(’The Advantage of Using Sparse As N\rightarrow 1000’,...
’FontSize’, 14)
subplot(2,1,2)
scatter(1:N, factor(:,2), ’LineWidth’,2)
xlabel(’Size of Matrix (N\times N)’, ’FontSize’, 10)
ylabel(’Proportional Saving in Time’, ’FontSize’, 10)

The ﬁgures below (12.1) suggest that these sparse commands can be very worthwhile if they are suitable to your application. As the size of the initial (sparse)
matrix grows, and with the removal of continually more non-information containing elements, the storage size of sparse matrices is linearly more eﬃcient
compared to their non-sparse counterparts, while the relative eﬃciency in terms
of operation time also increases approximately linearly.
Brieﬂy before switching tack, we think it worthwhile to point out that while
sparse matrices must be entered or converted using Matlab’s sparse commands, they can then be operated on normally, and Matlab will respect their
sparse nature. For example, were we to call sum with a sparse matrix (which
returns sums by column of our original matrix), this will return to us a sparse
vector, with only as many entries as there are non-zero containing columns in
our original matrix.

195

Proportional Saving in Memory
Proportional Saving in Time

The Advantage of Using Sparse Commands As N→ 1000
400
300
200
100
0

0

100

200

300

0

100

200

300

400
500
600
Size of Matrix (N× N)

700

800

900

1000

400
500
600
700
Inverse of Matrix (N× N)

800

900

1000

200
150
100
50
0

Figure 12.1: Why bother with sparsity?

12.2.3

Proﬁling Code

As we have generally done throughout this book, the normal way that we’ll write
our code in microeconometric applications is to work in stages. Often we’ll make
a ﬁrst attempt where we simply concern ourselves with getting things right, and
only then will we consider going back and working to make our code run more
eﬃciently.3 However, once we’ve got a version of our code working we may be
reticent to change it, or simply not know where to start if we were to try to
speed it up! As we’ve seen so far in this chapter, a useful way to know where
to concentrate is by using Matlab’s tic and toc commands, which can tell us
how long the code takes run at various points.
Fortunately, rather than having to introduce a series of counters at various
points in our code, the proﬁler is available which essentially works as an ongoing
3

After all, fast code is entirely useless if it doesn’t actually do what it is supposed to!

196

series of tics and tocs. It allows us to see at each point of our code how long the
code takes to run, and highlights for us those few places where bottlenecks exist,
and where we may want to focus our attention. Once again, this is incredibly
cheap to run. All we need to do is switch the proﬁler on and we’re good to go.
Let’s run this with the sparse tests we just wrote in the previous section, and
see what the proﬁler tells us. . .

>>
>>
>>
>>

profile on
sparseTests
profile off
profile viewer

Figure 12.2: Matlab’s proﬁler window

197

Matlab returns to us the output from ﬁgure 12.2.4 This simply shows us
the run time at each step of the process, and highlights in red those few parts
which hold up the script. Unsurprisingly perhaps, we see that most of the time
working is spent on inverting non-sparse matrices. Were this a true application
we could then consider trying to optimise this line (perhaps replacing it with
sparse matrix operations!), and very simply reduce our code run time in a
signiﬁcant way.

12.2.4

Waiting. . .

In sections 12.2.1-12.2.3 we’ve worked under the assumption that our code can
or should be optimised further. However, those among us who work with large
computations may ﬁnd that sometimes even after writing your code as cleverly
as possible, you still are required to wait for some non-neglible period of time
while this code runs. If so, perhaps you would like to be updated in some way
when Matlab has completed its task. For this reason the very nice inbuilt
command sendmail exists. This allows you to send an email directly to your
inbox from the Matlab window, and even include your Matlab results as
attachments.
The sendmail command itself is quite simple to use, as all it requires is an email
address(es) to send the message to, and optionally, a subject, a message and
attachments. However, there are a number of bugbears which must be ironed
out if you wish to use password protected email such as that provided by gmail
or a number of other providers. The below function is a wrapper for sendmail
in which we set all the email preferences, and which we can use to notify ourself
when our program ﬁnishes running.

function mailResults(ResultsLabel, MatrixOut,YourEmail);
% MailResults(ResultsLabel, MatrixOut,YourEmail) sends matrix
% of MATLAB results to the email address specified in YourEmail.
% This is useful to include at the end of a long script, as it
% will send an email upon termination
4

It also returns to us a line-by-line list of functions, but here we’ll just focus on the graphical
output, and let you look through other output further if this is useful for you.

198

%
% see also sendmail
%===============================================================
%=== (1) Basic Email Preferences
%===============================================================
mail
= ’matlaboxford@gmail.com’;
password
= ’matlabmatlab’;

%===============================================================
%=== (2) Advanced settings
%===============================================================
setpref(’Internet’,’SMTP_Server’,’smtp.gmail.com’);
setpref(’Internet’,’E_mail’,mail);
setpref(’Internet’,’SMTP_Username’,mail);
setpref(’Internet’,’SMTP_Password’,password);
props = java.lang.System.getProperties;
props.setProperty(’mail.smtp.auth’,’true’);
props.setProperty(’mail.smtp.socketFactory.class’, ...
’javax.net.ssl.SSLSocketFactory’);
props.setProperty(’mail.smtp.socketFactory.port’,’465’);
%===============================================================
%=== (3) Send email along with time spent running program
%===============================================================
MyToc
= toc;
dlmwrite(’MatlabResults.csv’, MatrixOut, ’precision’, ’%10.10f’)
sendmail(YourEmail,ResultsLabel, ...
strcat(’toc = ’, num2str(MyToc)), ’MatlabResults.csv’)
return

You can try this by including it with appropriate arguments at the end of some
other script, or simply by using at the Matlab command line.

199

>> tic;
>> matrix = magic(10);
>> mailResults('magicmatrix', matrix, 'your.email@gmail.com')

with the results of this script now evident in your inbox!

12.3

Parallel Computing

In a nutshell, parallel computing allows for computationally intensive procedures
to be separated and run in individual blocks rather than as one large job. This
is particularly useful in applications such as Monte Carlo simulation, or other
situations in which many processes which are mutually independent from one
another are involved in arriving at a ﬁnal result.
Modern computers are often made up of a number of integrated processors.
These processors, called CPUs, can be thought of as the workhorse of the computer when it comes to running the calculations and simulations we have been
doing in Matlab. The fact that many computers now come with more than
one CPU to speed up processing means that we can explicitly ask Matlab to
run our jobs using multiple CPUs, and hence experience (at times nearly linear)
speedups in processing by asking all the CPUs to pull together!5
What’s more, programming this in Matlab is remarkably easy.6 Where we
would have broken down jobs into parts and sent them to the CPU before, we
now break down jobs into parts and send them to multiple CPUs. In Matlabspeak this is as simple as saying parfor rather than for. Below we provide a
brief example of this, and demonstrate some of the common pitfalls:
5

Hint: to see how many cores your computer has try the following in the Matlab:
>> feature(’numCores’)
ans =
12

6

Provided that you have the parallel computing toolbox installed in Matlab. Unfortunatly,
without this parallel programming is somewhat harder. . .

200

%==============================================================
%% (1) Basic illustration of parfor
%==============================================================
matlabpool open
tic
parfor count = 1:12
count
pause(1)
end
toc
%==============================================================
%% (2) consider a problem that is not parallelisable...
%==============================================================
fibonacci
= zeros(15, 1);
fibonacci(1)
= 1;
fibonacci(2)
= 1;
for c = 3:size(fibonacci, 1)
c
fibonacci(c) = fibonacci(c - 1) + fibonacci(c - 2);
end
%==============================================================
%% (3) this IS parallelisable, but needs careful construction
%==============================================================
MyObviousMatrix
= NaN(10, 2);
MyObviousMatrix1
= NaN(10, 1);
MyObviousMatrix2
= NaN(10, 1);
parfor count = 1:size(MyRandomNumbers, 1)
count
MyObviousMatrix(count, 1)
= 1;
MyObviousMatrix(count, 2)
= 2;
%MyObviousMatrix1(count)
%MyObviousMatrix2(count)

= 1;
= 2;

201

end
MyObviousMatrix

= [MyObviousMatrix1, MyObviousMatrix2];

return

You’ll note that in block (1) of the code we simply use a parfor loop, asking
each loop to pause for 1 second. Were we to run this in a non-parallel fashion,
we’d of course expect this to take around 12 seconds. As you’ll see with our
parfor loop however, this took a mere 1 second as each pause was sent to a
separate CPU. The only other unfamiliar command here is matlabpool open:
this simply indicates to Matlab that it should set up parallel workers in a pool
to pull together.
In blocks (2) and (3), we go through the type of situation which won’t work with
parallel programming. Given that each step is run in a separate part of the computer, we can’t ask for information to be shared between cores. Essentially we
require the problem at hand to be ‘parallelisable’ in the sense that it can be
broken down into small blocks and then only aggregated once each block has
ﬁnished. For precisely this reason the Fibonnaci sequence is not parallelisable:
at each point in the algorithm we need to know the previous two realisations,
meaning that this clearly is a sequential rather than parallelisable calculation.
Notwithstanding these objections, there are many cases where we will be dealing with trivially parallelisable problems in microeconometrics. Consider, for
example a bootstrap calculation. These processes involve calculating a statistic
many times, and then from the empirical distribution of these calculated statistics determining a conﬁdence interval. Such a case is perfect for a Matlab
parfor loop. In each loop we can calculate a subset of the bootstrap draws,
and then once terminating all loops, pool these and calculate our ﬁnal standard
errors. Let’s try this out with our familiar auto.csv data. . .
% bootstrapOLS.m is a script which estimates standard errors by
% bootrstrapping a linear model. This illustrates the speed-ups
% that can reasonably be achieved in parallel computations with

202

% some overhead
%
% If we wanted to compare to (for example) Stata:
%
bootstrap, reps(10000): reg mpg price weight, noheader
clear
rng(1)
if matlabpool(’size’) == 0
matlabpool(12)
end
%=============================================================
% (1) Open regression data
%=============================================================
DataIn = dlmread(’auto.csv’);
X
= DataIn(:, 2:3);
X
= [X, ones(74, 1)];
y
= DataIn(:, 1);
[beta, se]
[beta, se]

= regress(y, X);

%=============================================================
% (2) Bootstrap standard errors (100,000 draws)
%=============================================================
reps
= 100000;
BootstrapBeta
= NaN(reps, 3);
tic
parfor count = 1:reps
MyIndex
= round(rand(74, 1) * 74 + 0.5);
BootX = X(MyIndex, :);
BootY = y(MyIndex, :);
BootstrapBeta(count, :)

= [regress(BootY, BootX)]’;

end

203

toc
[beta, se, mean(BootstrapBeta)’, std(BootstrapBeta)’]

12.4

Parallel Computing Plus: The GPU

So far we have seen that Matlab will let us take one big job, split it into a
number of smaller jobs and run these in parallel. While this is a pretty cool way
to save time, you may want to push things a bit further. Many computers now
come with between 1 and 8 CPUs (or brains). Wouldn’t it be cool if we could
increase this to say 20, or 100 or 1000 processors?
Work on the graphics processing unit (or GPU), has put processing power of
this type within reach of ‘ordinary’ computer users. While it would not be
feasible to put 1000 CPUs in a personal computer, the GPU—essentially a card
for rendering high quality graphics—is made up of many mini-processors, each
designed to render pixels in parallel. However, luckily for people like us, these
mini-processors can be tricked into working with numbers rather than pixels,
and we can use this to massively parallelise our microeconometric jobs. Parallel
calculations on the GPU are now used in a large range of ﬁelds, including
economics (see for example Aldrich et al. (2011) for an example of this type of
computation).
Even more luckily for us, Matlab has built a large number of functions which
take advantage of the GPU, and which we can use without going too far down the
rabbit hole. However, in order to use these GPU functions we require two things:
ﬁrstly, a GPU which works with these kinds of computations, and secondly
Matlab’s parallel computing toolbox. At the time of writing, this means that
you must have access to an NVIDIA brand CUDA enabled GPU. While this may
not mean much to you out of context (or indeed perhaps nothing at all!), this
is a very common type of GPU which you are likely to have in your computer,
and can be checked at the Matlab command line by typing gpuDevice. If your
computer has both the toolbox and an NVIDIA GPU installed you should see

204

something like the following excerpt7 :

>> gpuDevice
ans =
CUDADevice with properties:
Name:
Index:
ComputeCapability:
SupportsDouble:
DriverVersion:
ToolkitVersion:

'GeForce GT 630M'
1
'2.1'
1
5.5000
5

Assuming you’re with us after all of this, and that you have access to a computer
with this hardware and software, the remainder is relatively easy! Much like
Matlab’s sparse commands, its GPU commands are used by deﬁning a diﬀerent type of matrix, and then using normal Matlab commands which recognise
that we are dealing with GPU calculations. Essentially we tell Matlab to send
a matrix to the GPU, run calculations on it there (in a parallel way), and then
bring the processed infomration back from the GPU to the CPU. Below we pass
a vector of random draws to the GPU, take the mean of each row, and bring it
back:

>> N
= 10000;
>> GM
= gpuArray(rand(N));
>> tic; Gmean = mean(GM); G=toc
G =
9.500e-04
>> Gback
7

= gather(Gmean);

If you have the parallel computing toolbox but do not have an NVIDIA
GPU (or the appropriate software is not installed) you will see a message
like: “Error using gpuDevice (line 26). There is a problem with the CUDA driver
associated with this GPU device.” If, however you don’t have the parallel processing
toolbox, you will see “Undefined function or variable ’gpuDevice’.”.

205

Now, let’s try the same thing without using the GPU...

>> CM
= rand(N);
>> tic; Cmean = mean(CM);
C =
0.0439

C=toc

>> ratio = C/G
ratio =
46.4349

This very simple calculation suggests that we’ve managed to speed things up
arond 45 times when using the GPU, although this will vary a lot by the type of
GPU used, and the number of cores available. Finally, if we are to look at the
types of these variables, we will see how our GPU arrays and normal variable
types diﬀer:

>> whos
Name
C
CM
G
GM
Gback
Gmean
N
Cmean
ratio

Size

Bytes

1x1
10000x10000
1x1
10000x10000
1x10000
1x10000
1x1
1x10000
1x1

8
800000000
8
108
80000
108
8
80000
8

Class

Attributes

double
double
double
gpuArray
double
gpuArray
double
double
double

We now have a new class gpuArray for those matrices we passed to the GPU,
whereas the values we brought back with the gather command are seen as
normal vectors of double-precision numbers.
Before leaving GPU parallel programming, we feel it important to point out that
the suitability of the tool depends entirely upon the task we assign it to. Below
206

we create a function to run a relatively simple task: calculating (X X)−1 X y
on the GPU and the CPU.
function beta = gpuExample(N,k,method)
% gpuExample(N,k) creates an N by k matrix of X variables, and
% an N by 1 matrix of y variables and calculates betas using
% GPU computation.
if method==’GPU’
X = gpuArray(rand(N,k));
y = gpuArray(rand(N,1));
elseif method==’CPU’
X = rand(N,k);
y = rand(N,1);
end
tic
betas = mldivide((X’*X),(X’*y));
toc
return

In this case, when we run our calculation on the GPU we see that despite the
many cores available on the GPU, the result actually takes longer to calculate.

>> gpuExample(1000,3,'GPU')
Elapsed time is 0.000845 seconds.
ans =
0.3274
0.2976
0.3014
>> gpuExample(1000,3,'CPU')
Elapsed time is 0.000155 seconds.
ans =
207

0.3274
0.2976
0.3014

12.5

Other Tricks

So far this chapter has been a tour through some of the more ‘low-cost’ ways
to speed up our Matlab code. Before closing this chapter we will point out a
number of alternative tricks, however, due to their somewhat extensive nature,
we’ll leave you to explore these in your own time should you be interested
(perhaps starting with Matlab’s online resources).
Firstly, if you are concerned with resolving one or two bottlenecks in code that
are quick to code but slow to run and which run many times, you could consider
using Matlab’s MEX-ﬁles. These ﬁles allow Matlab to run (potentially much
faster) code which has been written in the alternative languages Fortran or
C/C++. These essentially act as ‘plug-ins’ to the Matlab language. While
the code is called ﬂuidly from you Matlab window, it retains the speed of the
language in which it was originally written. However, we should point out as a
means of caution, this requires learning the syntax of either Fortran or C/C++.
While it is true that you will probably see performance enhancements in your
code, this should be weighed against the cost of learning and implementing a
new language.8
Finally, we’ll brieﬂy mention a way to massively parallelise your code: the use
of online cloud computing. So far in this chapter, we’ve mentioned parallel
coding using parfor and using your computer’s GPU. However, both of these
are inherently limited by the technology of your personal computer. Should
you decide that you want to work on an extremely large number of cores, the
recent advances in cloud computing oﬀer you a solution. Here, rather than
running on the cores of your local machine, you can log in to a website which
provides you access to ‘virtual cores’ on which to run your code. The beauty
of this infrastructure is that in places no (or few) limits on the number of cores
8

That is to say, unless you already know one of these languages!

208

which you can access, as you simply use cores which live ‘on the cloud’, and
then log oﬀ when you are ﬁnished. This is particularly useful if you will be
doing large one-oﬀ jobs which require high computational resources for a short
period of time. Two options are to use Matlab with the Amazon EC2,9 or use
the online service PiCloud. Both of these are available for use with Matlab,
and, at least for the case of Amazon’s EC2, come with documentation on the
Matlab website.

9

Amazon EC2, or Amazon Elastic Compute Cloud is a leader in cloud computing and provides computational resources which can be rented by the hour.

209

Chapter 13

Conclusion
Now this is not the end. It is not even the beginning of the end.
But it is, perhaps, the end of the beginning.

Winston Churchill

13.1

Does This Book Follow Benford’s Law

In closing, as a mere curio1 we will ask one further question: do the numbers
on the pages of this book follow Benford’s Law? This “Law” states that the
frequency of occurence of digits in many real life data sets (where here we use
the term data set rather loosely!) follows a predictable pattern. In this pattern
the digit 1 should occur around 30% of the time, with the digits 2,...,9 occurring
with continually lower frequency. More speciﬁcally, the pattern should look like:
P (n) = log10

n+1
1

, n ∈ 1, ..., 9.

(13.1)

We’ll write a brief function which uses a txt ﬁle of this book as an input and
returns to us the predicted and real frequencies as a graph:
1

And because with Matlab we can!

210

function [freq,theoretical,num] = benfordLaw(txtfile)
% freq = benfordsLaw(txtfile) accepts a txt file as input and
% scans to find occurrances of each number (1-9) and compares
% the frequency of occurrance with that of Bedford’s Law.
%============================================================
% (1) generate numbers and theoretical prob
%============================================================
num = 1:9’;
count = NaN(9,1);
theoretical=log10(1+1./num)’;
%============================================================
% (2) Determine frequency of occurence in txt
%============================================================
filein = fopen(txtfile,’r’);
filec = fscanf(filein, ’%c’);
for i=1:9
count(i,1) = size(strfind(filec,num2str(i)),2);
end
total=sum(count);
freq = count/total;
%============================================================
% (3) Plot
%============================================================
figure
width1=0.6;
bar(num,theoretical,width1,’FaceColor’,[0.2,0.2,0.5],...
’EdgeColor’,’none’);
hold on
width2 = width1/2;
bar(num,freq,width2,’FaceColor’,[0,0.7,0.7],...
’EdgeColor’,[0,0.7,0.7]);

211

hold off
legend(’Theoretical’,’Actual’)
title(’Does Benford’’s Law Hold Here?’,’FontSize’,14)
return

Does Benford’s Law Hold Here?
0.4
Theoretical
Actual
0.35

0.3

0.25

0.2

0.15

0.1

0.05

0
1

2

3

4

5

6

7

Figure 13.1: Benford’s Law In This Book

212

8

9

Bibliography
D. Acemoglu. Introduction to Modern Economic Growth. Princeton University
Press, 2008.
J. Adda and R. Cooper. Dynamic Economics. The MIT Press, Cambridge,
Massachusetts, 2003.
E. M. Aldrich, J. Fern´ndez-Villaverde, A. Ronald Gallant, and J. F. Rubioa
Ram´
ırez. Tapping the supercomputer under your desk: Solving dynamic
equilibrium models with graphics processors. Journal of Economic Dynamics
and Control, 35(3):386–393, March 2011.
R. Bellman. Dynamic Programming. Princeton University Press, Princeton,
New Jersey, 1957.
D. P. Bertsekas. Dynamic Programming and Optimal Control. Academic Press,
USA, 1976.
D. P. Bertsekas. Dynamic Programming and Optimal Control. Athena Scientiﬁc,
USA, 2005.
S. Bond and M. S¨derbom. Adjustment costs and the identiﬁcation of cobb douo
glas production functions. Economics Papers 2005-W04, Economics Group,
Nuﬃeld College, University of Oxford, Jan. 2005.
A. C. Cameron and P. K. Trivedi. Microeconometrics: Methods and Applications. Cambridge University Press, New York, USA, 2005.
F. Collard. Dynamic programming.
lectnotes7.pdf.

URL http://fabcol.free.fr/pdf/

A. K. Dixit. Optimisation in Economic Theory. Oxford University Press, Oxford, 1990.
213

M. Fafchamps, D. J. McKenzie, S. Quinn, and C. Woodruﬀ. When is capital
enough to get female microenterprises growing? evidence from a randomized
experiment in ghana. CEPR Discussion Papers 8466, C.E.P.R. Discussion
Papers, July 2011.
A. R. Hall. Generalized Method of Moments. Advanced Texts in Econometrics.
Oxford University Press, Oxford, UK., 2005.
L. P. Hansen. Large sample properties of generalized method of moments estimators. Econometrica, 50(4):1029–54, 1982.
K. L. Judd. Numerical Methods in Economics. The MIT Press, Cambridge,
Massachusetts, 1998.
M. Keane and K. Wolpin. The Solution and Estimation of Discrete Choice
Dynamic Programming Models by Simulation and Interpolation: Monte Carlo
Evidence. The Review of Economics and Statistics, 76(4):648–672, 1994.
M. P. Keane, P. E. Todd, and K. I. Wolpin. The structural estimation of behavioral models: Discrete choice dynamic programming methods and applications. volume 4 of Handbook of Labor Economics, chapter 4, pages 331–461.
Elsevier, 2011.
E. P. Lazear. The future of personnel economics. Economic Journal, 110(467):
F611–39, November 2000.
L. Ljungqvist and T. J. Sargent. Recursive Macroeconomic Theory. MIT Press,
USA, second edition, 2000.
D. Michie. “Memo” Functions and Machine Learning. Nature, 218(5136):19–22,
1968.
F. P. Ramsey. A mathematical theory of saving. The Economic Journal, 38
(152):543–559, December 1928.
J. Rust. Estimation of dynamic structural models, problems and prospects:
Discrete decision processes. Proceedings of the 6th World Congress of the
Econometric Society. Cambridge University Press, 1994a.
J. Rust. Structural estimation of markov decision processes. volume IV of
Handbook of Econometrics. North-Holland, 1994b.
T. Sargent and J. Stachurski. Quantitative economics, August 2013. URL
http://quant-econ.net/.
214

T. J. Sargent. Dynamic Macroeconomic Theory. Harvard University Press,
Cambridge, Mass., 1987.
J. Stachurski. Economic Dynamics: Theory and Computation. MIT Press, USA,
2009.
N. Stokey and R. Lucas. Recurseive Methods in Economic Dynamics. Harvard
University Press, Cambridge, Massachusetts, 1989.
K. E. Train. Discrete Choie Methods with Simulation. Cambridge University
Press, 2009.

215

